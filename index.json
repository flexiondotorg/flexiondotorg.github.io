[{"categories":["Linux","Computer Hardware","Travel"],"contents":"During the second half of 2022, I dusted off my laptop and travelled to three events for the first time in over two years. During these trips, it became apparent that my laptop is not the right tool for the job.\nAt KubeCon EU 2022 my colleague Lindsay brought her Apple Macbook Pro M1. It was lightweight, compact, looked fabulous and had epic battery life. Meanwhile, my ThinkPad P1 Gen 1 looked fabulous but it is a bit of a chonker and a massive power pig üîåüêñ Battery anxiety was constant that week and also on my subsequent trips to SREday 2022 and the Ubuntu Summit 2022. Sensing that 2022 wasn\u0026rsquo;t an outlier and more travel would be on the cards in 2023 I decided that I wanted some of that thin and light laptop action. In early December 2022, I went hunting for a Linux laptop and this is my journey.\nAs featured on Linux Matters! üéôÔ∏è I recently discussed my hunt for a new Linux Loving Laptop on the Linux Matters podcast. You can hear that discussion with my friends Alan and Mark in Linux Matters: Mastodon on My R√©sum√© (Episode 1).\nLinux Matters Podcast Past laptop purchasing mistakes üò± \u0026ldquo;Those that fail to learn from history are doomed to repeat it\u0026rdquo; - Winston Churchill.\nThe requirements for my last two laptop purchases were very different from what I need today; a Dell XPS 15 5550 and ThinkPad P1 Gen1 Both have significant power requirements with 15.6\u0026quot; UHD displays and discrete NVIDIA GPUs. The ThinkPad P1 Gen also sports a Xeon CPU ‚ö°Ô∏è These made sense when I bought them, I was travelling one week every month and regularly compiling large applications, building container images, VMs and operating system images. These days I have a Threadripper 3970X workstation at home that I can connect to via Tailscale to run compute-intensive tasks. I simply don\u0026rsquo;t need a workhorse üê¥ laptop anymore.\nLaptop criteria üìë I\u0026rsquo;m deeply impressed with the outstanding work the Asahi Linux team are doing to enable Linux on Apple Silicon Macs, but running Linux on an M1 Mac isn\u0026rsquo;t viable for me as some hardware support (HDMI for example) is still a work in progress at the time of writing. Not ideal when you\u0026rsquo;re a conference speaker and running booth demos.\nThese are my criteria for the new laptop. Some must-haves, some nice-to-haves and some hard exclusions.\nFully Linux compatible. Linux pre-installed to demonstrate Linux is fully supported Full working day battery life; ~8 hours in my opinion. Low-power CPU, 35W or under Ideally AMD 6000 series but a 12th Gen Intel as a compromise No 11th Gen Intel or AMD 5000 series CPUs will be considered 64GB RAM, will compromise on 32GB RAM 13\u0026quot; or 14\u0026quot; 1920x1200 matte display No UHD resolutions display will be considered (for power-saving reasons) Touch support is a nice-to-have, but not essential 1920x1080 as a compromise, but nothing lower No discrete GPU. Again for power-saving reasons. USB-C charging Dual NVME SSD, or at least a single 2TB (or more) SSD Decent keyboard and touchpad The Laptop should weigh close to 1kg Premium build quality and design (somewhat subjective I know) With this list of requirements established, I started collating Linux laptop comparison notes in this somewhat idiosyncratic spreadsheet\nA spreadsheet that probably only makes sense to me Looking at the list of laptops in the sheet above, you might be wondering why I didn\u0026rsquo;t consider any laptops from the established dedicated Linux laptop vendors such as Entroware, Slimbook and StarLabs. Well, I did look at everything they offered at the time and none of them had a model available that met the requirements I\u0026rsquo;ve outlined above or the estimated dispatch time was nearly half a year.\nI\u0026rsquo;m not going to elaborate on the rationale behind ruling certain laptop models in or out, but I will say this; I was very impressed to see every laptop in the Lenovo ThinkPad lineup had a Linux pre-install option of either Ubuntu or Fedora in \u0026ldquo;Build YourPC\u0026rdquo; system configurator. While comparing the power requirements of Intel\u0026rsquo;s i7-12xx series and AMD\u0026rsquo;s 68x0 series CPU at the time, I was sold on the impressive battery endurance of AMD\u0026rsquo;s offerings and the superior integrated graphics, so I excluded any laptop with Intel CPUs quite early on.\nLenovo ThinkPad Z13 Gen 1 with Ubuntu pre-installed I went with the ThinkPad Z13 Gen 1 with Ubuntu pre-installed, and the ThinkPad T14s Gen 3 was runner-up in my selection process.\nSpecifications üìù The key specifications for the laptop I ordered are AMD Ryzen 7 PRO 6850U CPU, 32 GB LPDDR5-6400MHz (Soldered), 1 TB SSD M.2 2242 PCIe Gen4, 13.3\u0026quot; WUXGA (1920 x 1200), IPS, Anti-Glare, Non-Touch display weighing in at 1.19kg. I think this configuration hits the sweet spot for battery endurance, more on that later.\nI\u0026rsquo;m not a fan of the increasing trend of soldering RAM on motherboards, but that was common across all the models of laptops I was considering. If Framework had offered an AMD 6000 series CPU option at the time, I would\u0026rsquo;ve had a Framework laptop on my short list as the modular design of the Framework laptops is very appealing.\nAnd yes, I did make a compromise with the laptop specifications; that 1TB M.2 SSD is below my minimum requirement of 2TB. I did do my homework though and will present my creative upgrade solution in a future blog post. Like and Subscribe üòâ\nBuild Quality \u0026amp; Design üíªÔ∏è Without a doubt, the ThinkPad Z13 Gen 1 is a gorgeous laptop. I do not have enough superlatives to express just how much I love it. It is, in my option, an almost flawless design. Exactly the compact form factor laptop I was seeking; it\u0026rsquo;s beautiful to look at from any angle and a delight to use. Here are some highlights.\nThinkPad Z13 Gen 1 The laptop is engineered from 75% recycled aluminium and 95% recycled plastics, then boxed in 100% renewable, compostable packaging. The touchpad is sublime and amazingly 120mm wide on the compact laptop. The haptic touch is simply excellent. The touchpad is the most Macbook-like touchpad I\u0026rsquo;ve used on any PC and it is so good it has caused me to change what desktop environment I now use. More on this in a future blog post. However, there is currently no Linux software to configure the haptic touchpad settings such as click force and touchpad feedback intensity but I\u0026rsquo;ve been perfectly happy with the defaults. If you do dual boot Windows the haptic settings configured via Windows are stored on the device and carry over to Linux.\nThe Keyboard is an excellent low-profile design, each key has ~1.2mm of travel which is the same as the actuation point on my Razer Huntsman V2 TKL keyboards with opto-mechanical switches. Most importantly the Fn key is in the correct place on the Z13 and not where ThinkPads have been incorrectly plonking it for years. Fight me! ü•ä If you are a long-time ThinkPad owner, it is likely you\u0026rsquo;ll hate the idea of the keyboard and touchpad on the Z13 since it is quite a departure from the traditional design. But I went into this with my eyes üëÄ open and have watched and read many reviews.\n\"This is the way\" The Display is bright (400nits), anti-reflective and anti-smudge, covers 100% of the sRGB colour gamut and the laptop is perfectly balanced so it can be opened one-handed. I\u0026rsquo;m embracing the compact, thin and light lifestyle; so the two USB-C ports are fine with me as I\u0026rsquo;ve chosen a laptop configuration with excellent battery endurance (more on that in a bit) and plan to use it completely untethered most of the time with cables and adapters only plugged in for very specific tasks and overnight recharging.\nI do have one niggle though; there is an unusable 2242 M.2 slot on the motherboard. It is only intended for use with select models of WWAN cards, none of which are a configuration option for the UK models of the Z13. It doesn\u0026rsquo;t look like the antenna is wired in either, so even if you do get a supported WWAN card aftermarket it is unlikely to work well; if at all. I can share my iPhone\u0026rsquo;s mobile service via Wifi, so not a deal breaker in that regard but it is rather annoying to have an M.2 slot on the motherboard and nothing I can do with it.\nUbuntu pre-install experience üëå It is worth noting that at the time of purchase, selecting Ubuntu or Fedora in the system configuration on the Lenovo website applied a ¬£155 discount! ü§ë Choosing Ubuntu or Fedora across the ThinkPad line applies a discount, although the amount varies based on the model.\nAll OEMs that partner with Ubuntu get an OEM designation for each device officially endorsed and supported by Canonical. The ThinkPad Z13 Gen 1 is known as Sutton Newell Abe and the oem-sutton.newell-abe-meta package (along with the associated OEM PPA) provides the device-specific hardware enablement and power management tuning.\nThinkPad Z13 Gen 1 is known as Sutton Newell Abe for OEM enablement The OEM image of Ubuntu differs from the standard Ubuntu image in a few ways. The most obvious is that OEM image comes with recovery media creation pre-installed. This is a great feature and I highly recommend you use it to create a recovery USB stick, either during the initial setup or post-setup. The OEM image also comes with Chromium and Firefox installed, as opposed to just Firefox in the downloadable release of Ubuntu. IIRC, this is because Chromium has traditionally worked better with touchscreen laptops. The fingerprint reader works. I was able to enrol fingerprints quickly and authenticate GDM logins. But the biometric support does not extend throughout the system; Ubuntu Software doesn\u0026rsquo;t integrate with the fingerprint reader, nor does snapd or any other privilege escalation.\nI also experienced the touchpad becoming unresponsive, requiring a click to \u0026ldquo;unfreeze\u0026rdquo; it. This happens quite frequently and detracts from what is otherwise an excellent, class-leading, touchpad. I suspect it is overly aggressive power management settings in the OEM image, but I didn\u0026rsquo;t investigate beyond that hunch. Both these issues with the fingerprint reader and touchpad are Ubuntu-specific and nothing related to the actual hardware. Both issues are absent when running NixOS.\nHaving a tier-1 vendor such as Lenovo ship a laptop with Ubuntu pre-installed has the benefit of great firmware support. I\u0026rsquo;ve received several firmware updates since I got the laptop, and they have all applied without issue.\nFirmware updates for the ThinkPad Z13 Gen 1 on Ubuntu 20.04 Why not Ubuntu 22.04? ü§î My Z13 was shipped with Ubuntu 20.04.4 with OEM optimised Linux kernel 5.14.0-1054-oem. Some might be perplexed (or annoyed) that it didn\u0026rsquo;t come with Ubuntu 22.04, given it was ordered in late 2022. I used to work for Canonical, and during that time worked with Lenovo to enable Ubuntu on ~60 of their laptops and workstations between 2019 and 2021, so I do have some insight into how this process works. It simply boils down to how the factory image certification process works, and once an image is qualified that is what ships on the device for the duration of its availability. Re-certification adds cost and takes time, so it\u0026rsquo;s extremely rare for a device to have a revised factory image qualified once it has gone on sale.\nUpgrading to Ubuntu 22.04 LTS worked flawlessly, full audio support was restored and no other hardware supported regressed. Brilliant.\nLinux Kernel 6.1 üå∞ The pre-installed Ubuntu and Fedora images for the Z13 come with kernels that have backported patches applied to fully support the device. If you buy a ThinkPad Z13 and plan to run another Linux distro on it, make sure you can install Linux kernel version 6.1 or newer. This is to ensure the Qualcomm Wi-Fi 6E NFA725A 2x2 AX chipset is fully supported and that the required patches to properly suspend and resume are available.\nBattery endurance üîã This is, after all, my most important selection criteria. The conclusion here is simple: 11 hours ‚è±Ô∏è\nThis is 11 hours of mixed-use. Coding in Visual Studio Code. Chatting in Slack and Discord. Video calls in Google Meet and Zoom. Compiling software. Some screen capture with OBS Studio and basic video editing with Shotcut. Closing the lid of the laptop and leaving it suspended for 24 hours depletes the battery by ~4% which is about 2 Wh. Very respectable. I haven\u0026rsquo;t felt the need to profile power consumption or tweak anything as I\u0026rsquo;m get plenty of untethered compute time. I\u0026rsquo;m very happy with the battery life, typically charging the laptop overnight while I sleep and running it all day battery only.\nWhat\u0026rsquo;s next? üîÆ As noted, I did compromise on the 1TB M.2 SSD. I\u0026rsquo;ve come up with an aftermarket solution to upgrade to 2TB which I will post about soon. I chose a laptop pre-installed with Linux for two reasons:\nSupport companies shipping a Linux operating system pre-installed on their laptops and workstations Hard proof Linux works on their hardware After using Ubuntu for a few weeks I switched to NixOS. I will be posting about my experience with NixOS on the Z13 in a future blog post and will likely livestream about it on Twitch as well. TL;DR NixOS 22.11 has fewer issues than Ubuntu 22.04 on the ThinkPad Z13 Gen 1.\nThe ThinkPad Z13 Gen 1 is an excellent laptop for my requirements, and I have no regrets. If I were to buy I laptop pre-installed with a Linux distro in the future, I might go for Fedora, just so I can see what the OEM experience is like with Fedora.\nSince I purchased the Z13, Framework has announced AMD 7040-series powered laptops are coming later in 2023; and I\u0026rsquo;m not sure I can resist\u0026hellip;\n","permalink":"https://wimpysworld.com/posts/why-i-chose-the-thinkpad-z13-as-my-linux-laptop/","tags":["Lenovo","ThinkPad Z13","Ubuntu","NixOS","GNOME","AMD","Ryzen 7 PRO 6850U","Radeon 680M","Apple","M1"],"title":"Why I chose the ThinkPad Z13 Gen1 as my Linux laptop"},{"categories":["Linux","Development","Open Source"],"contents":"machinespawn is a wrapper for machinectl and systemd-nspawn to creating and managing containers; primarily focused at local development environment and CI/CD with a heavy emphasis on caching.\nOrganisation: machinespawn Date: October 2022 - date Role: Project Lead ","permalink":"https://wimpysworld.com/projects/machinespawn/","tags":["Bash","systemd","Containers","Virtualization","Ubuntu","Debian","CI","CD"],"title":"machinespawn"},{"categories":["Linux","Broadcasting","Open Source","Content Creation"],"contents":"Open source professionals Martin Wimpress, Hayden Barnes, Gary Kramlich, and Alan Pope join Joe Ressington for relaxed discussions in their downtime. From working in the industry and progressing your career, to managing a project\u0026rsquo;s community, and beyond.\nOrganisation: Linux Downtime Date: April 2022 - date Role: Co-presenter \u0026amp; Producer ","permalink":"https://wimpysworld.com/projects/linux-downtime/","tags":["Podcast","Community"],"title":"Linux Downtime"},{"categories":["Linux","Development","Open Source"],"contents":"deb-get makes it easy to install and update .debs published in 3rd party apt repositories or made available via direct download on websites or GitHub release pages.\nOrganisation: deb-get Date: April 2022 - date Role: Project Lead ","permalink":"https://wimpysworld.com/projects/deb-get/","tags":["Bash","Ubuntu","Debian","GitHub","dpkg","apt"],"title":"deb-get"},{"categories":["Linux","Development","Tutorial","Cloud Native"],"contents":"Creating production-ready containers for use in commercial-grade apps can be a far cry from the \u0026ldquo;get started with Node.js and Docker\u0026rdquo;-type of tutorials that are common around the Internet. Those guides are great for introducing all the advantages of Docker containers in modern cloud-native development, but creating a container that passes muster in a large-scale application in production is a different story.\nFor production-ready containers, there are three key things you want to optimise for when creating a container:\nImage Size üì¶ Build Speed üê¢ Security üîê Image size and build speed ensure that your containers can move through CI/CD and test pipelines easily and efficiently. Security is obviously critical in today\u0026rsquo;s software supply chain, and containers have their own set of security issues. Thankfully, reducing container image size actually can alleviate some security issues in containers.\nIn my Basics article, I showed you some easy techniques to improve your Dockerfile using a sample \u0026ldquo;Hello World\u0026rdquo; Node.js application.\nThese basics address all three optimisations, though they only scratch the surface.\nLet\u0026rsquo;s look at some more advanced techniques for Container Optimisation.\nAlpine Images The very first thing you\u0026rsquo;ll encounter when looking for techniques to create smaller containers is Alpine Linux. Alpine Linux is an open source project whose goal is to create a bare-bones ü¶¥ version of Linux that lets developers \u0026ldquo;build from the ground up.\u0026rdquo;\nPros: Transitioning to Alpine can be an easy way to get a smaller container Reducing image size with Alpine can be incredibly simple - under the right circumstances. For some apps, it\u0026rsquo;s as easy as changing the base image in your Dockerfile:\nFROM FROM node:16.2.0 TO FROM node:16.2.0-alpine When we build the new image, we see that the old image was 856MB and the new one is 114MB üéâ\nREPOSITORY TAG IMAGE ID CREATED SIZE cotw-node-alpine latest 2cc7b4a7b09c 2 minutes ago 114MB cotw-node latest 873fb9fca53a 3 days ago 856MB Easy, right? Not so fast.\nCons: Using Alpine images can lead to build problems, now and in the future There are some not so obvious gotchas with using Alpine images that don\u0026rsquo;t crop up in our super simple example application, such as:\nYou have to install everything Those tiny base images have to sacrifice something, right? Alpine users will be installing everything they need, right down to time-zone data or development tools. You won\u0026rsquo;t need your development tools for your production image, most likely, but for most developers, the thought of a server without curl or vim is a bridge too far.\nDifferent compilers and package managers You\u0026rsquo;ll also be installing any dependencies with the Alpine Package Keeper tool (apk) instead of the more familiar apt or rpm. The differences are small, but can trip up unsuspecting developers.\nFewer examples; less documentation Finally, while Alpine has been around for nine-plus years, it is and likely always will be a smaller and more specialised user base than established Linux distributions such as Ubuntu and Debian. To wit, at the time of this writing the alpine tag on StackOverflow has just 1,280 questions, compared with over 54,000 for Ubuntu.\nMulti-stage builds The next tactic you are likely to encounter when searching for ways to reduce Docker image sizes is multi-stage üèó builds. This tactic, recommended by Docker and many in the Docker community, is essentially building the image twice. The first set of commands builds your base application image, all things included. The second set of commands builds an image off of that base image, taking only what\u0026rsquo;s needed and leaving out anything that\u0026rsquo;s not.\nWith a multi-stage build, our Dockerfile would look like this. Notice the two FROM statements. The first builds the application image; the second copies the necessary files from that image into the second, more production-ready version.\nFROM node:16.2.0-alpine as builder WORKDIR /usr/src/app COPY package*.json ./ RUN npm ci COPY app.js ./ FROM node:16.2.0-alpine WORKDIR /usr/src/app COPY --from=builder /usr/src/app . EXPOSE 3000 USER node CMD [\u0026#34;node\u0026#34;,\u0026#34;app.js\u0026#34;] Pros: Dev and Prod images can be built separately When combined with Docker Compose, this approach gives developers a flexible development environment while reducing bloat in the production images. You can simply use your initial image for dev/test and the final version for productions. Multi-stage builds work especially well for Go containers, significantly reducing image size, but also work well for static Node.js and React-type applications.\nCons: Added complexity; use-case specific Multi-stage builds are still relatively new üå± on the scene. For most developers still new to containers, knowing what to copy over to the final production image and what to leave behind is a major barrier to entry. Further, this pattern can run into challenges.\nSince we\u0026rsquo;re already using an Alpine image, the size savings are relatively minor for our \u0026ldquo;Hello World\u0026rdquo; example. You\u0026rsquo;d expect to see greater gains in a full-blown React or Vue application.\nREPOSITORY TAG IMAGE ID CREATED SIZE cotw-node-multistage latest 52bc33d14a87 3 minutes ago 114MB cotw-node-alpine latest 2cc7b4a7b09c 4 days ago 114MB cotw-node latest 873fb9fca53a 7 days ago 856MB Development tools and Distroless There are several tools - and new ones emerging every day - that look to bypass or automate Dockerfile authoring to make image creation easier. Buildpacks are the most mature of these technologies, and can be used through tools like Pack or Waypoint.\nThere are builder options from multiple sources - Heroku, Google, and Paketo are common favourites - and each gives you a slightly different developer experience and final image when used.\n$ pack build cotw-node-bp-google --builder gcr.io/buildpacks/builder:v1 $ pack build cotw-node-bp-heroku --builder heroku/buildpacks:18 $ pack build cotw-node-bp-pb-base --builder paketobuildpacks/builder:base $ pack build cotw-node-bp-pb-full --builder paketobuildpacks/builder:full Pros: When they work, they work In certain instances, Buildpacks can take the pain out of Dockerfile authoring and just create container images of your application with no fuss. The pack tool is looking for \u0026ldquo;app-like\u0026rdquo; files in your source directory, and automatically figuring out what kind of application is there and how to containerize it. In the case of our Node sample, it sees package.json and correctly assumes we have a Node.js application.\nCons: When they don\u0026rsquo;t‚Ä¶ Given the relative newness of this approach for Docker containers, there are a lot of gotchas with Buildpacks. Non-standard applications or operating systems can struggle, and we\u0026rsquo;ve had issues running them successfully on the new Silicon Macbook Pros. The resulting images vary a lot - we saw a range of 200MB to 800MB in our examples - and the results tend to be lower than what you\u0026rsquo;d get with other techniques.\nAutomate it with DockerSlim The DockerSlim open source project was created by Slim.AI CTO Kyle Quest in 2015 as a way to automate container optimisation.\nSimply download and run docker-slim build \u0026lt;myimage\u0026gt; and DockerSlim will examine the image, rebuild it with only the required dependencies, and give you a new image that can be run just like the original.\nPros: It\u0026rsquo;s automatic DockerSlim means you can work with whatever base image you\u0026rsquo;d like (say, Ubuntu or Debian) and let DockerSlim worry about removing unnecessary tools and files en route to production. The best part is that DockerSlim can be used alongside any of these other techniques. Once tested, it can be integrated into your CI/CD pipeline for automatic container minification, and the reduction in size leads to faster build times and better security.\nCons: Steep learning curve As with any open-source software, DockerSlim can take some time to get working, especially for non-trivial applications. It works best for web-style applications, micro-services and APIs that have defined HTTP/HTTPS ports which the sensor can find and use to observe the container internals.\nFor best results, spend some time getting to know the various command flags available to tune your image, and take a look at the examples for whatever framework you\u0026rsquo;re using.\nConnecting with DockerSlim There\u0026rsquo;s an active DockerSlim Discord channel full of experts who can help you triage issues as they arise.\n","permalink":"https://wimpysworld.com/posts/creating-production-ready-containers-advanced-techniques/","tags":["Docker","DevOps","docker-slim","Alpine","Docker Compose","Distroless","Buildpacks","Multi-Stage Builds"],"title":"Creating Production-Ready Containers - Advanced Techniques"},{"categories":["Linux","Development","Tutorial","Cloud Native"],"contents":"So you\u0026rsquo;ve coded an awesome app and you are ready to deploy it to the cloud. You\u0026rsquo;ve heard a lot about Docker and completed a few online tutorials to containerise your app. All set, right? But what do you need to know if you\u0026rsquo;re going to move that app to a production environment on the public Internet? What if you\u0026rsquo;re using it for your job and need to pass security scans and DevOps checks?\nIn this series, I introduce some basic concepts for making production ready containers. I also introduce the concept of \u0026ldquo;slimming\u0026rdquo; a container. Slimming refers to both optimising and minifying your Docker containers, reducing them in size by up to 80-percent while also making them more secure by decreasing the attack surface. Slimming your container is also a great way to implement container best practices without re-engineering your entire workflow.\nThere are many ways to slim a container, from basic security to fully automated open-source tools like DockerSlim. Full disclosure: I work for Slim.AI, a company founded on the DockerSlim open source project. Let\u0026rsquo;s look at some of the common ways developers create production-ready container images today.\nI\u0026rsquo;ll explore each of these in a separate article using a simple \u0026ldquo;Hello World\u0026rdquo; Node.js example that can be found in a number of online tutorials.\nconst express = require(\u0026#39;express\u0026#39;) const app = express() const port = 3000 app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.send(\u0026#39;Hello World!\u0026#39;) }) app.listen(port, () =\u0026gt; { console.log(`Example app listening at http://localhost:${port}`) }) Let\u0026rsquo;s get started by simply improving your Dockerfile to build a better Docker image.\nCreating a Better Dockerfile Most Dockerfile examples you\u0026rsquo;ll find are not \u0026ldquo;production ready\u0026rdquo; and they aren\u0026rsquo;t meant to be. They are for instructional purposes to help developers successfully build an image. But when one gets into production scenarios, there are a number of \u0026ldquo;good-to-know\u0026rdquo; and a few \u0026ldquo;have-to-know\u0026rdquo; techniques that will improve build times, security, and reliability.\nLet\u0026rsquo;s look at a typical example that you might run into if you\u0026rsquo;re a Node.js developer looking to get \u0026ldquo;Hello World\u0026rdquo; running with Docker. I won\u0026rsquo;t go through building an actual app - there are a lot of great examples out there to show you how to do this - but rather focus on what to do if you were actually going to ship this to production.\nThe typical Dockerfile in a \u0026ldquo;Hello World\u0026rdquo; example might look something like this:\nFROM node:latest WORKDIR /usr/src/app COPY package*.json app.js ./ RUN npm install EXPOSE 3000 CMD [\u0026#34;node\u0026#34;, \u0026#34;app.js\u0026#34;] It uses the latest version of the official Node.js image, sets a directory and copies your app into the container image, installs dependencies, exposes port 3000, and runs the app via CMD.\nWhile this will run no problem on your local machine, and is great for learning the ropes, this approach is almost certainly going to run into issues when you ship it to production. Let\u0026rsquo;s take a look at some of these in order of severity.\nMajor issues Running as Root Since this example doesn\u0026rsquo;t set a USER explicitly in the Dockerfile, Docker runs the build and all commands as the root user. While not an issue for local development, your friendly neighbourhood SysAdmin will tell you the myriad of issues that come with running applications as root on a server in production. And with Docker, a new set of attack methods can arise.\nThankfully, most major languages and frameworks have a predefined user for running applications. In Node.js, the user is just node and can be invoked in the Dockerfile explicitly.\nFROM node:latest WORKDIR /usr/src/app COPY package*.json app.js ./ RUN npm install USER node EXPOSE 3000 CMD [\u0026#34;node\u0026#34;, \u0026#34;app.js\u0026#34;] Using latest version Choosing a version number for your container is often called pinning. While many tutorials - and even some experts - will counsel newcomers to pin their images to the latest tag, which means you get whatever the most recently updated version is, using the latest tag can cause issues in production.\nContainers are meant to be ephemeral, meaning they can be created, destroyed, started, stopped, and reproduced with ease and reliability. Using the latest tag means there isn\u0026rsquo;t a single source of truth for your container\u0026rsquo;s \u0026ldquo;bill of materials\u0026rdquo;. A new version or update of a dependency could introduce a breaking change, which may cause the build to fail somewhere in your CI/CD pipeline.\nExample Dockerfile\nFROM node:latest Production Dockerfile\nFROM node:16.2.0 Other tutorials I\u0026rsquo;ve seen pin only the major version. For example, using node:14. This carries the same risks as using latest, as minor versions can change dependencies as well.\nNow, pinning a specific major and minor version in your Dockerfile is a trade-off decision - you\u0026rsquo;re choosing to not automatically receive security, fixes or performance improvements that come via new updates - but most DevSecOps teams prefer to employ security scanning and container management software as a way to control updates rather than dealing with the unpredictability that comes with container build failures in production CI/CD pipelines.\nPerformance improvements Better layer caching Docker works on the concept of layer caching. It builds images sequentially. Layering dependencies on top of each other and only rebuilding them when something in the layer has changed.\nLayer 0 in a Docker image is often the base operating system, which rarely change significantly; although commercial Linux vendors often publish new base images to incorporate security fixes.\nApplication code, however, is highly likely to change during the software development cycle, as you iterate on features, refactor, and fix bugs. Dependencies in our core system, installed here by npm install, change more often than the base OS, but less often than the application code.\nIn our example Dockerfile, we simply need to break the installation of the dependencies into separate instructions on their own lines.\nFROM node:16.0.2 WORKDIR /usr/src/app COPY package*.json ./ RUN npm ci USER node COPY app.js ./ EXPOSE 3000 CMD [\u0026#34;node\u0026#34;, \u0026#34;app.js\u0026#34;] We actually end up creating another layer by now having two COPY commands. While adding layers is typically a no-no for build times and image sizes, the tax we pay on this optimisation is going to save us in the long run as we cycle through the QA process, since we aren\u0026rsquo;t reinstalling dependencies if we don‚Äôt have to.\nWe also opt for the npm ci command instead of npm install, which is preferred for automated environments, such as CI/CD, and will help prevent breaking changes from dependencies. Read more about npm ci here.\nUse ENTRYPOINT instead of CMD At a surface level, there isn\u0026rsquo;t a big difference between using ENTRYPOINT with your app file versus running CMD using the shell plus your app file. However, web- and API-type containers like Node.js applications are often running as executables in production, and there, proper signal handling - such as graceful shutdowns - are important.\nCMD provides some flexibility for calling executables with flags or overwriting them, which is common in development. But that generally won\u0026rsquo;t be relevant to production instances and ENTRYPOINT will likely provide better signal processing.\nFROM node:16.0.2 WORKDIR /usr/src/app COPY package*.json ./ RUN npm ci USER node COPY app.js ./ EXPOSE 3000 ENTRYPOINT [\u0026#34;node\u0026#34;, \u0026#34;app.js\u0026#34;] Cleaning up cached files Most package managers have the ability to clean up their own cache. If you don‚Äôt do this, you\u0026rsquo;ll just be moving a bunch of unused files into your container for no reason. It might not save a lot of space depending on your application, but think of it as dropping your unused items at the charity shop before you move rather than loading them in the moving van. It\u0026rsquo;s not a lot of effort and it\u0026rsquo;s the right thing to do. We do this by adding \u0026amp;\u0026amp; npm cache clean --force to our RUN instruction.\nFROM node:16.0.2 WORKDIR /usr/src/app COPY package*.json ./ RUN npm ci \u0026amp;\u0026amp; npm cache clean --force USER node COPY app.js ./ EXPOSE 3000 ENTRYPOINT [\u0026#34;node\u0026#34;, \u0026#34;app.js\u0026#34;] Conclusions Improving your Dockerfile is the first step towards creating a slimmed and optimised container. It closes some major security loopholes that are likely to raise flags with downstream checks and adds baseline optimisations for build time and docker image size.\nIf this is all you do to improve your containers prior to shipping to production, you won\u0026rsquo;t be in a bad spot, but there\u0026rsquo;s definitely more - way more - that you can do to optimise images. We\u0026rsquo;ll explore those techniques in the next article.\n","permalink":"https://wimpysworld.com/posts/creating-production-ready-containers-the-basics/","tags":["Docker","Node","DevOps","Dockerfile","docker-slim"],"title":"Creating Production-Ready Containers - The Basics"},{"categories":["Linux","Development","Open Source","Retro","Entertainment"],"contents":"Retro Home is custom Raspberry Pi operating system purpose built for retro gaming. Built with Ubuntu and using the minimalist emulator frontend Ludo it supports most classic consoles from Atari, Nintendo, Sega and SNK along with arcade emulation support. A number of retro styled Raspberry Pi cases from Retroflag and Waveshare are supported (with more in the works) using bespoke GPIO drivers.\nOrganisation: Retro Home Date: July 2020 - date Role: Project Lead ","permalink":"https://wimpysworld.com/projects/retro-home/","tags":["Raspberry Pi","GPIO","Gaming","Ludo","Ubuntu","Bash","Python","GNOME","libretro","debootstrap","Emulation"],"title":"Retro Home"},{"categories":["Linux","Development","Open Source"],"contents":"Simple shell script to convert Ubuntu into a \u0026ldquo;rolling release\u0026rdquo; that tracks the devel series; for the toughest of Ubuntu users.\nThis project has served its purpose. It inspired another group of developers to create a fully fledged Ubuntu Rolling Rhino distro.\nOrganisation: Rolling Rhino Date: March 2020 - November 2022 Role: Project Lead ","permalink":"https://wimpysworld.com/projects/rolling-rhino/","tags":["Bash","Ubuntu","apt"],"title":"Rolling Rhino"},{"categories":["Linux","Development","Open Source"],"contents":"Quickly create and run highly optimised desktop virtual machines for Linux, macOS and Windows; with just two commands. You decide what operating system you want to run and Quickemu will figure out the best way to do it for you\nOrganisation: Quickemu Project Date: March 2020 - date Role: Project Lead ","permalink":"https://wimpysworld.com/projects/quickemu/","tags":["Bash","QEMU","Windows","macOS","Virtualisation","SPICE","VirtIO","VirGL","Hyper-V","KVM"],"title":"Quickemu"},{"categories":["Linux","Retro","Entertainment","Computer Hardware"],"contents":"Inspired by the recent NES Classic I made a DIY SNES Classic just in time for the Christmas holidays and it\u0026rsquo;s very portable!\nRaspberry Pi 3 in a 3D printed SNES case with 8Bitdo SNES30 controllers To make one yourself you\u0026rsquo;ll need:\nRaspberry Pi 3 Model B. Retropie 4.1 or newer. Two 8Bitdo SNES30 wireless controllers. A SNES 3D Printed case. CRT scanline shaders to complete the retro look on the big screen. Both controllers use Bluetooth, so two player wire-free gaming is possible. The USB cables are just for charging, but if you\u0026rsquo;ve got no charge they can be used as wired controllers too. Retropie can be controlled via the controllers, no keyboard/mouse required.\n","permalink":"https://wimpysworld.com/posts/diy-snes-classic/","tags":["Retropie","SNES","Raspberry Pi","8Bitdo","Nintendo"],"title":"DIY SNES Classic"},{"categories":["Linux","Open Source","Self Hosting","Tutorial"],"contents":"I recently bought the Nextcloud Box. When it came to setting it up I ran into a problem, I only had Raspberry Pi 3 computers available and at the time of writing the microSDHC card provided with the Nextcloud Box only supports the Raspberry Pi 2. Bummer!\nOverview This guide outlines how to use Ubuntu Core on the Raspberry Pi 3 to run Nextcloud provided as a snap from the Ubuntu store.\nIf you\u0026rsquo;re not familiar with Ubuntu Core, here\u0026rsquo;s a quote:\nUbuntu Core is a tiny, transactional version of Ubuntu for IoT devices and large container deployments. It runs a new breed of super-secure, remotely upgradeable Linux app packages known as snaps\nAfter following this guide Ubuntu Core and any installed snaps (and their data) will reside on the SD card and the 1TB hard disk in the Nextcloud box will be available for file storage. This guide explains how to:\nInstall and configure Ubuntu Core 16 for the Raspberry Pi 3 Format the 1TB hard disk in the Nextcloud Box and auto-mount it Install the Nextcloud snap and connect the removable-media interface to allow access to the hard disk Activate and configure the Nextcloud External Storage app so the hard disk can be used to store files Optional configuration of Email and HTTPS for Nextcloud Prepare a microSDHC card I explained the main steps in this post but you really should read and follow the Get started with a Raspberry Pi 2 or 3 page as it fully explains how to use a desktop computer to download an Ubuntu Core image for your Raspberry Pi 2 or 3 and copy it to an SD card ready to boot.\nHere\u0026rsquo;s how to create an Ubuntu Core microSDHC card for the Raspberry Pi 3 using an Ubuntu desktop:\nDownload Ubuntu Core 16 image for Raspberry Pi 3 Insert the microSDHC card into your PC Use GNOME Disks and its Restore Disk Image\u0026hellip; option, which natively supports XZ compressed images. Select your SD card from the panel on the left Click the \u0026ldquo;burger menu\u0026rdquo; on the right and Select Restore Disk Image\u0026hellip; Making sure the SD card is still selected, click the Power icon on the right. Eject the SD card physically from your PC. Ubuntu Core first boot An Ubuntu SSO account is required to setup the first user on Ubuntu Core:\nStart by creating an Ubuntu SSO account Import an SSH Key into your Ubuntu SSO account Here are instructions to generate an SSH Key You\u0026rsquo;ll need a keyboard and monitor connected to the Raspberry Pi 3 to go complete the first boot process and device configuration. Insert the Ubuntu Core microSHDC into the Raspberry Pi, which should be in the assembled Nextcloud Box with a keyboard and monitor connected. Plug in the power.\nThe system will boot then become ready to configure The device will display the prompt \u0026ldquo;Press enter to configure\u0026rdquo; Press enter then select \u0026ldquo;Start\u0026rdquo; to begin configuring your network and an administrator account. Follow the instructions on the screen, you will be asked to configure your network and enter your Ubuntu SSO credentials At the end of the process, you will see your credentials to access your Ubuntu Core machine: This device is registered to \u0026lt;Ubuntu SSO email address\u0026gt;. Remote access was enabled via authentication with the SSO user \u0026lt;Ubuntu SSO user name\u0026gt; Public SSH keys were added to the device for remote access. Login Once setup is done, you can login to Ubuntu Core using ssh, from a computer on the same network, using the following command:\nssh \u0026lt;Ubuntu SSO user name\u0026gt;@\u0026lt;device IP address\u0026gt; The user name is your Ubuntu SSO user name.\nReconfiguring network Should you need to reconfigure the network at a later stage you can do so with:\nsudo console-conf Prepare 1TB hard disk Log in to your Raspberry Pi 3 running Ubuntu Core via ssh.\nssh \u0026lt;Ubuntu SSO user name\u0026gt;@\u0026lt;device IP address\u0026gt; Partition and format the Nextcloud Box hard disk This will create a single partition formatted with the ext4 filesystem.\nsudo fdisk /dev/sda Do the following to create the partition:\nCommand (m for help): o Created a new DOS disklabel with disk identifier 0x253fea38. Command (m for help): n Partition type p primary (0 primary, 0 extended, 4 free) e extended (container for logical partitions) Select (default p): p Partition number (1-4, default 1): 1 First sector (2048-1953458175, default 2048): Last sector, +sectors or +size{K,M,G,T,P} (2048-1953458175, default 1953458175): Created a new partition 1 of type \u0026#39;Linux\u0026#39; and of size 931.5 GiB. Command (m for help): w Now format the partition and give it the label data. This label will be used to reference it for mounting later:\nsudo mkfs.ext4 -L data /dev/sda1 Automatically mount the partition Most of the Ubuntu Core root file system is read-only, so it is not possible to edit /etc/fstab. Therefore we\u0026rsquo;ll use systemd to achieve that.\nBe aware of one of the systemd.mount pitfalls:\nMount units must be named after the mount point directories they control. Example: the mount point /home/lennart must be configured in a unit file home-lennart.mount.\nYes that\u0026rsquo;s right! The unit filename must match the mount point path.\nCreate the media-data.mount unit:\nsudo vi /writable/system-data/etc/systemd/system/media-data.mount Add the following content:\n[Unit] Description=Mount unit for data [Mount] What=/dev/disk/by-label/data Where=/media/data Type=ext4 [Install] WantedBy=multi-user.target Reload systemd, scanning for new or changed units:\nsudo systemctl daemon-reload Start the media-data.mount unit, which will mount the volume, and also enable it so it will be automatically mounted on boot.\nsudo systemctl start media-data.mount sudo systemctl enable media-data.mount And just like any other unit, you can view its status using systemctl status:\nsudo systemctl status media-data.mount Update Ubuntu Core Make sure Ubuntu Core is up-to-date and reboot.\nsudo snap refresh sudo reboot After the reboot, make sure /media/data is mounted. If not double check the steps above.\nInstall Nextcloud The Nextcloud snap uses the removable-media interface, which grants access to /media/*, and requires manual connection:\nsudo snap install nextcloud sudo snap connect nextcloud:removable-media core:removable-media Browse to the Nextcloud IP address and create the admin user account, for example:\nhttp://nextcloud.local/ Nextcloud configuration In the examples below replace nextcloud.local with the IP address or hostname of your Nextcloud Box and replace example.org with your domain.\nExternal Storage Enable the External Storge app via:\nhttp://nextcloud.local/index.php/settings/apps?category=disabled# Configure External Storage app via:\nhttp://nextcloud.local/index.php/settings/admin/externalstorages Use these settings:\nFolder name: data External storage: Local Authentication: None Configuration: /media/data Available for: All Email Configure your outgoing email settings via:\nhttp://nextcloud.local/index.php/settings/admin/additional I use Sendgrid for sending email alerts from my servers and devices. These are the settings that work for me:\nSend mode: SMTP Encryption: STARTTLS From address: nextcloud@example.org Authentication method: Plain Authentication required: Yes Server address: smtp.sendgrid.net:587 Username: apikey Password: theactualapikey Enabling HTTPS It is strongly recommend that you use HTTPS if you intend to expose your Nextcloud to the Internet.\nFirst do a test to see if you can install a Let\u0026rsquo;s Encrypt certificate:\nsudo nextcloud.enable-https -d Answer the questions:\nHave you met these requirements? (y/n) y Please enter an email address (for urgent notices or key recovery): name@example.org Please enter your domain name(s) (space-separated): nextcloud.example.org Attempting to obtain certificates... done Looks like you\u0026#39;re ready for HTTPS! If everything went well, then install the certificate\nsudo nextcloud.enable-https Answer the questions again:\nHave you met these requirements? (y/n) y Please enter an email address (for urgent notices or key recovery): name@example.org Please enter your domain name(s) (space-separated): nextcloud.example.org Attempting to obtain certificates... done Restarting apache... done If Let\u0026rsquo;s Encrypt didn\u0026rsquo;t work for you, you can always use Nextcloud with a self-signed certificate.\nsudo nextcloud.enable-https -s Manual configuration changes If you need to make any tweaks to the Nextcloud configuration file you can edit it like so:\nsudo vi /var/snap/nextcloud/current/nextcloud/config/config.php If you have manually edited the Nextcloud configuration you may need to restart nextcloud:\nsudo snap disable nextcloud sudo snap enable nextcloud Conclusion So there it is, Nextcloud running on Ubuntu Core powered by a Raspberry Pi 3. The performance is reasonable, obviously not stellar, but certainly good enough to move some cloud services for a small family away from the likes of Google and Dropbox. Now go and install some Nextcloud clients for your desktops and devices :-)\n","permalink":"https://wimpysworld.com/posts/raspberry-pi-3-nextcloud-box-running-on-ubuntu-core/","tags":["Ubuntu","Raspberry Pi","Nextcloud","Ubuntu Core"],"title":"Raspberry Pi 3 Nextcloud Box running on Ubuntu Core"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"I\u0026rsquo;ve installed Open Media Vault on a HP ProLiant MicroServer G7 N54L and use it as media server for the house. OpenMediaVault (OMV) is a network attached storage (NAS) solution based on Debian.\nI want to minimise power consumption but maximise performance. Here are some tweaks reduce power consumption and improve network performance.\nPower Saving Install the following.\napt-get install amd64-microcode firmware-linux firmware-linux-free \\ firmware-linux-nonfree pciutils powertop radeontool And for ACPI.\napt-get install acpi acpid acpi-support acpi-support-base ASPM and ACPI First I enabled PCIE ASPM in the BIOS and forced the kernel to use it and ACPI via grub by changing GRUB_CMDLINE_LINUX_DEFAULT in /etc/default/grub, so it looks like this:\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026#34;quiet acpi=force pcie_aspm=force nmi_watchdog=0\u0026#34; Then update grub and reboot.\nupdate-grub reboot Enable Power Saving via udev The following rules file /etc/udev/rules.d/90-local-n54l.rules enables power saving modes for all PCI, SCSI and USB devices and ASPM. Futher the internal Radeon card power profile is set to low as there is rarely a monitor connected. The file contains the following:\nSUBSYSTEM==\u0026#34;module\u0026#34;, KERNEL==\u0026#34;pcie_aspm\u0026#34;, ACTION==\u0026#34;add\u0026#34;, TEST==\u0026#34;parameters/policy\u0026#34;, ATTR{parameters/policy}=\u0026#34;powersave\u0026#34; SUBSYSTEM==\u0026#34;i2c\u0026#34;, ACTION==\u0026#34;add\u0026#34;, TEST==\u0026#34;power/control\u0026#34;, ATTR{power/control}=\u0026#34;auto\u0026#34; SUBSYSTEM==\u0026#34;pci\u0026#34;, ACTION==\u0026#34;add\u0026#34;, TEST==\u0026#34;power/control\u0026#34;, ATTR{power/control}=\u0026#34;auto\u0026#34; SUBSYSTEM==\u0026#34;usb\u0026#34;, ACTION==\u0026#34;add\u0026#34;, TEST==\u0026#34;power/control\u0026#34;, ATTR{power/control}=\u0026#34;auto\u0026#34; SUBSYSTEM==\u0026#34;usb\u0026#34;, ACTION==\u0026#34;add\u0026#34;, TEST==\u0026#34;power/autosuspend\u0026#34;, ATTR{power/autosuspend}=\u0026#34;2\u0026#34; SUBSYSTEM==\u0026#34;scsi\u0026#34;, ACTION==\u0026#34;add\u0026#34;, TEST==\u0026#34;power/control\u0026#34;, ATTR{power/control}=\u0026#34;auto\u0026#34; SUBSYSTEM==\u0026#34;spi\u0026#34;, ACTION==\u0026#34;add\u0026#34;, TEST==\u0026#34;power/control\u0026#34;, ATTR{power/control}=\u0026#34;auto\u0026#34; SUBSYSTEM==\u0026#34;drm\u0026#34;, KERNEL==\u0026#34;card*\u0026#34;, ACTION==\u0026#34;add\u0026#34;, DRIVERS==\u0026#34;radeon\u0026#34;, TEST==\u0026#34;power/control\u0026#34;, TEST==\u0026#34;device/power_method\u0026#34;, ATTR{device/power_method}=\u0026#34;profile\u0026#34;, ATTR{device/power_profile}=\u0026#34;low\u0026#34; SUBSYSTEM==\u0026#34;scsi_host\u0026#34;, KERNEL==\u0026#34;host*\u0026#34;, ACTION==\u0026#34;add\u0026#34;, TEST==\u0026#34;link_power_management_policy\u0026#34;, ATTR{link_power_management_policy}=\u0026#34;min_power\u0026#34; Add this to /erc/rc.local.\necho \u0026#39;1500\u0026#39; \u0026gt; \u0026#39;/proc/sys/vm/dirty_writeback_centisecs\u0026#39; Hard disk spindown Using the Open Media Vault web interface got to Storage -\u0026gt; Physical Disks, select each disk in turn and click Edit then set:\nAdvanced Power Management: Intermediate power usage with standby Automatic Acoustic Management: Minimum performance, Minimum acoustic output Spindown time: 20 minutes Performance Tuning Network The following tweaks improve network performance ,but I have a HP NC360T PCI Express Dual Port Gigabit Server Adapter in my N54L so these settings may not be applicable to the onboard NIC.\nAdd this to /erc/rc.local.\nethtool -G eth0 rx 4096 ethtool -G eth1 rx 4096 ethtool -G eth0 tx 4096 ethtool -G eth1 tx 4096 ifconfig eth0 txqueuelen 1000 ifconfig eth1 txqueuelen 1000 Add the following to /etc/sysctl.d/local.conf.\nfs.file-max = 100000 net.core.netdev_max_backlog = 50000 net.core.optmem_max = 40960 net.core.rmem_default = 16777216 net.core.rmem_max = 16777216 net.core.wmem_default = 16777216 net.core.wmem_max = 16777216 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.all.accept_source_route = 0 net.ipv4.conf.all.log_martians = 1 net.ipv4.conf.all.send_redirects = 0 net.ipv4.ip_local_port_range = 10000 65000 net.ipv4.tcp_fin_timeout = 10 net.ipv4.tcp_max_syn_backlog = 30000 net.ipv4.tcp_max_tw_buckets = 2000000 net.ipv4.tcp_rfc1337 = 1 net.ipv4.tcp_rmem = 4096 87380 16777216 net.ipv4.tcp_sack=0 net.ipv4.tcp_slow_start_after_idle = 0 net.ipv4.tcp_timestamps=0 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_wmem = 4096 65536 16777216 net.ipv4.udp_rmem_min = 8192 net.ipv4.udp_wmem_min = 8192 vm.swappiness = 10 Conclusion With these settings applied powertop reports everything that can be in a power saving mode is and the room temperature is measurably cooler. More importantly, with four 4TB drives in a RAID-5 configuration formatted with XFS and dual bonded gigabit ethernet, I am able to backup data to the server at a sustained rate of 105MB/s, which is 0.85 Gbit.\nNot too shabby for an AMD Turion II Neo N54L (2.2GHz) üôÇ\nReferences http://www.wgdd.de/2013/08/hp-n54l-microserver-energy-efficiency.html?m=1 http://gareth.halfacree.co.uk/2014/02/tuning-an-hp-proliant-microserver http://www.scottalanmiller.com/linux/2011/06/20/working-with-nic-ring-buffers/ https://gist.github.com/dstroot/2785263 ","permalink":"https://wimpysworld.com/posts/hp-microserver-n54l-power-saving-and-performance-tuning-using-debian/","tags":["Linux","Debian","HP MicroServer","N54L","powertop","udev","ethtool","AMD Turion II Neo"],"title":"HP Microserver N54L power saving and performance tuning using Debian"},{"categories":["Linux","Open Source","Computer Hardware"],"contents":"I\u0026rsquo;ve just bought my first brand new computer since 2008. Thanks to the Black Friday and Cyber Monday sales on Amazon.co.uk and Scan.co.uk this year I was able to put together a pretty sweet Intel NUC which is now running Ubuntu MATE 15.10.\nI spoke about this new system on LINUX Unplugged Episode 122 and have been contacted by people wanting more details. Hopefully this blog post will answer any outstanding questions. Press play below to hear to what I said on the podcast.\nThe NUC I purchased an Intel Next Unit of Computing (NUC) Kit NUC5I7RYH.\nBarebones mini PC 1 x Core i7 5557U / 3.1 GHz Iris Graphics 6100 Gigabit Ethernet Bluetooth 4.0 LE 802.11a/b/g/n/ac WiFi Everything works out of the box with Ubuntu MATE 15.10 including sending audio to the monitor over HDMI and DisplayPort.\nThe RAM The Core i7 5557U specs state that DDR3L 1866 Mhz RAM is supported. The arstechnica Mini-review: Intel‚Äôs powered-up Core i7 Broadwell mini PC has some benchmarks that show a performance improvement when using 1866 Mhz clocked RAM, so I purchased:\nHyperX Impact SODIMM - 16GB Kit*(2x8GB) - DDR3L 1866MHz CL11 SODIMM The SSDs I have two SSDs in the NUC.\nSamsung MZVPV256HDGL-00000 - SM951 256GB M.2 PCI-e 3.0 x 4 NVMe Solid State Drive SanDisk Ultra II SSD 960 GB Sata III 2.5-inch Internal SSD This is where you might need to do some more research. At the time of writing, it is not possible to boot directly from the Samsung SM951 NVMe SSD. Although other quad channel NVMe SSDs do appear to be supported as the boot device. It is possible that the Samsung SSD 950 Pro, which is also NVMe, can be used as the boot device in Linux, but don\u0026rsquo;t take my word for it. Do your research.\nMy work around was make the SanDisk Ultra II the boot device by putting /boot and the MBR on it. I have put / and swap (swap because I want to experiment with suspend and hibernate) are on the Samsung SM951 and /home is on the SanDisk Ultra II.\nThere are faster SSDs than the SanDisk Ultra II but this was 50% off during Black Friday and just too good a deal to pass by. I did sacrifice a little performance on this component, so if absolute performance is your goal look at alternative SSDs, the Samsung 850 EVO seems to benchmark favourably.\nThe Monitor A week after I purchased the NUC I noticed ebuyer.com were selling the monitor I wanted with a ¬£100 discount. So I snapped one up.\nSamsung S27D850T 27\u0026quot; WQHD LED DVI HDMI Monitor The NUC is connected via mini Display Port and my Dell Precision T7400 is connected via HDMI. The Samsung S27D850T has an audio out and a 2.1 speaker set is connected to it.\nConclusion I\u0026rsquo;m extremely happy with the NUC5I7RYH. Linux compatibility is first class, it\u0026rsquo;s fast and has relatively low power consumption. You can even charge a mobile phone using one of the front USB ports (the yellow one) when the NUC is powered off. It is my principle workstation and is able to handle everything I demand from it, with ease:\nmp3 and ogg audio encoding h.264 video encoding (~1 min of video @480p encodes in 1 second) running multiple virtual machines compiling large applications creating xz compressed images of Ubuntu flavours for the Raspberry Pi 2 I\u0026rsquo;ve not tried gaming on it yet, but the holidays are approaching and GRID Autosport was released for SteamOS this week. So I know what I\u0026rsquo;ll be doing in a couple of weeks time :-D\n","permalink":"https://wimpysworld.com/posts/intel-nuc5i7ryh-with-ubuntu/","tags":["Intel","NUC","NUC5i7RYH","Samsung SM951","NVME","Ubuntu","Ubuntu MATE","Core i7 5557U"],"title":"Intel NUC5i7RYH with Ubuntu"},{"categories":["Linux","Open Source","Content Creation"],"contents":"Nikola is a static site and blog generator written in Python that I\u0026rsquo;ve been using for a good while now. This blog post describes how to install Nikola on Ubuntu 14.04 or newer. Now, this may look like a long winded way to install Nikola, given that .deb package exists, but in my opinion it is the correct way to install Nikola on Ubuntu.\nInstalling Python First you\u0026rsquo;ll need Python.\nsudo apt-get install cython3 libpython3.4 python3.4 python3.4-dev python3.4-minimal Now install the Python \u0026ldquo;package\u0026rdquo; management utilities.\nsudo apt-get install python-setuptools python-virtualenv python-pip virtualenvwrapper The Snakepit Create a \u0026ldquo;Snakepit\u0026rdquo; directory for storing all the virtualenvs.\nmkdir ~/Snakepit Create a virtualenv for Nikola The following will create a new virtualenv called nikola based on Python 3.4.\nvirtualenv -p /usr/bin/python3.4 ~/Snakepit/nikola-773 Working on a virtualenv To activate the virtualenv do the following.\nsource ~/Snakepit/nikola-773/bin/activate Your shell prompt will change while a virtualenv is being worked on to indicate which virtualenv is currently active.\nWhile working on a virtualenv you can pip install what you need or manually install any Python libraries safe in the knowledge you will not adversely damage any other virtualenvs or the global packages in the process. Very useful for developing a new branch which may have different library requirements than the master/head.\nWhen you are finished working in a virtualenv you can deactivate it by simply executing deactivate.\nInstall Nikola requirements Nikola requires some additional packages.\nsudo apt-get install liblcms2-dev libfreetype6-dev libjpeg8-dev \\ libopenjp2-7-dev libtiff5-dev libwebp-dev libxslt1-dev libxml2-dev \\ libyaml-dev libzmq-dev zlib1g-dev Some of the content optimisation filters require additional packages.\nsudo apt-get install closure-compiler jpegoptim optipng yui-compressor Install Tidy 5. (optional)\nsudo apt-get -y remove libtidy-0.99-0 tidy wget http://binaries.html-tidy.org/binaries/tidy-5.1.14/tidy-5.1.14-64bit.deb -O /tmp/tidy5.deb sudo dpkg -i /tmp/tidy5.deb sudo ln -s /usr/bin/tidy /usr/local/bin/tidy5 rm /tmp/tidy5.deb What are these requirements for? The following are required to build pillow, the Python imaging library.\nliblcms2-dev libfreetype6-dev libjpeg8-dev libopenjp2-7-dev libtiff5-dev libwebp-dev zlib1g-dev The following are required to build lxml, a Python XML library.\nlibxml2-dev libxslt1-dev The following are required to build python-coveralls.\nlibyaml-dev The following are required to build pyzmq.\nlibzmq-dev Install Nikola First install Cython, which will ensure some of the packages required by Nikola use all the available optimisations.\npip install --upgrade Cython Install all of Nikola.\npip install --upgrade \u0026#34;Nikola[extras,tests]\u0026#34; Create a site After installing Nikola, you should create a site. A site is a collection of all assets needed to render your website, including configuration, posts, pages, images, and all other files and customizations.\nTo create a site, you need to run:\nnikola init \u0026lt;directory_name\u0026gt; A wizard will guide your initial setup The --demo option can be used to populate your site with some example content. If you do not want the wizard, use the --quiet argument.\nNikola is now installed and and initial site is setup. nikola help and the Nikola Handbook will assist you from here.\n","permalink":"https://wimpysworld.com/posts/installing-nikola-on-ubuntu/","tags":["Nikola","Python","Content Management","Ubuntu","Static Site Generator","virtualenv"],"title":"Installing Nikola on Ubuntu"},{"categories":["Linux","Broadcasting","Open Source"],"contents":"Ubuntu Podcast was a weekly podcast that discussd news from the Ubuntu and Open Source community. The podcast ran from 2008 to 2021 and I joined the line up of presenters in 2015. In addition to the weekly podcasts we also participated in live shows at OggCamp and FOSS Talk Live.\nOrganisation: Ubuntu Podcast Date: February 2015 - September 2021 Role: Co-presenter \u0026amp; Producer ","permalink":"https://wimpysworld.com/projects/ubuntu-podcast/","tags":["Ubuntu","Podcast","Live Show","Live Streaming","Audio Production","OggCamp","FOSS Talk Live"],"title":"Ubuntu Podcast"},{"categories":["Linux","Development","Open Source"],"contents":"Debian is a Unix-like computer operating system and a Linux distribution that is composed entirely of free and open-source software, most of which is under the GNU General Public License, and packaged by a group of individuals known as the Debian Project.\nOrganisation: Debian Project Date: October 2014 - date Role: Package maintainer ","permalink":"https://wimpysworld.com/projects/debian/","tags":["Debian","Ubuntu","MATE Desktop","dpkg","apt"],"title":"Debian"},{"categories":["Linux","Open Source"],"contents":"Willie is an IRC bot written in Python that I\u0026rsquo;ve recently started using. This blog post describes how to install Willie on Debian and as usual I will be using virtualenv to isolate this Python application from the rest of the system.\nInstalling Python First you\u0026rsquo;ll need Python.\nsudo apt-get install libpython2.7 python2.7 python2.7-dev python2.7-minimal The following will also be required to enable all the features Willie supports.\nsudo apt-get install enchant python2.7-dev libxslt1-dev libxml2-dev Remove any apt installed Python packages that we are about to replace. The versions of these packages in the Debian repositories soon get stale.\nsudo apt-get purge python-setuptools python-virtualenv python-pip python-profiler Install pip.\nwget https://bootstrap.pypa.io/get-pip.py sudo python2.7 get-pip.py Use pip to install virtualenv.\nsudo pip install virtualenv --upgrade The Snakepit Create a \u0026ldquo;Snakepit\u0026rdquo; directory for storing all the Python virtual environments.\nmkdir ~/Snakepit Create a virtualenv for Willie The following will create a new virtualenv called willie using Python 2.7 as the interpreter.\nvirtualenv -p /usr/bin/python2.7 ~/Snakepit/willie Working on a virtualenv Activate the virtualenv for Willie.\nsource ~/Snakepit/willie/bin/activate Your shell prompt will change, something like (willie)user@host:~$, while a virtualenv is being worked on to indicate which virtualenv is currently active.\nWhile working on a virtualenv you can pip install what you need or manually install any Python libraries safe in the knowledge you will not upset any other virtualenvs or the global packages in the process. Very useful for developing a new branch which may have different library requirements than the current stable release.\nWhen you are finished working in a virtualenv you can deactivate it by simply executing deactivate.\nInstall Willie I\u0026rsquo;ve decided to use Python 2.7 to run Willie and therefore have to install backports.ssl_match_hostname which is not required if you use Python 3.3.\npip install willie backports.ssl_match_hostname Additional functionality Willie has no external dependencies, besides Python. However, some of the modules do have external dependencies. So install the following Python modules so that I can make use of everything Willie can do.\npip install feedparser pytz lxml praw pyenchant pygeoip ipython --upgrade Configure Willie I am not going to explain to how to configure Willie because all that good stuff is very well documented by the project.\nhttps://github.com/embolalia/willie/wiki But for reference, my default.cfg looks something like this:\n[core] nick = nicofyourbot user = nicofyourbot name = Give You Bot A Name host = chat.freenode.net use_ssl = true verify_ssl = true port = 6697 owner = nicofthebotowner channels = #example nickserv_password = ************ prefix = \\. timeout = 120 [db] userdb_type = sqlite userdb_file = /home/username/.willie/willie.db Willie as a daemon From this point on I assume you\u0026rsquo;ve completed the first run configuration of Willie and have .willie/default.cfg in your home directory.\nAdd the following to /etc/init.d/willie.\n#!/bin/sh ### BEGIN INIT INFO # Provides: willie # Required-Start: $local_fs $remote_fs # Required-Stop: $local_fs $remote_fs # Should-Start: $network # Should-Stop: $network # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Willie IRC Bot. # Description: Start and stops the Willie IRC bot for a given user. ### END INIT INFO # NOTE! Replace with the user you want to run Willie. willie_USER=\u0026#34;yourusername\u0026#34; HOMEDIR=$(getent passwd $willie_USER | awk -F: \u0026#39;{print $6}\u0026#39;) DAEMON=\u0026#34;$HOMEDIR/Snakepit/willie/bin/willie\u0026#34; CONFIG=\u0026#34;$HOMEDIR/.willie/default.cfg\u0026#34; startd() { if [ -f ${CONFIG} ]; then echo \u0026#34;Starting Willie for $willie_USER\u0026#34; start-stop-daemon -c $willie_USER -u $willie_USER -x $DAEMON -S -- --config ${CONFIG} --fork --quiet else echo \u0026#34;Couldn\u0026#39;t start Willie for $willie_USER (no $CONFIG found)\u0026#34; fi } stopd() { echo \u0026#34;Stopping Willie for $willie_USER\u0026#34; willie_PID=$(pgrep -fu $willie_USER $DAEMON) if [ -z \u0026#34;$willie_PID\u0026#34; ]; then echo \u0026#34;Willie for USER $willie_USER: not running.\u0026#34; else kill -15 $willie_PID fi } status() { willie_PID=$(pgrep -fu $willie_USER $DAEMON) if [ -z \u0026#34;$willie_PID\u0026#34; ]; then echo \u0026#34;Willie for USER $willie_USER: not running.\u0026#34; else echo \u0026#34;Willie for USER $willie_USER: running (pid $willie_PID)\u0026#34; fi } case \u0026#34;$1\u0026#34; in start) startd ;; stop) stopd ;; restart|reload|force-reload) stopd \u0026amp;\u0026amp; startd ;; status) status ;; *) echo \u0026#34;Usage: /etc/init.d/willie {start|stop|reload|force-reload|restart|status}\u0026#34; exit 1 ;; esac exit 0 Set the permissions.\nsudo chmod +x /etc/init.d/willie Check that you can start/stop Willie.\nsudo /etc/init.d/willie start sudo /etc/init.d/willie status sudo /etc/init.d/willie stop Add willie to the startup/shutdown sequence.\nsudo update-rc.d willie defaults And that\u0026rsquo;s it. Willie is now running as a daemon inside a virtualenv.\n","permalink":"https://wimpysworld.com/posts/installing-willie-irc-bot-on-debian/","tags":["Python","IRC","Debian","Bot","virtualenv"],"title":"Installing Willie IRC Bot on Debian"},{"categories":["Linux","Open Source","Tutorial"],"contents":"I have been using the BIP IRC proxy that maintains a persistent connection to a list of IRC channels. However, I\u0026rsquo;ve heard good things about ZNC and decided to give it a try.\nThe purpose of an IRC proxy, or bouncer, is that you can then point your IRC clients to them to maintain a transparent connection from multiple clients and playback the conversations that took place while you were away.\nInstalling ZNC The ZNC package for Debian Wheezy are very old, so I decide to install from source.\nInstall required packages We first need to make sure we have all the packages required to build ZNC.\nsudo apt-get install build-essential libssl-dev libperl-dev pkg-config Compile ZNC Now download and compile ZNC.\ncd wget http://znc.in/releases/znc-1.4.tar.gz tar zxvf znc-1.4.tar.gz cd znc-1.4 ./configure --with-openssl make sudo make install Create a user Create a separate ZNC user so that ZNC does not need to run as root:\nsudo groupadd znc sudo adduser --system --home /var/lib/znc --group znc Configuring ZNC You can use the interactive wizard to configure ZNC which really help create the initial configuration.\nsudo -u znc /usr/local/bin/znc --datadir=/var/lib/znc --makeconf Here is a transcript of how I answered the initial configuration questions.\n[ .. ] Checking for list of available modules... [ \u0026gt;\u0026gt; ] ok [ ** ] Building new config [ ** ] [ ** ] First let\u0026#39;s start with some global settings... [ ** ] [ ?? ] What port would you like ZNC to listen on? (1025 to 65535): 7778 [ ?? ] Would you like ZNC to listen using SSL? (yes/no) [no]: yes [ ?? ] Would you like ZNC to listen using both IPv4 and IPv6? (yes/no) [yes]: [ .. ] Verifying the listener... [ \u0026gt;\u0026gt; ] ok [ ** ] Unable to locate pem file: [/var/lib/znc/znc.pem], creating it [ .. ] Writing Pem file [/var/lib/znc/znc.pem]... [ \u0026gt;\u0026gt; ] ok [ ** ] [ ** ] -- Global Modules -- [ ** ] [ ** ] +-----------+----------------------------------------------------------+ [ ** ] | Name | Description | [ ** ] +-----------+----------------------------------------------------------+ [ ** ] | partyline | Internal channels and queries for users connected to znc | [ ** ] | webadmin | Web based administration module | [ ** ] +-----------+----------------------------------------------------------+ [ ** ] And 10 other (uncommon) modules. You can enable those later. [ ** ] [ ?? ] Load global module \u0026lt;partyline\u0026gt;? (yes/no) [no]: yes [ ?? ] Load global module \u0026lt;webadmin\u0026gt;? (yes/no) [no]: yes [ ** ] [ ** ] Now we need to set up a user... [ ** ] [ ?? ] Username (AlphaNumeric): yournick [ ?? ] Enter Password: [ ?? ] Confirm Password: [ ?? ] Would you like this user to be an admin? (yes/no) [yes]: [ ?? ] Nick [yournick]: [ ?? ] Alt Nick [yournick_]: [ ?? ] Ident [yournick]: [ ?? ] Real Name [Got ZNC?]: Your Name [ ?? ] Bind Host (optional): [ ?? ] Number of lines to buffer per channel [50]: 1024 [ ?? ] Would you like to clear channel buffers after replay? (yes/no) [yes]: [ ?? ] Default channel modes [+stn]: [ ** ] [ ** ] -- User Modules -- [ ** ] [ ** ] +--------------+------------------------------------------------------------------------------------------+ [ ** ] | Name | Description | [ ** ] +--------------+------------------------------------------------------------------------------------------+ [ ** ] | chansaver | Keep config up-to-date when user joins/parts | [ ** ] | controlpanel | Dynamic configuration through IRC. Allows editing only yourself if you\u0026#39;re not ZNC admin. | [ ** ] | perform | Keeps a list of commands to be executed when ZNC connects to IRC. | [ ** ] | webadmin | Web based administration module | [ ** ] +--------------+------------------------------------------------------------------------------------------+ [ ** ] And 21 other (uncommon) modules. You can enable those later. [ ** ] [ ?? ] Load module \u0026lt;chansaver\u0026gt;? (yes/no) [no]: yes [ ?? ] Load module \u0026lt;controlpanel\u0026gt;? (yes/no) [no]: tes [ ?? ] Load module \u0026lt;controlpanel\u0026gt;? (yes/no) [no]: yes [ ?? ] Load module \u0026lt;perform\u0026gt;? (yes/no) [no]: yes [ ?? ] Load module \u0026lt;webadmin\u0026gt;? (yes/no) [no]: yes [ ** ] [ ?? ] Would you like to set up a network? (yes/no) [no]: [ ** ] [ ?? ] Would you like to set up another user? (yes/no) [no]: [ .. ] Writing config [/var/lib/znc/configs/znc.conf]... [ \u0026gt;\u0026gt; ] ok [ ** ] [ ** ]To connect to this ZNC you need to connect to it as your IRC server [ ** ]using the port that you supplied. You have to supply your login info [ ** ]as the IRC server password like this: user/network:pass. [ ** ] [ ** ]Try something like this in your IRC client... [ ** ]/server \u0026lt;znc_server_ip\u0026gt; +7778 flexiondotorg:\u0026lt;pass\u0026gt; [ ** ]And this in your browser... [ ** ]https://\u0026lt;znc_server_ip\u0026gt;:7778/ [ ** ] [ ?? ] Launch ZNC now? (yes/no) [yes]: no Running ZNV as a daemon Here is a /etc/init.d/znc for Debian based on this installation method:\n#! /bin/sh ### BEGIN INIT INFO # Provides: znc # Required-Start: $remote_fs $syslog # Required-Stop: $remote_fs $syslog # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: ZNC IRC bouncer # Description: ZNC is an IRC bouncer ### END INIT INFO PATH=/sbin:/usr/sbin:/bin:/usr/bin:/usr/local/bin DESC=\u0026#34;ZNC daemon\u0026#34; NAME=znc DAEMON=/usr/local/bin/$NAME DATADIR=/var/lib/znc DAEMON_ARGS=\u0026#34;--datadir=$DATADIR\u0026#34; PIDDIR=$DATADIR/run PIDFILE=$PIDDIR/$NAME.pid SCRIPTNAME=/etc/init.d/$NAME USER=znc GROUP=znc # Exit if the package is not installed [ -x \u0026#34;$DAEMON\u0026#34; ] || exit 0 # Read configuration variable file if it is present [ -r /etc/default/$NAME ] \u0026amp;\u0026amp; . /etc/default/$NAME # Load the VERBOSE setting and other rcS variables . /lib/init/vars.sh # Define LSB log_* functions. # Depend on lsb-base (\u0026gt;= 3.2-14) to ensure that this file is present # and status_of_proc is working. . /lib/lsb/init-functions # # Function that starts the daemon/service # do_start() { # Return # 0 if daemon has been started # 1 if daemon was already running # 2 if daemon could not be started if [ ! -d $PIDDIR ] then mkdir $PIDDIR fi chown $USER:$GROUP $PIDDIR start-stop-daemon --start --quiet --pidfile $PIDFILE --exec $DAEMON --test --chuid $USER \u0026gt; /dev/null || return 1 start-stop-daemon --start --quiet --pidfile $PIDFILE --exec $DAEMON --chuid $USER -- $DAEMON_ARGS \u0026gt; /dev/null || return 2 } # # Function that stops the daemon/service # do_stop() { # Return # 0 if daemon has been stopped # 1 if daemon was already stopped # 2 if daemon could not be stopped # other if a failure occurred start-stop-daemon --stop --quiet --retry=TERM/30/KILL/5 --pidfile $PIDFILE --name $NAME --chuid $USER RETVAL=\u0026#34;$?\u0026#34; [ \u0026#34;$RETVAL\u0026#34; = 2 ] \u0026amp;\u0026amp; return 2 # Wait for children to finish too if this is a daemon that forks # and if the daemon is only ever run from this initscript. # If the above conditions are not satisfied then add some other code # that waits for the process to drop all resources that could be # needed by services started subsequently. A last resort is to # sleep for some time. start-stop-daemon --stop --quiet --oknodo --retry=0/30/KILL/5 --exec $DAEMON --chuid $USER [ \u0026#34;$?\u0026#34; = 2 ] \u0026amp;\u0026amp; return 2 # Many daemons don\u0026#39;t delete their pidfiles when they exit. rm -f $PIDFILE return \u0026#34;$RETVAL\u0026#34; } # # Function that sends a SIGHUP to the daemon/service # do_reload() { start-stop-daemon --stop --signal 1 --quiet --pidfile $PIDFILE --name $NAME --chuid $USER return 0 } case \u0026#34;$1\u0026#34; in start) [ \u0026#34;$VERBOSE\u0026#34; != no ] \u0026amp;\u0026amp; log_daemon_msg \u0026#34;Starting $DESC\u0026#34; \u0026#34;$NAME\u0026#34; do_start case \u0026#34;$?\u0026#34; in 0|1) [ \u0026#34;$VERBOSE\u0026#34; != no ] \u0026amp;\u0026amp; log_end_msg 0 ;; 2) [ \u0026#34;$VERBOSE\u0026#34; != no ] \u0026amp;\u0026amp; log_end_msg 1 ;; esac ;; stop) [ \u0026#34;$VERBOSE\u0026#34; != no ] \u0026amp;\u0026amp; log_daemon_msg \u0026#34;Stopping $DESC\u0026#34; \u0026#34;$NAME\u0026#34; do_stop case \u0026#34;$?\u0026#34; in 0|1) [ \u0026#34;$VERBOSE\u0026#34; != no ] \u0026amp;\u0026amp; log_end_msg 0 ;; 2) [ \u0026#34;$VERBOSE\u0026#34; != no ] \u0026amp;\u0026amp; log_end_msg 1 ;; esac ;; status) status_of_proc -p $PIDFILE \u0026#34;$DAEMON\u0026#34; \u0026#34;$NAME\u0026#34; \u0026amp;\u0026amp; exit 0 || exit $? ;; reload) log_daemon_msg \u0026#34;Reloading $DESC\u0026#34; \u0026#34;$NAME\u0026#34; do_reload log_end_msg $? ;; restart) log_daemon_msg \u0026#34;Restarting $DESC\u0026#34; \u0026#34;$NAME\u0026#34; do_stop case \u0026#34;$?\u0026#34; in 0|1) do_start case \u0026#34;$?\u0026#34; in 0) log_end_msg 0 ;; 1) log_end_msg 1 ;; # Old process is still running *) log_end_msg 1 ;; # Failed to start esac ;; *) # Failed to stop log_end_msg 1 ;; esac ;; *) echo \u0026#34;Usage: $SCRIPTNAME {status|start|stop|reload|restart}\u0026#34; \u0026gt;\u0026amp;2 exit 3 ;; esac After you\u0026rsquo;ve created the script, you must give it the proper permissions to run and add the script to the startup/shutdown sequence.\nsudo chmod 755 /etc/init.d/znc sudo update-rc.d znc defaults Start the service:\nsudo service znc start Stop the service:\nsudo service znc stop Web configuration I love that ZNC comes bundled with a web based configuration tool. Just login to https://znc.example.org:7778 to add users, add networks to users and to add channels to networks. Really simple stuff.\nIRC client configuration I use HexChat, but other IRC clients are available. Just add a new Network to HexChat for your ZNC server, use the username, suffixed with the network name you configured in ZNC, and your ZNC password.\nConclusion I much prefer ZNC to BIP.\nI really like the web and IRC configuration but I still have the option to configure the config files directly. ZNC is far less cryptic with regard to setting up IRC client connections and user management is much better implemented. When I add a new channel to an existing network in ZNC it automatically appears in my connected clients without the need to restart anything. ZNC\u0026rsquo;s IRC backlogs don\u0026rsquo;t have the confusing double time stamps present in BIP and ZNC is much faster re-establishing connections to my multiple IRC network and channels. Most importantly, ZNC has been far more stable than BIP. References\nhttp://wiki.znc.in/Installation http://wiki.znc.in/Running_ZNC_as_a_system_daemon https://www.digitalocean.com/community/tutorials/how-to-install-znc-an-irc-bouncer-on-an-ubuntu-vps https://raymii.org/s/tutorials/Install_the_Lastest_ZNC_from_Source_in_Ubuntu.html https://shellfish.io/tutorial/1/how-to-install-znc-on-debian-7/ ","permalink":"https://wimpysworld.com/posts/znc-irc-proxy/","tags":["Debian","IRC","Proxy","Bouncer"],"title":"ZNC IRC proxy"},{"categories":["Linux","Open Source","Tutorial"],"contents":"I have a few Debian servers that run at home and on VPSs. I wanted to add some basic systems monitoring to them, but didn\u0026rsquo;t want anything too complicated to look after. I found Monitorix.\nMonitorix is a free, open source, lightweight system monitoring tool designed to monitor as many services and system resources as possible. It has been created to be used under production Linux/UNIX servers, but due to its simplicity and small size can be used on embedded devices as well.\nInstall Monitorix This install has been tested on Debian Squeeze and Wheezy. First install the dependencies.\nsudo apt-get install rrdtool perl libwww-perl libmailtools-perl \\ libmime-lite-perl librrds-perl libdbi-perl libxml-simple-perl \\ libhttp-server-simple-perl libconfig-general-perl libio-socket-ssl-perl Now Monitorix itself.\nwget -c \u0026#34;http://apt.izzysoft.de/ubuntu/dists/generic/index.php?file=monitorix_3.5.1-izzy1_all.deb\u0026#34; -O monitorix_3.5.1-izzy1_all.deb sudo dpkg -i monitorix_3.5.1-izzy1_all.deb At this point Monitorix is installed and running. Point your browser to http://example.org:8080/monitorix/ and enjoy!\nConfiguring Monitorix Everything in /etc/monitorix/monitorix.conf is comprehensively documented, just get tweaking.\nhttp://www.monitorix.org/documentation.html Each time you update the configuration Monitorix will require a restart.\nsudo service monitorix restart nginx status If you run nginx then you\u0026rsquo;ll want to drop the following into /etc/nginx/conf.d/status.conf so that Monitorix can monitor nginx.\nserver { listen localhost:80; location /nginx_status { stub_status on; access_log off; allow 127.0.0.1; deny all; } } References http://www.monitorix.org/doc-debian.html ","permalink":"https://wimpysworld.com/posts/monitorix-on-debian/","tags":["Debian","Monitorix","System Monitoring","nginx"],"title":"Monitorix on Debian"},{"categories":["Linux","Open Source","Tutorial","Self Hosting"],"contents":"Last year I removed all my music from Google Play Music and created my own subSonic server. I really like subSonic but don\u0026rsquo;t use it a huge amount, mostly for syncing some music to my phone prior to going on holiday or business. Therefore, I\u0026rsquo;ve made a single one time donation to the project rather than the ongoing monthly usage fee.\nInstalling subSonic on Debian This is how I install subSonic on Debian Wheezy.\nInstall Tomcat. sudo apt-get install tomcat7 Install subSonic. apt-get install ffmpeg sudo mkdir /var/subsonic sudo chown tomcat7: /var/subsonic sudo wget -c https://github.com/KHresearch/subsonic/releases/download/v4.9-kang/subsonic.war sudo cp subsonic.war /var/lib/tomcat7/webapps Restart Tomcat.\nsudo service tomcat7 restart Login to subSonic by visiting http://server.example.org:8080/subsonic and login with the credentials admin and admin. Make sure you change the password straight away.\nRight, that is it. You can stop here and start filling subSonic with your music.\nsubSonic clients On the rare occasions that I listen to music via subSonic I use UltraSonic for Android and Clementine on my Arch Linux workstations.\nReferences http://www.subsonic.org/pages/installation.jsp https://github.com/KHresearch/subsonic/ ","permalink":"https://wimpysworld.com/posts/subsonic-on-debian/","tags":["Debian","subSonic","Android","UltraSonic","Clementine","Tomcat"],"title":"subSonic on Debian"},{"categories":["Linux","Open Source","Tutorial","Self Hosting"],"contents":"I have a Brother MFC-7360N printer at home and there is also one at work. I wanted to to get Cloudprint working with Android devices rather than use the Android app Brother provide, which is great when it works but deeply frustrating (for my wife) when it doesn\u0026rsquo;t.\nWhat I describe below is how to Cloudprint enable \u0026ldquo;Classic printers\u0026rdquo; using Debian Wheezy.\nInstall CUPS Install CUPS and the Cloudprint requirements.\nsudo apt-get install cups python-cups python-daemon python-pkg-resources Install the MFC-7360N Drivers I used the URL below to access the .deb files required.\nhttp://support.brother.com/g/b/downloadlist.aspx?c=gb\u0026amp;lang=en\u0026amp;prod=mfc7360n_all\u0026amp;os=128 If you\u0026rsquo;re running a 64-bit Debian, then install ia32-libs first.\nsudo apt-get install ia32-libs Download and install the MFC-7360N drivers.\nwget -c http://download.brother.com/welcome/dlf006237/mfc7360nlpr-2.1.0-1.i386.deb wget -c http://download.brother.com/welcome/dlf006239/cupswrapperMFC7360N-2.0.4-2.i386.deb sudo dpkg -i --force-all mfc7360nlpr-2.1.0-1.i386.deb sudo dpkg -i --force-all cupswrapperMFC7360N-2.0.4-2.i386.deb Configure CUPS Edit the CUPS configuration file commonly located in /etc/cups/cupsd.conf and make the section that looks like this\u0026hellip;\n# Only listen for connections from the local machine. Listen localhost:631 Listen /var/run/cups/cups.sock \u0026hellip;is changed to look like this:\n# Listen on all interfaces Port 631 Listen /var/run/cups/cups.sock Modify the Apache specific directives to allow connections from everywhere as well. Find the follow section in /etc/cups/cupsd.conf:\n\u0026lt;Location /\u0026gt; # Restrict access to the server... Order allow,deny \u0026lt;/Location\u0026gt; # Restrict access to the admin pages... \u0026lt;Location /admin\u0026gt; Order allow,deny \u0026lt;/Location\u0026gt; # Restrict access to the configuration files... \u0026lt;Location /admin/conf\u0026gt; AuthType Default Require user @SYSTEM Order allow,deny \u0026lt;/Location\u0026gt; Add Allow All after each Order allow,deny so it looks like this:\n\u0026lt;Location /\u0026gt; # Restrict access to the server... Order allow,deny Allow All \u0026lt;/Location\u0026gt; # Restrict access to the admin pages... \u0026lt;Location /admin\u0026gt; Order allow,deny Allow All \u0026lt;/Location\u0026gt; # Restrict access to the configuration files... \u0026lt;Location /admin/conf\u0026gt; AuthType Default Require user @SYSTEM Order allow,deny Allow All \u0026lt;/Location\u0026gt; Add the MFC-7360N to CUPS If your MFC-7360N is connected to your server via USB then you should be all set. Login to the CUPS administration interface on http://yourserver:631 and modify the MFC7360N printer (if one was created when the drivers where installed) then make sure you can print a test page via CUPS before proceeding.\nInstall Cloudprint and Cloudprint service wget -c http://davesteele.github.io/cloudprint-service/deb/cloudprint_0.11-5.1_all.deb wget -c http://davesteele.github.io/cloudprint-service/deb/cloudprint-service_0.11-5.1_all.deb sudo dpkg -i cloudprint_0.11-5.1_all.deb sudo dpkg -i cloudprint-service_0.11-5.1_all.deb Authenticate Google accounts with 2 step verification enabled need to use an application-specific password.\nhttp://www.google.com/support/accounts/bin/static.py?page=guide.cs\u0026amp;guide=1056283\u0026amp;topic=1056286 Authenticate cloudprintd.\nsudo service cloudprintd login You should see something like this.\nAccounts with 2 factor authentication require an application-specific password Google username: you@example.org Password: Added Printer MFC7360N Start the Cloudprint daemon.\nsudo service cloudprintd start If everything is working correctly you should see your printer the following page:\nhttps://www.google.com/cloudprint#printers Printing from mobile devices Android Add the Google Cloud Print app to Android devices and you\u0026rsquo;ll be able to configure your printer preferences and print from Android..\nChrome and Chromium When printing from within Google Chrome and Chromium you can now select Cloudprint as the destination and choose your printer.\nReferences https://github.com/armooo/cloudprint http://davesteele.github.io/cloudprint-service/ https://github.com/davesteele/cloudprint-service http://injustfiveminutes.com/2013/11/07/remote-access-to-cups-admin-inter/ http://ubuntuforums.org/showthread.php?t=1794179 https://support.google.com/a/answer/2906017?hl=en ","permalink":"https://wimpysworld.com/posts/headless-cloudprint-server-on-debian-for-mfc-7360n/","tags":["Cloudprint","Debian","MFC-7360N","Android","Chrome","CUPS","Apache","Printing"],"title":"Headless cloudprint server on Debian for MFC-7360N"},{"categories":["Linux","Home Cinema","Gadgets"],"contents":"I\u0026rsquo;ve had these notes kicking around for absolutely ages. I haven\u0026rsquo;t checked to see if this stuff is still accurate because during the last 12 months or so our viewing habits have changed and we almost exclusively watch streamed content now.\nThat said, my father-in-law gave us a Humax Foxsat HDR Freesat digital recorder as a thank you for some work I did for him. It turns out the Humax Foxsat HDR is quite hackable.\nHard Disk Upgrade I contributed to the topic below. The Humax firmware only supports disks up to 1TB but the hackers method works for 2TB drives, possibly bigger but I haven\u0026rsquo;t tried. I\u0026rsquo;ve upgraded mine and my father-in-laws to 2TB without any problems.\nhttp://www.avforums.com/forums/pvrs-vcrs/1336395-humax-foxsat-hdr-upgrade-hdd-2tb.html Custom Firmware These are the topics that discuss the custom firmware itself and includes the downloads. Once the custom firmware is installed and it\u0026rsquo;s advanced interface has been enabled you can enable several add-ons such as Samba, Mediatomb, ssh, ftp, etc.\nhttp://www.avforums.com/threads/media-file-server-bundle-for-the-foxsat-hdr-release-4-part-5.1829374/ http://www.avforums.com/forums/freesat/1747997-media-file-server-bundle-foxsat-hdr-release-4-0-part-4-a.html http://www.avforums.com/forums/freesat/1661195-media-file-server-bundle-foxsat-hdr-release-4-0-part-3-a.html http://www.avforums.com/forums/freesat/1599048-media-file-server-bundle-foxsat-hdr-release-4-0-part-2-a.html http://www.avforums.com/forums/freesat/1517610-media-file-server-bundle-foxsat-hdr-release-4-0-part-1-a.html Web Interface This is the topic about the web interface. No download required it is bundled in the custom firmware above.\nhttp://www.avforums.com/forums/freesat/1601205-web-interface-channel-editor-plug-foxsat-hdr.html Channel Editor The channel editor is installed and configured via the web interface and is one of my favourite add-ons. It also allows you to enable non-freesat channels in the normal guide.\nhttp://www.avforums.com/forums/freesat/1601205-web-interface-channel-editor-plug-foxsat-hdr.html Non Freesat channels We get our broadcasts from Astra 2A / Astra 2B / Astra 2D / Eurobird 1 (28.2¬∞E). Other free to air channels are available and KingOfSat lists them all. These channels can only be added via the Humax setup menus, but can then be presented in the normal EPG using the Channel Editor above.\nhttp://en.kingofsat.net/pos-28.2E.php Decrypt HD recordings I never actually tried this, but what follows might be useful.\nhttp://www.avforums.com/forums/pvrs-vcrs/1721573-can-i-install-auto-unprotect-foxsat-hdr-if-so-how.html http://www.avforums.com/forums/18051843-post715.html http://www.avforums.com/forums/18057417-post732.html http://www.avforums.com/forums/18061024-post740.html http://www.avforums.com/forums/18085731-post768.html OTA updates This is not so relevant now, since Humax haven\u0026rsquo;t released an OTA update for some time.\nI have not yet found a way to prevent automatic over the air updates from being automatically applied. When an over the air update is applied the Humax still works, but the web interface and all the add-ons stop working. The can be solved by waiting for the custom firmware to be updated (which happen remarkably quickly) and then re-flashing the custom firmware. All the add-ons should start working again.\n","permalink":"https://wimpysworld.com/posts/humax-foxsat-hdr-custom-firmware/","tags":["Humax Foxsat HDR","Firmware","Hacking"],"title":"Humax Foxsat HDR Custom Firmware"},{"categories":["Linux","Open Source","Tutorial","Self Hosting"],"contents":"This how-to was updated for Open Media Vault 2.x and 3.x on 22nd August 2016.\nI\u0026rsquo;ve installed Open Media Vault on a HP ProLiant MicroServer G7 N54L and use it as media server for the house. OpenMediaVault (OMV) is a network attached storage (NAS) solution based on Debian Linux.\nI use a free Dropbox account to sync photos from mine and my wife\u0026rsquo;s Android phones and wanted to automate to import of these photo upload into Plex, which is also running on Open Media Vault.\nInstalling Dropbox on Open Media Vault I looked for a Dropbox Plugin for Open Media Vault and found this:\nhttps://github.com/lordldx/openmediavault-dropbox Sadly, at the time of writing, it is unfinished and I didn\u0026rsquo;t have the time to go and learn the Open Media Vault plugin API.\nThe Open Media Vault forum does include a Dropbox HOW-TO which is very similar to how I\u0026rsquo;ve run Dropbox on headless Linux servers in the past. So, I decided to adapt my existing notes to Open Media Vault.\nCreate a Dropbox Share Create a Dropbox share via the OMV WebUI.\nAccess Right Management -\u0026gt; Shared Folders I gave my the name \u0026ldquo;Dropbox\u0026rdquo;. I know, very original.\nInstalling Dropbox on a headless server Download and extract the latest Dropbox stable release.\ncd ~ \u0026amp;\u0026amp; wget -O - \u0026#34;https://www.dropbox.com/download?plat=lnx.x86_64\u0026#34; | tar xzf - chown -Rv ${USER}: ~/.dropbox-dist sudo ln -s ~/.dropbox-dist/dropboxd /usr/local/bin/ Run dropboxd.\n~/.dropbox-dist/dropboxd You should see output like this:\nThis client is not linked to any account... Please visit https://www.dropbox.com/cli_link?host_id=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx to link this machine. Visit the URL, login with your Dropbox account and link the account. You should see the following.\nClient successfully linked, Welcome Web! dropboxd will now create a ~/Dropbox folder and start synchronizing. Stop dropboxd with CTRL+C.\nSymlink the Dropbox share Login to the OMV server as root and sym-link the Dropbox share you created earlier to the Dropbox directory in the root home directory.\nmv ~/Dropbox ~/Dropbox-old ln -s /media/\u0026lt;UUID\u0026gt;/Dropbox ~/Dropbox rsync -a -W --progress ~/Dropbox-old/ ~/Dropbox/ init.d - Open Media Vault 2.x If you are using Open Media Vault 2.x (based on Debian wheezy) the you\u0026rsquo;ll need to create an init script.\nTo run Dropbox as daemon with init.d. Create /etc/init.d/dropbox with the following content.\n#!/bin/sh ### BEGIN INIT INFO # Provides: dropbox # Required-Start: $local_fs $remote_fs $network $syslog $named # Required-Stop: $local_fs $remote_fs $network $syslog $named # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # X-Interactive: false # Short-Description: dropbox service ### END INIT INFO DROPBOX_USERS=\u0026#34;user_a\u0026#34; DAEMON=.dropbox-dist/dropboxd start() { echo \u0026#34;Starting dropbox...\u0026#34; for dbuser in $DROPBOX_USERS; do HOMEDIR=`getent passwd $dbuser | cut -d: -f6` if [ -x $DAEMON ]; then HOME=\u0026#34;$HOMEDIR\u0026#34; start-stop-daemon -b -o -c $dbuser -S -u $dbuser -x $HOMEDIR/$DAEMON fi done } stop() { echo \u0026#34;Stopping dropbox...\u0026#34; for dbuser in $DROPBOX_USERS; do HOMEDIR=`getent passwd $dbuser | cut -d: -f6` if [ -x $HOMEDIR/$DAEMON ]; then start-stop-daemon -o -c $dbuser -K -u $dbuser -x $HOMEDIR/$DAEMON fi done } status() { for dbuser in $DROPBOX_USERS; do dbpid=`pgrep -u $dbuser dropbox` if [ -z $dbpid ] ; then echo \u0026#34;dropboxd for USER $dbuser: not running.\u0026#34; else echo \u0026#34;dropboxd for USER $dbuser: running (pid $dbpid)\u0026#34; fi done } case \u0026#34;$1\u0026#34; in start) start ;; stop) stop ;; restart|reload|force-reload) stop start ;; status) status ;; *) echo \u0026#34;Usage: /etc/init.d/dropbox {start|stop|reload|force-reload|restart|status}\u0026#34; exit 1 esac exit 0 Enable the init.d script.\nsudo chmod +x /etc/init.d/dropbox sudo update-rc.d dropbox defaults Starting and Stopping the Dropbox daemon Use /etc/init.d/dropbox start to start and /etc/init.d/dropbox stop to stop.\nsystemd - OpenMediaVault 3.x If you are using Open Media Vault 3.x (based on Debian jessie) then you\u0026rsquo;ll need to create a systemd unit. Create the systemd service file.\nsudo nano /lib/systemd/system/dropbox.service Add this:\n[Unit] Description=Dropbox After=local-fs.target network.target [Service] Type=simple WorkingDirectory=%h/.dropbox-dist ExecStart=/usr/local/bin/dropboxd ExecReload=/bin/kill -HUP $MAINPID KillMode=process Restart=on-failure User=%I [Install] WantedBy=multi-user.target Enable the dropbox service for a given user.\nsudo systemctl enable dropbox@user_a Start the service.\nsudo systemctl start dropbox@user_a Dropbox client It is recommended to download the official Dropbox client to configure Dropbox and get its status.\nwget \u0026#34;http://www.dropbox.com/download?dl=packages/dropbox.py\u0026#34; -O dropbox sudo chmod 755 dropbox sudo mv dropbox /usr/local/bin/ You can check on Dropbox status by running the following.\ndropbox status For usage instructions run dropbox help.\nPhoto importing So, the reason for doing all this is that I now have a Dropbox instance running on my home file server and everyday it runs a script, that I wrote, to automatically import new photos into a directory that Plex monitors. I\u0026rsquo;ll post details about my photo sorting script, Phort, at a later date.\nReferences http://www.dropboxwiki.com/Text_Based_Linux_Install ","permalink":"https://wimpysworld.com/posts/integrating-dropbox-photo-syncing-with-open-media-vault-and-plex/","tags":["Dropbox","Open Media Vault","Plex","Debian"],"title":"Integrating Dropbox photo syncing with Open Media Vault and Plex"},{"categories":["Linux","Open Source","Tutorial","Self Hosting"],"contents":"At the time of writing OpenMediaVault 0.6 is pre-release. But it is possible to install OpenMediaVault on Debian Wheezy in order to get some testing done.\nInstall Debian Wheezy on your target VM or test server. Go with the defaults until the \u0026lsquo;Software selection\u0026rsquo; dialogue. Make sure everything is unselected, like this:\n[ ] Debian desktop environment [ ] Web server [ ] Print server [ ] SQL database [ ] DNS Server [ ] File server [ ] Mail server [ ] SSH server [ ] Laptop [ ] Standard system utilities After the install is complete, reboot and login to the new Debian system as root.\nUpdate the repository sources and add the contrib and non-free repositories.\nnano /etc/apt/sources.list It should look something like this:\ndeb http://ftp.uk.debian.org/debian/ wheezy main contrib non-free deb-src http://ftp.uk.debian.org/debian/ wheezy main contrib non-free deb http://security.debian.org/ wheezy/updates main contrib non-free deb-src http://security.debian.org/ wheezy/updates main contrib non-free # wheezy-updates, previously known as \u0026#39;volatile\u0026#39; deb http://ftp.uk.debian.org/debian/ wheezy-updates main contrib non-free deb-src http://ftp.uk.debian.org/debian/ wheezy-updates main contrib non-free Now add the OpenMediaVault repository.\necho \u0026#34;deb http://packages.openmediavault.org/public kralizec main\u0026#34; \u0026gt; /etc/apt/sources.list.d/openmediavault.list Update.\napt-get update Install the OpenMediaVault repository key and Postfix.\napt-get install openmediavault-keyring postfix When the \u0026lsquo;Postfix Configuration\u0026rsquo; dialogue is displayed choose No configuration. Update again and install OpenMediaVault.\napt-get update apt-get install openmediavault When the \u0026lsquo;Configuring mdadm\u0026rsquo; dialogue is displayed enter none. Do you want to start MD arrays automatically? YES When the \u0026lsquo;ProFTPD configuration\u0026rsquo; dialogue is displayed choose standalone. Initialise OpenMediaVault and reboot.\nomv-initsystem reboot After the reboot you should be able to connect to the OpenMediaVault WebUI and login as admin with the password of openmediavault. That\u0026rsquo;s it. Get testing.\n","permalink":"https://wimpysworld.com/posts/openmediavault-on-debian/","tags":["Debian","Open Media Vault"],"title":"OpenMediaVault on Debian"},{"categories":["Linux","Tutorial","Self Hosting"],"contents":"I\u0026rsquo;ve replaced Dropbox with BitTorrent Sync. In order to do this I\u0026rsquo;ve have btsync running on a VPS (2CPU, 2GB, 400GB), my home server and assorted Arch Linux workstations.\nI had a couple of reasons for migrating away from Dropbox.\nDropbox was costing $100 per year. Dropbox encryption model is weak and I have data security/privacy. The VPS I am running BitTorrent Sync on costs $50 per year and provides four times the storage. I run btsync on a VPS so that there is always a server \u0026ldquo;in the cloud\u0026rdquo; that is available to sync with so that my setup emulates what Dropbox used to do.\nAll my servers are running Debian and this is how I install btsync on Debian.\nsh -c \u0026#34;$(curl -fsSL http://debian.yeasoft.net/add-btsync-repository.sh)\u0026#34; sudo apt-get install btsync This is how I respond to the prompts:\n* Do you want to define a default BitTorrent Sync instance? : YES * BitTorrent Sync Daemon Credentials: yourusername * BitTorrent Sync Daemon Group: yourusername * Niceness of the BitTorrent Sync Daemon: 0 * On which portnumber should BitTorrent Sync listen? 0 * BitTorrent Sync Listen Port: 12345 * Do you want BitTorrent Sync to request port mapping via UPNP? NO * Download Bandwith Limit: 0 * Upload Bandwith Limit: 0 * Web Interface Bind IP Address: 0.0.0.0 * Web Interface Listen Port: 8888 * The username for accessing the web interface: yourusername * The password for accessing the web interface: yourpassword As you\u0026rsquo;ll see, I don\u0026rsquo;t use UPNP on my VPS. I elect a specific port (not actually 12345 by the way) and open that port up with ufw. I also only allow access to the WebUI port from another server I own which reverse proxies via nginx.\nbtsync works really well, I have it syncing hundreds of thousands of files that amount to several hundred gigabytes of data. On my Arch Linux workstations I use the brilliant btsync-gui and BitTorrent Sync is also available for Android.\nThat said, I still use a free Dropbox account to sync photos from mine and my wife\u0026rsquo;s Android phones. I have a Dropbox instance running on my home file server and everyday it runs a script to automatically import these photos into Plex.\nSuch a shame, that at the time of writing, btsync is closed source :-( Maybe that will change but if it doesn\u0026rsquo;t syncthing may well be the answer when it has matured a little.\nReferences http://www.yeasoft.com/site/projects:btsync-deb:btsync-server http://forum.bittorrent.com/topic/18974-debian-and-ubuntu-server-packages-for-bittorrent-sync/ ","permalink":"https://wimpysworld.com/posts/setting-up-bitsync-on-debian/","tags":["Debian","BitTorrent Sync","btsync","BitSync","Torrent","syncthing","Dropbox"],"title":"Setting up BitSync on Debian"},{"categories":["Linux","Open Source","Tutorial"],"contents":"I\u0026rsquo;m a member of the MATE Desktop team and until recently the majority of my involvement has been focused around Arch Linux.\nHowever, I\u0026rsquo;m working on a MATE project that is based on a Debian derivative. MATE has recently been accepted into the Debian Backports repository for Wheezy, so I decided to do a \u0026ldquo;MATE from scratch\u0026rdquo; on Debian using an old netbook to get familiar with the MATE package naming differences between Arch Linux and Debian.\nInstall Debian I installed Debian Wheezy from the netinst ISO to ensure the target install was as minimal as possible. I went with the defaults until the \u0026lsquo;Software selection\u0026rsquo; dialogue, at this point unselect everything except \u0026ldquo;SSH server\u0026rdquo;. Like this:\n[ ] Debian desktop environment [ ] Web server [ ] Print server [ ] SQL database [ ] DNS Server [ ] File server [ ] Mail server [X] SSH server [ ] Laptop [ ] Standard system utilities Debian ISO with Firmware If you\u0026rsquo;re installing on hardware that requires additional firmware in order for it to work with Linux then use the netinst ISO that includes firmware.\nhttp://cdimage.debian.org/cdimage/unofficial/non-free/cd-including-firmware/current/ Configure Debian When the install is finished, reboot and configure Debian a little.\nRepositories You\u0026rsquo;ll need to install lsb-release for the following to work.\napt-get install lsb-release This is what I put in /etc/apt/sources.list.\ncat \u0026gt;/etc/apt/sources.list\u0026lt;\u0026lt;EOF deb http://ftp.uk.debian.org/debian/ $(lsb_release -cs) main contrib non-free deb-src http://ftp.uk.debian.org/debian/ $(lsb_release -cs) main contrib non-free deb http://security.debian.org/ $(lsb_release -cs)/updates main contrib non-free deb-src http://security.debian.org/ $(lsb_release -cs)/updates main contrib non-free # $(lsb_release -cs)-updates, previously known as \u0026#39;volatile\u0026#39; deb http://ftp.uk.debian.org/debian/ $(lsb_release -cs)-updates main contrib non-free deb-src http://ftp.uk.debian.org/debian/ $(lsb_release -cs)-updates main contrib non-free EOF Backports MATE is only available in the wheezy-backports repository.\ncat \u0026gt;/etc/apt/sources.list.d/backports.list \u0026lt;\u0026lt;EOF deb http://ftp.uk.debian.org/debian $(lsb_release -cs)-backports main contrib non-free deb-src http://ftp.uk.debian.org/debian $(lsb_release -cs)-backports main contrib non-free EOF Update.\nsudo apt-get update All backports are deactivated by default (i.e. the packages are pinned to 100 by using ButAutomaticUpgrades: yes in the Release files. If you want to install something from backports run:\napt-get -t wheezy-backports install \u0026#34;package\u0026#34; Install MATE Desktop First install the LightDM display manager.\napt-get install accountsservice lightdm lightdm-gtk-greeter Now for the MATE Desktop itself.\napt-get -t wheezy-backports install mate-desktop-environment-extras NetworkManager I typically use NetworkManager, so lets install that too.\napt-get install network-manager-gnome Supplementary Depending on your hardware you may require CPU frequency utilities or additional firmware.\napt-get install cpufreqd cpufrequtil firmware-linux firmware-linux-nonfree And, that\u0026rsquo;s it! Reboot and you\u0026rsquo;ll see the LightDM greeter waiting for your login credentials.\nReferences http://wiki.mate-desktop.org/download?s[]=debian https://wiki.debian.org/InstallingDebianOn/HP/HP2133 ","permalink":"https://wimpysworld.com/posts/mate-desktop-on-debian-wheezy/","tags":["Debian","MATE Desktop","Backports"],"title":"MATE Desktop on Debian Wheezy"},{"categories":["Linux","Development","Open Source"],"contents":"A community developed Ubuntu based operating system that beautifully integrates the MATE desktop. Ubuntu MATE is a stable, easy-to-use operating system with a configurable desktop environment and is suitable for modern workstations, laptops, single board computers and older hardware alike.\nOrganisation: Ubuntu MATE Project Date: June 2014 - date Role: Project Lead ","permalink":"https://wimpysworld.com/projects/ubuntu-mate/","tags":["Ubuntu MATE","Ubuntu","Debian","MATE Desktop","C","GTK","Python","Raspberry Pi","GPD","Community","Entroware","Kernel"],"title":"Ubuntu MATE"},{"categories":["Linux","Open Source","Tutorial","Self Hosting"],"contents":"I switched from BIP to ZNC, and recommend you use ZNC instead!\nBIP is an IRC proxy that maintains a persistent connection(s) to a list of IRC channels. You can then point your IRC client to BIP each time you log in and playback the conversations that took place while you were away.\nI\u0026rsquo;ve found bBIP to be so useful that I now maintain BIP for Arch Linux, although I now run my BIP proxy on Debian because my new VPS provider doesn\u0026rsquo;t offer Arch Linux as an option.\nInstalling BIP Installing BIP is simple for both Arch Linux and Debian.\nDebian I run BIP on Debian Wheezy with the backport repository enabled.\nsudo apt-get -t wheezy-backports install bip sudo sed -i \u0026#39;s/ENABLED=0/ENABLED=1/\u0026#39; /etc/default/bip Arch Linux pacman -S bip systemctl enable bip Create a user The next thing to do is create a username and password and BIP provides it\u0026rsquo;s own utility for doing this called bipmkpw. Replace \u0026lsquo;username\u0026rsquo; with whatever you want your BIP \u0026lsquo;username\u0026rsquo; to be. This name has no relation to any IRC usernames so it can be anything.\nbipmkpw username Enter a password when prompted. The password will then be output as a hash. Make a note of both the hashed and un-hashed values somewhere, you will need them later.\nCreate a certificate We don\u0026rsquo;t want the username and password being sent as clear-text, so we will create an SSL certificate for BIP to use.\nopenssl req -new -newkey rsa:4096 -nodes -x509 -keyout bip.pem -out bip.pem Move the certificate to /var/lib/bip\nsudo mv bip.pem /var/lib/bip Change ownership and permissions of the certificate to the user bip which was created automatically when the package was installed.\nsudo chown bip:bip /var/lib/bip/bip.pem sudo chmod 600 /var/lib/bip/bip.pem Configure BIP Here is example configuration for BIP. Copy it to /etc/bip.conf, modify it accordingly and then change the ownership and permissions.\nsudo chown bip:bip /etc/bip.conf sudo chmod 640 /etc/bip.conf Example configuration # bip default config file. # Thou shoult change thy password ip = \u0026#34;0.0.0.0\u0026#34;; # To connect a client to bip, try the port below, and # be sure to set the password to the value # specified in the network you want to connect to. port = 7778; # If you set this to true, you\u0026#39;ll only be able to connect to bip # with a SSL capable IRC client. Be sure to generate a certificate # for bip with \u0026#39;make cert\u0026#39; client_side_ssl = true; log_level = 3; pid_file=\u0026#34;/var/run/bip/bip.pid\u0026#34;; # This is where logs go. Channel and private messages will use that # configuration value as a prefix, and then log_format to determine # full log filename. log_root = \u0026#34;/var/log/bip/\u0026#34;; # Log format allows you to make log filenames depend on the log line\u0026#39;s # attributes. Here\u0026#39;s a list : # %u -\u0026gt; user name # %n -\u0026gt; network name # %Y -\u0026gt; 4 digit year # %m -\u0026gt; 2 digit month # %d -\u0026gt; 2 digit day # %c -\u0026gt; destination (#chan, privates, ...) #log_format = \u0026#34;%n/%Y-%m/%c.%d.log\u0026#34;; # Sets the frequency (in seconds) of log syncing (real write to kernel) #log_sync_interval = 5; # Makes bip send the log of each channel and privates while # you were not connected to the proxy upon connection. backlog = true; # enable backlog backlog_lines = 0; # number of lines in backlog, 0 means no limit backlog_always = false; # backlog even lines already backlogged # If blreset_on_talk talking on an irc network has the same effect of issuing # /bip blreset, meaning that stuffed logged before the command won\u0026#39;t be read # back on backlog blreset_on_talk = true; # Network definition, a name and server info network { name = \u0026#34;freenode\u0026#34;; server { host = \u0026#34;chat.freenode.net\u0026#34;; port = 6667; }; }; network { name = \u0026#34;blitzed\u0026#34;; server { host = \u0026#34;irc.blitzed.org\u0026#34;; port = 6667; }; }; # Configuration example with one user who connects to two irc networks # To use the multi-server feature: # - define the connections # - chose and setup a different login for each connection # on your irc client: # - Use the multi server feature of your client, the server being each time # the server where bip is running. In your client setup server password to: # username:password:connectionname # - do not store the password in clear here, use the bipmkpw util to generate # a hash # User structure is grouping information for a given user user { # The name in bip of the user # This is used by bip only name = \u0026#34;USERNAME; #BIP User account created with bipmkpw password = \u0026#34;00000000000000000000000000000000000000\u0026#34;; # the hash bipmkpw created ssl_check_mode = \u0026#34;none\u0026#34;; # These will be the default for each connections default_nick = \u0026#34;NICKNAME\u0026#34;; #IRC Nick default_user = \u0026#34;IRCUSERNAME\u0026#34;; #IRC User default_realname = \u0026#34;REALNAME\u0026#34;; #IRC Real Name admin = true; backlog_msg_only = true; # When true, # A user can have mutiple connections to irc networks. # define a connection: connection { name = \u0026#34;freenode\u0026#34;; # used by bip only network = \u0026#34;freenode\u0026#34;; # which ircnet to connect to # these will be sent to the real IRC server user = \u0026#34;IRCUSERNAME\u0026#34;; realname = \u0026#34;IRCREALNAME\u0026#34;; password = \u0026#34;serverpassword\u0026#34;; #can be commented out if not needed # Some options: follow_nick = true; ignore_first_nick = false; #on_connect_send = \u0026#34;PRIVMSG NickServ :IDENTIFY nspassword\u0026#34;; # Autojoined channels: channel { name = \u0026#34;#cat\u0026#34;; }; # Join #cat channel { name = \u0026#34;#dog\u0026#34;; backlog = false; }; # Join #dog but don\u0026#39;t backlog it. channel { name = \u0026#34;#pig\u0026#34;; key = \u0026#34;01nk01nk\u0026#34;; }; # Join #pig that has a password. }; connection { name = \u0026#34;blitzed\u0026#34;; # used by bip only network = \u0026#34;blitzed\u0026#34;; # which ircnet to connect to # these will be sent to the real IRC server user = \u0026#34;IRCUSERNAME\u0026#34;; realname = \u0026#34;IRCREALNAME\u0026#34;; password = \u0026#34;serverpassword\u0026#34;; #can be commented out if not needed # Some options: follow_nick = true; ignore_first_nick = false; #on_connect_send = \u0026#34;PRIVMSG NickServ :IDENTIFY nspassword\u0026#34;; # Autojoined channels: channel { name = \u0026#34;#bar\u0026#34;; }; channel { name = \u0026#34;#foo\u0026#34;; }; }; }; If you require any clarification about what the configuration options do then man bip.conf is your friend.\nStart BIP Now that BIP is configured, it can be started.\nDebian sudo /etc/init.d/bip start Arch Linux sudo systemctl start bip Client configuration I use HexChat, but other IRC clients are available. I add a new Network to HexChat for each of the IRC networks I defined in /etc/bip.conf. The screen shot below shows how I configure a BIP network in HexChat.\nPassword format The Password is the most important and confusing item. This is for BIP, not for any IRC network. Remember the unhashed password? That goes here but with a twist. The format for the password is:\nbipusername:unhashedbippassword:bipnetwork Bipnetwork? What is that? It is from the following section of /etc/bip.conf on the server?\nnetwork { name = \u0026#34;freenode\u0026#34;; server { host = \u0026#34;chat.freenode.net\u0026#34;; port = 6667; }; }; A more practical example:\nmyuser:S3cr3tP@$$w0rd:freenode Conclusion And that\u0026rsquo;s it! We are now perpetually connected to IRC, can connect to BIP proxy from multiple devices in a completely transparent and seamless manner. Moreover, the logs for all channels are saved and automatically rotated on the server.\nIf you looking for an alternative to BIP, then try ZNC.\nReferences\nhttps://wiki.linaro.org/Resources/HowTo/BIP http://nerderati.com/2010/11/perpetual-irc-the-proxy-edition/ http://stevengorrell.com/bip-irc-proxy/ ","permalink":"https://wimpysworld.com/posts/bip-irc-proxy/","tags":["Arch Linux","Debian","IRC","Bouncer","Proxy"],"title":"BIP IRC proxy"},{"categories":["Linux","Open Source","Tutorial"],"contents":"At some point last year I was experimenting with Linux Containers (LXC) on Arch Linux. I never finished the blog post but somehow it was briefly published and then unplublished. I have no idea how accurate this blog post is but someone did see it and bookmarked it. They recently emailed me to ask where the blog has disappeared to, so here it is in all its unfinished glory.\nInstall LXC sudo pacman -Syy --needed --noconfirm arch-install-scripts bridge-utils lxc netctl netctl Bridge The guest containers will connect to the LAN via a bridged network deviced.\nsudo nano /etc/netctl/bridge Add the following.\nDescription=\u0026#34;Bridge\u0026#34; Interface=br0 Connection=bridge BindsToInterfaces=(eth0) IP=dhcp ## sets forward delay time FwdDelay=0 ## sets max age of hello message #MaxAge=10 Enable and start the bridge.\nsudo netctl enable bridge sudo netctl start bridge Creating Containers I\u0026rsquo;m only interested in running Arch Linux or Debian containers.\nContainer Configurations Each container should have a matching configuration file, they look something like this.\nlxc.arch = i686 lxc.utsname = myhostname lxc.network.type = veth lxc.network.flags = up lxc.network.link = br0 lxc.network.ipv4 = 0.0.0.0 lxc.network.name = eth0 lxc.arch Architecture for the container, valid options are x86, i686, x86_64, amd64. lxc.utsman Container name, should also be used when naming the configuration file lxc_network.type Type of network virtualization to be used for the container. The option veth defines a peer network device. It is created with one side assigned to the container and the other side is attached to a bridge by the lxc.network.link option. lxc_network.flags Network actions. The value up in this case activates the network. lxc.network.link Host network interface to be used for the container. lxc.network.ipv4 IPv4 address assigned to the virtualized interface. Use the address 0.0.0.0 to make use of DHCP. Use lxc.network.ipv6 if you need IPv6 support. lxc.network.name Dynamically allocated interface name. This option will rename the interface in the container. More example files can be found in /usr/share/doc/lxc/examples/. Find details about all options via man lxc.conf.\nArch Linux sudo lxc-create -t archlinux -n arch-01 -f ~/arch-01.conf -- --packages netctl I am unable to get DHCP to work for a Arch Linux LXC container, therefore my dirty hack is to alway use a statis IP address in the netctl profile. There is also a bug (#35715) was helpful in narrowing down the problem, but wasn\u0026rsquo;t the solution in my case. Use /var/lib/lxc/CONTAIN_NAME/rootfs/etc/netctl/example/ethernet-static as a template.\nsudo cp /var/lib/lxc/CONTAIN_NAME/rootfs/etc/netctl/example/ethernet-static /var/lib/lxc/CONTAIN_NAME/rootfs/etc/netctl/static Modify /var/lib/lxc/CONTAIN_NAME/rootfs/etc/netctl/static accordingly. Now create a hook, with the same name as the netctl profile.\nsudo nano /var/lib/lxc/CONTAIN_NAME/rootfs/etc/netctl/hooks/static Add the following.\n#!/usr/bin/env bash if [[ $(systemd-detect-virt) != none ]]; then BindsToInterfaces=() ForceConnect=yes fi Start the container and enable the netctl profile.\nnetctl enable static netctl start static Debian Containers. Install debobootstrap and dpkg so that Debian containers can be created.\npacker -S --noedit dpkg debootstrap Squeeze Create a Debian container, squeeze is the default.\nsudo lxc-create -t debian -n squeeze-01 -f ~/squeeze-01.conf Change the root password.\nchroot /var/lib/lxc/squeeze/rootfs/ passwd Wheezy Much the same as the Squeeze exaple above but use the following template.\nhttps://github.com/simonvanderveldt/lxc-debian-wheezy-template Using containers Start a container\nsudo lxc-start -d -n CONTAINER_NAME Connect to the container and log in:\nsudo lxc-console -n CONTAINER_NAME To halt a container cleanly by the containers initv-system:\nsudo lxc-halt -n CONTAINER_NAME Stop and remove your container always with the two steps:\nsudo lxc-stop -n CONTAINER_NAME sudo lxc-destroy -n CONTAINER_NAME References http://nurupoga.org/articles/archlinux-on-lxc-with-netctl/ https://bbs.archlinux.org/viewtopic.php?id=164753 http://andyortlieb.wordpress.com/2013/03/15/practical-use-of-lxc-in-arch-linux-in-march-of-2013/ https://wiki.archlinux.org/index.php/Linux_Containers https://wiki.archlinux.org/index.php/Lxc-systemd https://wiki.archlinux.org/index.php/Netctl https://www.suse.com/documentation/sles11/singlehtml/lxc_quickstart/lxc_quickstart.html http://wiki.gentoo.org/wiki/LXC ","permalink":"https://wimpysworld.com/posts/lxc-on-arch-linux/","tags":["Arch Linux","Containers","LXC","Debian"],"title":"LXC on Arch Linux"},{"categories":["Linux","Open Source","Tutorial"],"contents":"Nikola is a static site and blog generator written in Python that I\u0026rsquo;ve been using for a good while now. This blog post describes how to install Nikola on Debian. Now, this may look like a long winded way to install Nikola, given that Debian .deb package exist, but in my opinion it is the correct way to install Nikola on Debian.\nInstalling Python First you\u0026rsquo;ll need Python and virtualenvwrapper\nsudo apt-get install libpython2.7 python2.7 python2.7-dev python2.7-minimal Remove any apt installed Python packages that we are about to replace. The versions of these packages in the Debian repositories soon get stale.\nsudo apt-get purge python-setuptools python-virtualenv python-pip python-profiler Install pip.\nwget https://bootstrap.pypa.io/get-pip.py sudo python2.7 get-pip.py Use pip to install virtualenv and virtualenvwrapper.\nsudo pip install virtualenv --upgrade sudo pip install virtualenvwrapper The Snakepit Create a \u0026ldquo;Snakepit\u0026rdquo; directory for storing all the virtualenvs.\nmkdir ~/Snakepit Add the following your ~/.bashrc to enable virtualenvwrapper.\nexport WORKON_HOME=${HOME}/Snakepit if [ -f /usr/local/bin/virtualenvwrapper.sh ]; then source /usr/local/bin/virtualenvwrapper.sh elif [ -f /usr/bin/virtualenvwrapper.sh ]; then source /usr/bin/virtualenvwrapper.sh fi Create a virtualenv for Nikola Open a new shell to ensure that the virtualenvwrapper configuration is active. The following will create a new virtualenv called nikola based on Python 2.7.\nmkvirtualenv -p /usr/bin/python2.7 ~/Snakepit/nikola-640 Working on a virtualenv To activate an existing virtualenv do the following.\nworkon nikola-640 You can switch to another virtualenv at any time, just use workon envname. Your shell prompt will change while a virtualenv is being worked on to indicate which virtualenv is currently active.\nWhile working on a virtualenv you can pip install what you need or manually install any Python libraries safe in the knowledge you will not adversely damage any other virtualenvs or the global packages in the process. Very useful for developing a new branch which may have different library requirements than the master/head.\nWhen you are finished working in a virtualenv you can deactivate it by simply executing deactivate.\nInstall Nikola requirements Nikola is will be powered by Python 2.7 and some additional packages will be required.\nsudo apt-get install python2.7-dev libfreetype6-dev libjpeg8-dev libxslt1-dev libxml2-dev libyaml-dev What are these requirements for? python2.7-dev provides the header files for Python 2.7 so that Python modules with C extensions can be built. The following are required to build pillow, the Python imaging library.\nlibjpeg8-dev libfreetype6-dev The following are required to build lxml, a Python XML library.\nlibxml2-dev libxslt1-dev The following are required to build python-coveralls.\nlibyaml-dev Install Nikola Download Nikola.\nmkdir -p ${VIRTUAL_ENV}/src cd ${VIRTUAL_ENV}/src wget https://github.com/getnikola/nikola/archive/v6.4.0.tar.gz -O nikola-640.tar.gz tar zxvf nikola-640.tar.gz cd nikola-6.4.0 Install the Nikola requirements.\npip install -r requirements-full.txt If you intend to use the Nikola planetoid (Planet generator) plugin you\u0026rsquo;ll also need to following.\npip install peewee feedparser Actually install nikola.\npython setup.py install Nikola is now installed. nikola help and the Nikola Handbook will assist you from here on.\n","permalink":"https://wimpysworld.com/posts/installing-nikola-on-debian/","tags":["Nikola","Python","Content Management","Debian","Static Site Generator","virtualenv"],"title":"Installing Nikola on Debian"},{"categories":["Linux","Open Source","Computer Hardware"],"contents":" Note Updated on June 3rd 2014 and now includes LXQt and Unity. For the last 9 months or so I\u0026rsquo;ve spent my spare time working with the MATE Desktop Team. Every so often, via the various on-line MATE communities, the topic of how \u0026ldquo;light weight\u0026rdquo; MATE is when compared to other desktop environments crops up and quite often Xfce is suggested as a lighter alternative. After all MATE and Xfce both provide a traditional desktop environment based on GTK+ so this suggestion is sensible. But is Xfce actually \u0026ldquo;lighter\u0026rdquo; than MATE?\nI\u0026rsquo;ve found MATE to be (subjectively) more responsive that Xfce and there have been two recent blog posts that indicate MATE has lower memory requirements than Xfce.\nFour Lightweight Desktops for openSUSE 13.1 A Memory Comparison of Light Linux Desktops ‚Äì Part 3 Given that I\u0026rsquo;m comfortably running MATE on the Raspberry Pi Model B (which has just 512MB RAM) I\u0026rsquo;ve been stating that MATE is well suited for use on resource constrained hardware and professional workstations alike. This is still true, but I\u0026rsquo;ve also said that MATE is lighter than Xfce and I might have to eat humble pie on that one.\nThe topic of measursing desktop environment resource use came up on the #archlinux-tu IRC channel recently and someone suggested using ps_mem.py to gather the memory usage data. ps_mem.py provides a far more robust mechanism for gathering memory usage data than I\u0026rsquo;ve seen in previous comparisons.\nSo the seed was planted, I created a bunch of VirtualBox guest machines and set to work comparing the memory requirements of all the Linux desktop environments I could.\nDamn it, just tell me what the \u0026ldquo;lightest\u0026rdquo; desktop environment is! OK, for those of you who just want the final answer, with none of the explanation, here it is:\nDesktop Environment Memory Used Enlightenment 0.18.8 83.8 MiB LXDE 0.5.5 87.0 MiB Xfce 4.10.2 110.0 MiB LXQt 0.7.0 113.0 MiB MATE 1.8.1 123.0 MiB Cinnamon 2.2.13 176.3 MiB GNOME3 3.12.2 245.3 MiB KDE 4.13.1 302.6 MiB Unity 7.2.0.14 312.5 MiB Bullshit! How did you come up with these numbers? All the VirtualBox VMs are 32-bit with 768MB RAM and based on the same core Arch Linux installation. I achieved this using my ArchInstaller script which is designed for quickly installing reproducible Arch Linux setups.\nEach VM differs only by the packages that are required for the given desktop environment. The desktop environments native display manager is also installed but if it doesn\u0026rsquo;t have one then lightdm was chosen. LXDE, Xfce, MATE, Cinnamon and GNOME all have gvfs-smb installed as this enables accessing Windows and Samba shares (a common requirement for home and office) in their respective file managers and the KDE install includes packages to provide equivalent functionality. You can see the specific desktop environment packages or package groups that were installed here:\nhttps://github.com/flexiondotorg/ArchInstaller/tree/master/packages/desktop Each VM was booted, logged in and any initial desktop environment configuration was completed choosing the default options if prompted. Then ps_mem was installed, the VM shut down and a snapshot made.\nEach VM was then started, logged in via the display manager, the desktop environment was fully loaded and waited for disk activity to settle. Then ps -efH and ps_mem were executed via SSH and the results sent back to my workstation. When the process and memory collections were conducted there had been no desktop interaction and no applications had been launched.\nYour numbers are wrong I can get xxx desktop to run in yyy less memory! Well done, you probably can.\nEach virtual machine has VirtualBox guest additions, OpenSSH, Network Manager, avahi-daemon, ntpd, rpc.statd, syslog-ng and various other bits and bobs installed and running. Some of these are not required or have lighter alternatives available.\nSo, while I freely accept that each desktop environment can be run in less memory, the results here are relative to a consistent base setup.\nHowever, what is important to note is that I think the Cinnamon results are too low. Cinnamon is forked from GNOME3 and the Arch Linux package groups for Cinnamon only install the core Cinnamon packages but none of the GNOME3 applications or components that would be required to create a full desktop environment.\nSo comparing Cinnamon with the other desktops in this test is not a fair comparison. For example, GNOME3 and KDE default installs on Arch Linux include all the accessibility extensions and applications for sight or mobility impaired individuals where as Cinnamon does not. This is just one example of where I think the Cinnamon results are skewed.\nThe RAM is there to be used. Is lighter actually better? No, and Yes.\nI subscribe to the school of thought that RAM is there to be used. But;\nI want to preserve as much free RAM for the applications I run, not for feature bloat in the desktop environment. I\u0026rsquo;m looking at you KDE. I want a fully integrated desktop experience, but not one that is merely lighter because it lacks features. I\u0026rsquo;m looking at you LXDE. I want a consistent user interface that any of my family could use, not one that favours style over substance. I\u0026rsquo;m looking at you Enlightenment. Another take on lightness is that the more RAM used, the more code that needs executing. Therefore, higher CPU utilisation and degraded desktop performance on modest hardware. This could also translate into degraded battery performance.\nThis is why I choose MATE Desktop. It is a fully integrated desktop environment, that is responsive, feature full, has reasonable memory requirements and scales from single core armv6h CPU with 512MB RAM to multi core x86_64 CPU with 32GB RAM (for me at least).\nWithout the full stats it never happened. Prove it! He is the full data capture from ps_mem.py for each desktop environment.\nEnlightenment Private + Shared = RAM used\tProgram 172.0 KiB + 46.5 KiB = 218.5 KiB\tdbus-launch 316.0 KiB + 40.0 KiB = 356.0 KiB\tdhcpcd 336.0 KiB + 87.5 KiB = 423.5 KiB\trpcbind 560.0 KiB + 37.0 KiB = 597.0 KiB\tcrond 580.0 KiB + 54.0 KiB = 634.0 KiB\tsystemd-logind 688.0 KiB + 67.5 KiB = 755.5 KiB\tsystemd-udevd 480.0 KiB + 276.0 KiB = 756.0 KiB\tavahi-daemon (2) 700.0 KiB + 133.5 KiB = 833.5 KiB\tntpd 768.0 KiB + 78.5 KiB = 846.5 KiB\tVBoxService 580.0 KiB + 267.0 KiB = 847.0 KiB\ttempget 544.0 KiB + 312.0 KiB = 856.0 KiB\tenlightenment_start 764.0 KiB + 94.0 KiB = 858.0 KiB\trpc.statd 600.0 KiB + 280.5 KiB = 880.5 KiB\tat-spi-bus-launcher 624.0 KiB + 298.0 KiB = 922.0 KiB\tat-spi2-registryd 724.0 KiB + 309.5 KiB = 1.0 MiB\taccounts-daemon 784.0 KiB + 386.5 KiB = 1.1 MiB\tenlightenment_fm 952.0 KiB + 395.0 KiB = 1.3 MiB\tefreetd 1.0 MiB + 517.0 KiB = 1.5 MiB\tdbus-daemon (3) 5.3 MiB + -3781.0 KiB = 1.7 MiB\tudisksd 1.2 MiB + 483.0 KiB = 1.7 MiB\t(sd-pam) (2) 1.6 MiB + 234.0 KiB = 1.9 MiB\tsyslog-ng 1.1 MiB + 1.0 MiB = 2.1 MiB\tsystemd (3) 1.4 MiB + 814.5 KiB = 2.2 MiB\tlightdm (2) 1.3 MiB + 1.1 MiB = 2.4 MiB\tsshd (2) 2.6 MiB + 575.5 KiB = 3.2 MiB\tVBoxClient (4) 2.4 MiB + 781.0 KiB = 3.2 MiB\tNetworkManager 10.9 MiB + -7741.5 KiB = 3.3 MiB\tpolkitd 6.2 MiB + 68.5 KiB = 6.3 MiB\tsystemd-journald 11.3 MiB + -2300.0 KiB = 9.1 MiB\tnm-applet 16.3 MiB + 426.0 KiB = 16.7 MiB\tXorg 19.9 MiB + 1.5 MiB = 21.4 MiB\tenlightenment --------------------------------- 89.6 MiB ================================= LXDE Private + Shared = RAM used\tProgram 184.0 KiB + 45.0 KiB = 229.0 KiB\tdbus-launch 320.0 KiB + 36.0 KiB = 356.0 KiB\tdhcpcd 340.0 KiB + 83.0 KiB = 423.0 KiB\trpcbind 360.0 KiB + 78.0 KiB = 438.0 KiB\tlxdm-binary 384.0 KiB + 93.5 KiB = 477.5 KiB\tlxsession 580.0 KiB + 50.0 KiB = 630.0 KiB\tsystemd-logind 700.0 KiB + 55.0 KiB = 755.0 KiB\tsystemd-udevd 464.0 KiB + 297.0 KiB = 761.0 KiB\tavahi-daemon (2) 4.6 MiB + -3890.5 KiB = 821.5 KiB\tmenu-cached 612.0 KiB + 213.0 KiB = 825.0 KiB\tat-spi-bus-launcher 500.0 KiB + 328.0 KiB = 828.0 KiB\tlxdm-session 768.0 KiB + 97.5 KiB = 865.5 KiB\trpc.statd 632.0 KiB + 251.5 KiB = 883.5 KiB\tgvfsd 644.0 KiB + 244.5 KiB = 888.5 KiB\tat-spi2-registryd 776.0 KiB + 189.0 KiB = 965.0 KiB\taccounts-daemon 4.8 MiB + -3888.5 KiB = 1.0 MiB\tgvfsd-fuse 884.0 KiB + 305.0 KiB = 1.2 MiB\tgvfsd-trash 1.1 MiB + 322.0 KiB = 1.4 MiB\tudisksd 1.1 MiB + 381.0 KiB = 1.5 MiB\tupowerd 1.1 MiB + 410.0 KiB = 1.5 MiB\tgvfs-udisks2-volume-monitor 1.0 MiB + 485.5 KiB = 1.5 MiB\tdbus-daemon (3) 1.2 MiB + 507.0 KiB = 1.7 MiB\t(sd-pam) (2) 1.6 MiB + 259.0 KiB = 1.9 MiB\tsyslog-ng 1.2 MiB + 991.5 KiB = 2.1 MiB\tsystemd (3) 1.3 MiB + 1.1 MiB = 2.4 MiB\tsshd (2) 1.5 MiB + 983.0 KiB = 2.4 MiB\tlxpolkit 6.3 MiB + -3414.0 KiB = 3.0 MiB\tNetworkManager 3.3 MiB + 706.5 KiB = 4.0 MiB\topenbox 4.4 MiB + 59.5 KiB = 4.4 MiB\tsystemd-journald 6.9 MiB + -1941.0 KiB = 5.0 MiB\tlxpanel 12.9 MiB + -7745.0 KiB = 5.3 MiB\tpolkitd 3.6 MiB + 1.8 MiB = 5.4 MiB\tpcmanfm 11.5 MiB + -3637.5 KiB = 8.0 MiB\tntpd 7.1 MiB + 1.8 MiB = 9.0 MiB\tnm-applet 13.9 MiB + 604.5 KiB = 14.5 MiB\tXorg --------------------------------- 87.0 MiB ================================= Xfce Private + Shared = RAM used\tProgram 176.0 KiB + 32.0 KiB = 208.0 KiB\tdbus-launch 292.0 KiB + 26.5 KiB = 318.5 KiB\tgpg-agent 316.0 KiB + 32.0 KiB = 348.0 KiB\tdhcpcd 324.0 KiB + 81.0 KiB = 405.0 KiB\trpcbind 488.0 KiB + 96.0 KiB = 584.0 KiB\txfconfd 588.0 KiB + 47.0 KiB = 635.0 KiB\tsystemd-logind 464.0 KiB + 260.0 KiB = 724.0 KiB\tavahi-daemon (2) 712.0 KiB + 49.0 KiB = 761.0 KiB\tsystemd-udevd 608.0 KiB + 173.0 KiB = 781.0 KiB\tat-spi-bus-launcher 644.0 KiB + 169.5 KiB = 813.5 KiB\tat-spi2-registryd 768.0 KiB + 57.5 KiB = 825.5 KiB\tVBoxService 784.0 KiB + 55.5 KiB = 839.5 KiB\tsh 640.0 KiB + 218.5 KiB = 858.5 KiB\tgvfsd 764.0 KiB + 94.5 KiB = 858.5 KiB\trpc.statd 760.0 KiB + 160.0 KiB = 920.0 KiB\taccounts-daemon 872.0 KiB + 174.0 KiB = 1.0 MiB\tgvfsd-fuse 4.8 MiB + -3831.0 KiB = 1.1 MiB\tgvfsd-trash 1.1 MiB + 311.0 KiB = 1.4 MiB\tupowerd 1.1 MiB + 282.0 KiB = 1.4 MiB\ttumblerd 1.1 MiB + 289.0 KiB = 1.4 MiB\tudisksd 1.1 MiB + 369.0 KiB = 1.4 MiB\tgvfs-udisks2-volume-monitor 1.1 MiB + 353.0 KiB = 1.5 MiB\txfce4-notifyd 1.2 MiB + 515.0 KiB = 1.7 MiB\t(sd-pam) (2) 1.3 MiB + 483.5 KiB = 1.8 MiB\tdbus-daemon (3) 1.6 MiB + 248.5 KiB = 1.9 MiB\tsyslog-ng 1.5 MiB + 465.0 KiB = 1.9 MiB\tThunar 5.4 MiB + -3457.5 KiB = 2.0 MiB\tlightdm (2) 1.1 MiB + 992.5 KiB = 2.1 MiB\tsystemd (3) 1.4 MiB + 695.5 KiB = 2.1 MiB\tpanel-6-systray 1.6 MiB + 651.0 KiB = 2.3 MiB\txfce4-session 1.3 MiB + 1.1 MiB = 2.3 MiB\tsshd (2) 1.9 MiB + 525.0 KiB = 2.4 MiB\txfsettingsd 1.6 MiB + 903.0 KiB = 2.5 MiB\tpanel-2-actions 6.3 MiB + -3505.0 KiB = 2.9 MiB\tNetworkManager 2.6 MiB + 442.5 KiB = 3.0 MiB\tVBoxClient (4) 2.6 MiB + 624.5 KiB = 3.2 MiB\txfce4-power-manager (2) 2.1 MiB + 1.1 MiB = 3.2 MiB\txfwm4 3.1 MiB + 1.3 MiB = 4.4 MiB\txfce4-panel 5.0 MiB + 61.5 KiB = 5.0 MiB\tsystemd-journald 12.9 MiB + -7827.0 KiB = 5.3 MiB\tpolkitd 3.8 MiB + 1.6 MiB = 5.4 MiB\txfdesktop 6.6 MiB + 1.3 MiB = 7.8 MiB\tnm-applet 11.5 MiB + -3643.5 KiB = 7.9 MiB\tntpd 23.0 MiB + -3258.0 KiB = 19.8 MiB\tXorg --------------------------------- 110.0 MiB ================================= LXQt Private + Shared = RAM used Program 176.0 KiB + 35.0 KiB = 211.0 KiB dbus-launch 320.0 KiB + 35.0 KiB = 355.0 KiB dhcpcd 324.0 KiB + 83.0 KiB = 407.0 KiB rpcbind 612.0 KiB + 51.0 KiB = 663.0 KiB systemd-logind 460.0 KiB + 267.0 KiB = 727.0 KiB avahi-daemon (2) 676.0 KiB + 53.0 KiB = 729.0 KiB systemd-udevd 580.0 KiB + 179.0 KiB = 759.0 KiB menu-cached (2) 768.0 KiB + 63.5 KiB = 831.5 KiB VBoxService 604.0 KiB + 247.0 KiB = 851.0 KiB at-spi-bus-launcher 768.0 KiB + 96.5 KiB = 864.5 KiB rpc.statd 648.0 KiB + 231.5 KiB = 879.5 KiB at-spi2-registryd 4.7 MiB + -3856.0 KiB = 976.0 KiB accounts-daemon 908.0 KiB + 396.0 KiB = 1.3 MiB lxqt-globalkeysd 1.1 MiB + 425.0 KiB = 1.5 MiB upowerd 1.1 MiB + 484.5 KiB = 1.6 MiB dbus-daemon (3) 1.2 MiB + 551.0 KiB = 1.7 MiB (sd-pam) (2) 1.6 MiB + 248.0 KiB = 1.9 MiB syslog-ng 1.1 MiB + 998.5 KiB = 2.1 MiB systemd (3) 1.3 MiB + 1.0 MiB = 2.3 MiB sshd (2) 1.5 MiB + 933.5 KiB = 2.4 MiB lxqt-policykit-agent 1.6 MiB + 901.0 KiB = 2.4 MiB lxqt-session 1.7 MiB + 837.0 KiB = 2.5 MiB sddm 2.6 MiB + 456.5 KiB = 3.0 MiB VBoxClient (4) 6.3 MiB + -3350.0 KiB = 3.1 MiB NetworkManager 2.4 MiB + 1.5 MiB = 3.8 MiB lxqt-powermanagement 2.6 MiB + 1.5 MiB = 4.1 MiB lxqt-runner 3.4 MiB + 881.0 KiB = 4.3 MiB openbox 2.7 MiB + 1.8 MiB = 4.5 MiB lxqt-notificationd 4.7 MiB + 59.5 KiB = 4.7 MiB systemd-journald 12.5 MiB + -7812.0 KiB = 4.9 MiB polkitd 3.8 MiB + 2.2 MiB = 6.0 MiB lxqt-panel 11.5 MiB + -3644.5 KiB = 7.9 MiB ntpd 11.2 MiB + -2581.0 KiB = 8.7 MiB nm-applet 12.2 MiB + 366.0 KiB = 12.6 MiB pcmanfm-qt 18.2 MiB + -644.0 KiB = 17.6 MiB Xorg --------------------------------- 113.0 MiB ================================= MATE Private + Shared = RAM used\tProgram 248.0 KiB + 57.0 KiB = 305.0 KiB\trtkit-daemon 316.0 KiB + 31.0 KiB = 347.0 KiB\tdhcpcd 344.0 KiB + 81.0 KiB = 425.0 KiB\trpcbind 388.0 KiB + 80.5 KiB = 468.5 KiB\tdbus-launch (2) 4.4 MiB + -4003.0 KiB = 525.0 KiB\tdconf-service 588.0 KiB + 45.0 KiB = 633.0 KiB\tsystemd-logind 552.0 KiB + 117.0 KiB = 669.0 KiB\tgconfd-2 456.0 KiB + 259.0 KiB = 715.0 KiB\tavahi-daemon (2) 548.0 KiB + 189.0 KiB = 737.0 KiB\tgconf-helper 692.0 KiB + 47.0 KiB = 739.0 KiB\tsystemd-udevd 592.0 KiB + 150.5 KiB = 742.5 KiB\tat-spi-bus-launcher 660.0 KiB + 179.5 KiB = 839.5 KiB\tat-spi2-registryd 644.0 KiB + 199.5 KiB = 843.5 KiB\tgvfsd 768.0 KiB + 92.5 KiB = 860.5 KiB\trpc.statd 4.7 MiB + -3955.0 KiB = 893.0 KiB\taccounts-daemon 4.8 MiB + -3943.5 KiB = 1.0 MiB\tgvfsd-fuse 4.8 MiB + -3854.0 KiB = 1.1 MiB\tgvfsd-trash 5.0 MiB + -3789.0 KiB = 1.3 MiB\tupowerd 5.1 MiB + -3817.0 KiB = 1.4 MiB\tudisksd 1.1 MiB + 337.0 KiB = 1.4 MiB\tgvfs-udisks2-volume-monitor 1.6 MiB + 249.5 KiB = 1.9 MiB\tsyslog-ng 1.6 MiB + 429.0 KiB = 2.0 MiB\tpolkit-mate-authentication-agent-1 5.4 MiB + -3485.5 KiB = 2.0 MiB\tlightdm (2) 1.7 MiB + 510.5 KiB = 2.2 MiB\tdbus-daemon (4) 1.3 MiB + 1.0 MiB = 2.3 MiB\tsshd (2) 1.4 MiB + 1.0 MiB = 2.4 MiB\tsystemd (4) 1.8 MiB + 679.5 KiB = 2.4 MiB\t(sd-pam) (3) 1.9 MiB + 570.5 KiB = 2.5 MiB\tmate-screensaver 2.0 MiB + 536.0 KiB = 2.5 MiB\tmate-session 1.9 MiB + 679.5 KiB = 2.6 MiB\tnotification-area-applet 2.1 MiB + 703.0 KiB = 2.8 MiB\tmate-power-manager 2.2 MiB + 596.0 KiB = 2.8 MiB\tNetworkManager 2.7 MiB + 686.5 KiB = 3.4 MiB\tmarco 2.6 MiB + 937.5 KiB = 3.5 MiB\twnck-applet 3.6 MiB + 309.5 KiB = 3.9 MiB\tpulseaudio 2.7 MiB + 1.2 MiB = 3.9 MiB\tmate-volume-control-applet 3.0 MiB + 1.0 MiB = 4.0 MiB\tclock-applet 7.6 MiB + -2931.0 KiB = 4.7 MiB\tmate-settings-daemon 7.7 MiB + -2790.0 KiB = 4.9 MiB\tmate-panel 5.0 MiB + 60.5 KiB = 5.1 MiB\tsystemd-journald 13.0 MiB + -7854.0 KiB = 5.3 MiB\tpolkitd 10.2 MiB + -2592.0 KiB = 7.7 MiB\tcaja 11.5 MiB + -3653.5 KiB = 7.9 MiB\tntpd 7.5 MiB + 1.1 MiB = 8.6 MiB\tnm-applet 14.9 MiB + 1.2 MiB = 16.1 MiB\tXorg --------------------------------- 123.0 MiB ================================= Cinnamon Private + Shared = RAM used\tProgram 248.0 KiB + 56.0 KiB = 304.0 KiB\trtkit-daemon 316.0 KiB + 31.0 KiB = 347.0 KiB\tdhcpcd 340.0 KiB + 82.0 KiB = 422.0 KiB\trpcbind 4.4 MiB + -3995.0 KiB = 469.0 KiB\tdconf-service 384.0 KiB + 88.5 KiB = 472.5 KiB\tdbus-launch (2) 576.0 KiB + 44.0 KiB = 620.0 KiB\tsystemd-logind 556.0 KiB + 115.0 KiB = 671.0 KiB\tgconfd-2 452.0 KiB + 258.0 KiB = 710.0 KiB\tavahi-daemon (2) 544.0 KiB + 185.0 KiB = 729.0 KiB\tgconf-helper 596.0 KiB + 174.5 KiB = 770.5 KiB\tat-spi-bus-launcher 656.0 KiB + 170.5 KiB = 826.5 KiB\tat-spi2-registryd 800.0 KiB + 47.0 KiB = 847.0 KiB\tsystemd-udevd 640.0 KiB + 208.5 KiB = 848.5 KiB\tgvfsd 768.0 KiB + 88.5 KiB = 856.5 KiB\trpc.statd 4.7 MiB + -3946.0 KiB = 910.0 KiB\taccounts-daemon 4.8 MiB + -3938.5 KiB = 1.0 MiB\tgvfsd-fuse 4.8 MiB + -3847.0 KiB = 1.1 MiB\tgvfsd-trash 5.0 MiB + -3818.0 KiB = 1.3 MiB\tupowerd 5.1 MiB + -3819.0 KiB = 1.4 MiB\tudisksd 1.1 MiB + 340.0 KiB = 1.4 MiB\tgvfs-udisks2-volume-monitor 1.1 MiB + 303.0 KiB = 1.4 MiB\tcupsd 1.3 MiB + 394.0 KiB = 1.7 MiB\tcsd-printer 1.6 MiB + 198.5 KiB = 1.8 MiB\tsyslog-ng 1.4 MiB + 599.5 KiB = 2.0 MiB\tlightdm (2) 1.6 MiB + 513.5 KiB = 2.1 MiB\tdbus-daemon (4) 1.3 MiB + 979.0 KiB = 2.2 MiB\tsshd (2) 1.4 MiB + 1.0 MiB = 2.4 MiB\tsystemd (4) 1.9 MiB + 784.5 KiB = 2.6 MiB\t(sd-pam) (3) 6.2 MiB + -3555.0 KiB = 2.7 MiB\tNetworkManager 6.6 MiB + -3794.5 KiB = 2.9 MiB\tcolord 2.7 MiB + 713.5 KiB = 3.4 MiB\tpolkit-gnome-authentication-agent-1 2.8 MiB + 805.0 KiB = 3.6 MiB\tcinnamon-screensaver 3.6 MiB + 341.5 KiB = 3.9 MiB\tpulseaudio 3.2 MiB + 826.5 KiB = 4.0 MiB\tcinnamon-session 4.9 MiB + 56.5 KiB = 5.0 MiB\tsystemd-journald 13.2 MiB + -7890.0 KiB = 5.4 MiB\tpolkitd 3.9 MiB + 2.1 MiB = 6.0 MiB\tnm-applet 5.5 MiB + 2.0 MiB = 7.5 MiB\tcinnamon-settings-daemon 11.4 MiB + -3668.5 KiB = 7.9 MiB\tntpd 8.2 MiB + 1.1 MiB = 9.3 MiB\tcinnamon-launch 7.7 MiB + 2.0 MiB = 9.8 MiB\tnemo 21.2 MiB + -527.5 KiB = 20.7 MiB\tXorg 85.9 MiB + -34668.5 KiB = 52.1 MiB\tcinnamon --------------------------------- 176.3 MiB ================================= GNOME3 Private + Shared = RAM used\tProgram 180.0 KiB + 34.0 KiB = 214.0 KiB\tdbus-launch 276.0 KiB + 14.0 KiB = 290.0 KiB\tssh-agent 248.0 KiB + 51.0 KiB = 299.0 KiB\trtkit-daemon 312.0 KiB + 28.0 KiB = 340.0 KiB\tdhcpcd 324.0 KiB + 21.5 KiB = 345.5 KiB\tsystemd-hostnamed 328.0 KiB + 20.0 KiB = 348.0 KiB\tsystemd-localed 324.0 KiB + 80.0 KiB = 404.0 KiB\trpcbind 580.0 KiB + 52.5 KiB = 632.5 KiB\tbluetoothd 604.0 KiB + 40.0 KiB = 644.0 KiB\tsystemd-logind 556.0 KiB + 109.0 KiB = 665.0 KiB\tgconfd-2 452.0 KiB + 252.0 KiB = 704.0 KiB\tavahi-daemon (2) 680.0 KiB + 44.0 KiB = 724.0 KiB\tsystemd-udevd 548.0 KiB + 182.0 KiB = 730.0 KiB\tgconf-helper 4.6 MiB + -3950.5 KiB = 765.5 KiB\tat-spi2-registryd 596.0 KiB + 185.0 KiB = 781.0 KiB\tat-spi-bus-launcher 768.0 KiB + 50.5 KiB = 818.5 KiB\tVBoxService 696.0 KiB + 146.5 KiB = 842.5 KiB\tgvfsd 768.0 KiB + 86.5 KiB = 854.5 KiB\trpc.statd 4.8 MiB + -3960.0 KiB = 960.0 KiB\taccounts-daemon 852.0 KiB + 137.5 KiB = 989.5 KiB\tgvfsd-fuse 792.0 KiB + 267.0 KiB = 1.0 MiB\tzeitgeist-daemon 5.1 MiB + -3910.5 KiB = 1.3 MiB\tgdm 5.0 MiB + -3853.0 KiB = 1.3 MiB\tupowerd 1.0 MiB + 291.0 KiB = 1.3 MiB\tgvfs-udisks2-volume-monitor 5.1 MiB + -3877.0 KiB = 1.3 MiB\tudisksd 1.1 MiB + 286.0 KiB = 1.4 MiB\tcupsd 1.4 MiB + 133.0 KiB = 1.5 MiB\tgnome-keyring-daemon 1.1 MiB + 448.0 KiB = 1.5 MiB\tgdm-session-worker 1.3 MiB + 359.0 KiB = 1.7 MiB\tgsd-printer 1.2 MiB + 509.0 KiB = 1.7 MiB\t(sd-pam) (2) 1.6 MiB + 192.5 KiB = 1.8 MiB\tsyslog-ng 1.3 MiB + 648.0 KiB = 1.9 MiB\tmission-control-5 5.6 MiB + -3676.5 KiB = 2.0 MiB\tgnome-session 1.1 MiB + 984.5 KiB = 2.1 MiB\tsystemd (3) 1.5 MiB + 573.5 KiB = 2.1 MiB\tzeitgeist-datahub 1.3 MiB + 953.0 KiB = 2.2 MiB\tsshd (2) 6.1 MiB + -3700.5 KiB = 2.5 MiB\tcolord 6.1 MiB + -3656.0 KiB = 2.5 MiB\tNetworkManager 2.2 MiB + 466.0 KiB = 2.6 MiB\tdbus-daemon (3) 2.0 MiB + 728.5 KiB = 2.7 MiB\tgnome-shell-calendar-server 2.6 MiB + 491.5 KiB = 3.1 MiB\tVBoxClient (4) 2.5 MiB + 1.0 MiB = 3.5 MiB\tevolution-source-registry 6.5 MiB + -2914.5 KiB = 3.6 MiB\ttracker-extract 3.5 MiB + 338.5 KiB = 3.9 MiB\tpulseaudio 6.7 MiB + -2828.5 KiB = 3.9 MiB\ttracker-miner-fs 3.4 MiB + 2.1 MiB = 5.5 MiB\tgoa-daemon 13.3 MiB + -7973.0 KiB = 5.5 MiB\tpolkitd 4.9 MiB + 728.0 KiB = 5.7 MiB\ttracker-store 6.1 MiB + 51.5 KiB = 6.2 MiB\tsystemd-journald 4.2 MiB + 2.1 MiB = 6.3 MiB\tnm-applet 11.4 MiB + -3668.5 KiB = 7.9 MiB\tntpd 10.1 MiB + -1729.0 KiB = 8.4 MiB\tgnome-settings-daemon 8.1 MiB + 1.7 MiB = 9.8 MiB\tXorg 10.7 MiB + -816.5 KiB = 9.9 MiB\tevolution-alarm-notify 24.6 MiB + 1.1 MiB = 25.7 MiB\tevolution-calendar-factory 143.2 MiB + -56658.5 KiB = 87.9 MiB\tgnome-shell --------------------------------- 245.3 MiB ================================= KDE Private + Shared = RAM used\tProgram 72.0 KiB + 8.0 KiB = 80.0 KiB\tstart_kdeinit 80.0 KiB + 13.5 KiB = 93.5 KiB\tkwrapper4 128.0 KiB + 23.0 KiB = 151.0 KiB\tagetty 176.0 KiB + 28.0 KiB = 204.0 KiB\tdbus-launch 292.0 KiB + 28.5 KiB = 320.5 KiB\tgpg-agent 320.0 KiB + 28.0 KiB = 348.0 KiB\tdhcpcd 272.0 KiB + 84.0 KiB = 356.0 KiB\tcat (4) 340.0 KiB + 79.0 KiB = 419.0 KiB\trpcbind 604.0 KiB + 39.0 KiB = 643.0 KiB\tsystemd-logind 464.0 KiB + 247.0 KiB = 711.0 KiB\tavahi-daemon (2) 768.0 KiB + 87.5 KiB = 855.5 KiB\trpc.statd 852.0 KiB + 51.5 KiB = 903.5 KiB\tstartkde 352.0 KiB + 669.0 KiB = 1.0 MiB\tsystemd-udevd (2) 656.0 KiB + 524.5 KiB = 1.2 MiB\tkdm (2) 1.1 MiB + 420.0 KiB = 1.5 MiB\tupowerd 852.0 KiB + 780.0 KiB = 1.6 MiB\tklauncher 1.3 MiB + 346.0 KiB = 1.7 MiB\tudisksd 1.5 MiB + 256.5 KiB = 1.8 MiB\takonadi_control 1.3 MiB + 529.0 KiB = 1.8 MiB\t(sd-pam) (2) 1.6 MiB + 201.5 KiB = 1.8 MiB\tsyslog-ng 1.5 MiB + 409.5 KiB = 1.9 MiB\tdbus-daemon (2) 1.2 MiB + 971.5 KiB = 2.1 MiB\tsystemd (3) 656.0 KiB + 1.5 MiB = 2.2 MiB\tkdeinit4 1.3 MiB + 997.0 KiB = 2.3 MiB\tsshd (2) 1.3 MiB + 1.6 MiB = 2.9 MiB\tkio_trash (2) 2.1 MiB + 1.1 MiB = 3.2 MiB\tklipper 6.9 MiB + -3587.0 KiB = 3.4 MiB\tNetworkManager 2.4 MiB + 1.0 MiB = 3.5 MiB\tksmserver 3.2 MiB + 594.5 KiB = 3.8 MiB\tkuiserver 3.2 MiB + 952.5 KiB = 4.1 MiB\tkglobalaccel 3.4 MiB + 829.5 KiB = 4.2 MiB\takonadi_migration_agent 3.4 MiB + 837.5 KiB = 4.3 MiB\tpolkit-kde-authentication-agent-1 3.8 MiB + 716.5 KiB = 4.5 MiB\tknotify4 4.4 MiB + 49.5 KiB = 4.5 MiB\tsystemd-journald 3.8 MiB + 891.0 KiB = 4.7 MiB\tbaloo_file 3.8 MiB + 975.0 KiB = 4.7 MiB\takonadi_maildispatcher_agent 3.8 MiB + 983.0 KiB = 4.7 MiB\takonadi_baloo_indexer 4.1 MiB + 1.3 MiB = 5.4 MiB\takonadi_newmailnotifier_agent 4.3 MiB + 1.1 MiB = 5.4 MiB\tkorgac 13.2 MiB + -7804.0 KiB = 5.6 MiB\tpolkitd 5.5 MiB + 1.7 MiB = 7.1 MiB\takonadi_notes_agent 11.1 MiB + -3575.0 KiB = 7.6 MiB\tkactivitymanagerd 5.6 MiB + 2.1 MiB = 7.7 MiB\takonadi_sendlater_agent 11.4 MiB + -3697.5 KiB = 7.8 MiB\tntpd 7.2 MiB + 777.5 KiB = 8.0 MiB\takonadiserver 6.0 MiB + 2.9 MiB = 8.9 MiB\takonadi_archivemail_agent 6.3 MiB + 2.6 MiB = 8.9 MiB\tkmix 6.1 MiB + 2.9 MiB = 9.0 MiB\takonadi_mailfilter_agent 6.9 MiB + 2.4 MiB = 9.3 MiB\tkded4 9.1 MiB + 2.7 MiB = 11.7 MiB\takonadi_agent_launcher (3) 13.8 MiB + -1069.5 KiB = 12.8 MiB\tkwin 13.2 MiB + 3.2 MiB = 16.5 MiB\tkrunner 68.8 MiB + -49024.0 KiB = 21.0 MiB\tmysqld 30.3 MiB + -2270.0 KiB = 28.1 MiB\tXorg 36.9 MiB + 6.8 MiB = 43.7 MiB\tplasma-desktop --------------------------------- 302.6 MiB ================================= Unity Private + Shared = RAM used\tProgram 92.0 KiB + 14.0 KiB = 106.0 KiB\tcat 128.0 KiB + 21.0 KiB = 149.0 KiB\tagetty 180.0 KiB + 28.0 KiB = 208.0 KiB\tdbus-launch 252.0 KiB + 47.0 KiB = 299.0 KiB\trtkit-daemon 312.0 KiB + 27.0 KiB = 339.0 KiB\tdhcpcd 324.0 KiB + 18.0 KiB = 342.0 KiB\tsystemd-localed 336.0 KiB + 21.0 KiB = 357.0 KiB\tsystemd-timedated 344.0 KiB + 79.0 KiB = 423.0 KiB\trpcbind 412.0 KiB + 69.0 KiB = 481.0 KiB\tdconf-service 592.0 KiB + 39.0 KiB = 631.0 KiB\tsystemd-logind 588.0 KiB + 92.5 KiB = 680.5 KiB\tindicator-messages-service 448.0 KiB + 245.0 KiB = 693.0 KiB\tavahi-daemon (2) 604.0 KiB + 89.5 KiB = 693.5 KiB\tindicator-bluetooth-service 548.0 KiB + 168.0 KiB = 716.0 KiB\tgconf-helper 4.6 MiB + -3955.0 KiB = 725.0 KiB\tat-spi-bus-launcher 684.0 KiB + 42.0 KiB = 726.0 KiB\tsystemd-udevd 640.0 KiB + 100.0 KiB = 740.0 KiB\tgconfd-2 636.0 KiB + 115.5 KiB = 751.5 KiB\tat-spi2-registryd 652.0 KiB + 144.5 KiB = 796.5 KiB\tindicator-power-service 648.0 KiB + 158.5 KiB = 806.5 KiB\tgvfsd 772.0 KiB + 45.5 KiB = 817.5 KiB\tVBoxService 768.0 KiB + 85.5 KiB = 853.5 KiB\trpc.statd 796.0 KiB + 122.0 KiB = 918.0 KiB\taccounts-daemon 568.0 KiB + 391.5 KiB = 959.5 KiB\t(sd-pam) 4.8 MiB + -3982.5 KiB = 969.5 KiB\tgvfsd-fuse 824.0 KiB + 253.0 KiB = 1.1 MiB\tdbus (2) 828.0 KiB + 271.0 KiB = 1.1 MiB\tzeitgeist-daemon 4.9 MiB + -3904.0 KiB = 1.1 MiB\tgvfsd-trash 1.0 MiB + 131.5 KiB = 1.2 MiB\tindicator-session-service 5.0 MiB + -3883.0 KiB = 1.2 MiB\tupowerd 1.1 MiB + 237.0 KiB = 1.3 MiB\tcupsd 1.1 MiB + 279.0 KiB = 1.4 MiB\tgvfs-udisks2-volume-monitor 5.1 MiB + -3857.0 KiB = 1.4 MiB\tudisksd 1.1 MiB + 324.5 KiB = 1.4 MiB\tzeitgeist-fts 5.1 MiB + -3833.0 KiB = 1.4 MiB\tindicator-application-service 1.2 MiB + 382.0 KiB = 1.6 MiB\tindicator-sound-service 1.6 MiB + 174.5 KiB = 1.8 MiB\tsyslog-ng 5.6 MiB + -3769.0 KiB = 1.9 MiB\tgnome-session 932.0 KiB + 1.0 MiB = 1.9 MiB\tsystemd (2) 1.4 MiB + 537.0 KiB = 2.0 MiB\tlightdm (2) 1.4 MiB + 753.0 KiB = 2.1 MiB\tmission-control-5 1.3 MiB + 936.0 KiB = 2.2 MiB\tsshd (2) 1.8 MiB + 531.0 KiB = 2.3 MiB\tzeitgeist-datahub 6.2 MiB + -3779.0 KiB = 2.5 MiB\tcolord 2.2 MiB + 458.5 KiB = 2.6 MiB\tdbus-daemon (3) 6.2 MiB + -3682.0 KiB = 2.6 MiB\tNetworkManager 2.3 MiB + 515.0 KiB = 2.8 MiB\tgnome-fallback-mount-helper 2.3 MiB + 485.0 KiB = 2.8 MiB\tpolkit-gnome-authentication-agent-1 2.4 MiB + 514.0 KiB = 2.9 MiB\tnotify-osd 2.5 MiB + 417.5 KiB = 3.0 MiB\tVBoxClient (4) 2.6 MiB + 547.5 KiB = 3.1 MiB\tindicator-keyboard-service 2.7 MiB + 657.0 KiB = 3.3 MiB\tindicator-printers-service 2.7 MiB + 854.0 KiB = 3.5 MiB\ttelepathy-indicator 2.5 MiB + 1.1 MiB = 3.6 MiB\tevolution-source-registry 3.1 MiB + 577.0 KiB = 3.7 MiB\tbamfdaemon 3.6 MiB + 306.5 KiB = 3.9 MiB\tpulseaudio 3.0 MiB + 933.0 KiB = 3.9 MiB\tindicator-datetime-service 3.9 MiB + 1.3 MiB = 5.3 MiB\tunity-panel-service 13.2 MiB + -7982.0 KiB = 5.4 MiB\tpolkitd 4.4 MiB + 1.8 MiB = 6.1 MiB\tnm-applet 6.1 MiB + 747.0 KiB = 6.9 MiB\tgoa-daemon 7.3 MiB + 50.5 KiB = 7.3 MiB\tsystemd-journald 11.4 MiB + -3690.5 KiB = 7.8 MiB\tntpd 5.3 MiB + 4.5 MiB = 9.8 MiB\tgnome-settings-daemon 11.6 MiB + 1.0 MiB = 12.6 MiB\tnautilus 24.7 MiB + 1.2 MiB = 25.8 MiB\tevolution-calendar-factory 40.2 MiB + -351.0 KiB = 39.9 MiB\tXorg 103.2 MiB + -4818.0 KiB = 98.5 MiB\tcompiz --------------------------------- 312.5 MiB ================================= Final thoughts On Arch Linux at least, Xfce has lower resource requirements than MATE. When I said different in the past I was wrong, unless you use openSUSE in which case I was probably right, maybe.\n","permalink":"https://wimpysworld.com/posts/memory-consumption-of-linux-desktop-environments/","tags":["Arch Linux","MATE Desktop","Xfce","GNOME","KDE","Enlightment","LXDE","LXQt","Unity","ps_mem"],"title":"Memory consumption of Linux desktop environments"},{"categories":["Linux","Development","Open Source"],"contents":"Mentored three students for the openSUSE 2014 Google Summer of Code. All three students successfully completed their projects for the MATE Desktop.\nOrganisation: openSUSE Date: February 2014 - August 2014 Role: Student mentor ","permalink":"https://wimpysworld.com/projects/opensuse/","tags":["openSUSE","MATE Desktop","C","GTK","Python","Google Summer of Code","Mentor"],"title":"openSUSE"},{"categories":["Linux","Broadcasting","Open Source","Content Creation"],"contents":"LINUX Unplugged is a weekly show, by Jupiter Broadcasting, that debates and discusses developments and goings on in the Linux community. I joined as a regular contributor in January 2014.\nOrganisation: Jupiter Broadcasting Date: January 2014 - February 2021 Role: Talking Head ","permalink":"https://wimpysworld.com/projects/linux-unplugged/","tags":["Podcast","Live Show"],"title":"LINUX Unplugged"},{"categories":["Linux","Development","Open Source"],"contents":"Arch Linux is a Linux distribution that uses a rolling release model, such that a regular system update is all that is needed to obtain all the latest software. The design approach follows the KISS principle (\u0026ldquo;keep it simple, stupid\u0026rdquo;) and focuses on elegance, code correctness, minimalism and simplicity.\nOrganisation: Arch Linux Date: December 2013 - December 2016 Role: Trusted user \u0026amp; Package maintainer ","permalink":"https://wimpysworld.com/projects/arch-linux/","tags":["Arch Linux","MATE Desktop","PKGBUILD","pacman","systemd","AUR"],"title":"Arch Linux"},{"categories":["Linux","Open Source","Tutorial","Computer Hardware"],"contents":"I have an old Thinkpad T43p that I am trying to extend the life of. So I recently fitted a cheap 60GB IDE Solid State Drive (SSD) and put a 320GB SATA Hard Disk Drive (HDD) in the Ultrabay. This is not a true hybrid disk, but the principles are similar. The root partition will go on the SDD (for performance) and the home partition will be located on the HDD (for capacity).\nI\u0026rsquo;ve been running Arch Linux on the T43p and the SDD improves system responsiveness and boot time considerably, especially when using F2FS or btrfs (with LZO compression and SSD mount options) on the root filesystem.\nI am also testing Linux Mint Debian Edition (LMDE) with the MATE Desktop desktop to determine if this is a suitable operating system for my family to use. It appears they find GNOME 3 confusing and would prefer a familiar desktop experience.\nWhile testing LMDE 201203 I ran into a few issues, so I\u0026rsquo;ve decided to capture my notes here for future reference.\nFix the installer In order to install LMDE using partitions on multiple drives you must use the ADVANCED USER install mode. However, the ADVANCED USER install mode has a bug that prevents the installer from completing, so that needs to be fixed first.\nsudo nano /usr/lib/live-installer/frontend/gtk_interface.py Find the following on line 1765.\nself.wTree.get_widget(\u0026#34;button_next\u0026#34;).show() After it add the following line, making sure the indentation is correct.\nself.wTree.get_widget(\u0026#34;button_next\u0026#34;).set_sensitive(True) Installing LMDE Double click the Install Linux Mint icon on the desktop. Select your Language and click Forward. Select your Timezone and click Forward. Select your Keyboard layout and click Forward. Enter your User info and click Forward. From the Hard drive window Select Manually mount partitions (ADVANCED USERS ONLY) and click Forward. The Please make sure you wish to manually manage partitions window will appear. On my system the SSD is detected on /dev/sda and the HDD is detected on /dev/sdb. Start GParted and partition and format the drives as follows.\n/dev/sda1 Size: 256MiB Create as: Primary Partition File system: ext4 Label: boot /dev/sda2 Size: 2048MiB (or the size you prefer) Create as: Primary Partition File system: linux-swap Label: swap /dev/sda3 Size: Remainder Create as: Primary Partition File system: btrfs Label: root /dev/sdb1 Size: All Create as: Primary Partition File system: ext4 Label: home Apply the changes and close GParted.\nI use ext4 for the /boot partition because GRUB can\u0026rsquo;t currently boot from btrfs in LMDE. I use ext4 for /home because it offers the best performance on rotational drives on my Thinkpad T43p. I use btrfs on the /root partition because performs best (by some margin) on solid state drives in my Thinkpad T43p.\nThe filesystems need mounting under /target so the installer can install the OS. Open a Terminal and do the following.\nsudo mkdir /target sudo mount -t btrfs -o compress=lzo,ssd /dev/disk/by-label/root /target sudo mkdir /target/{boot,home} sudo mount -t ext4 /dev/disk/by-label/boot /target/boot sudo mount -t ext4 /dev/disk/by-label/home /target/home Return to the Linux Mint Debian Installer.\nClick Forward. From the Advanced options check Install GRUB and select /dev/sda. Click Forward. Confirm the Summary is correct and click Install. Time for a cup of tea while the install runs. A pop-up, titled Installation Paused, will appear. Click OK.\nCreate /target/etc/fstab Do as the installer says and create /target/etc/fstab. Open a Terminal.\nsudo nano /target/etc/fstab The following fstab works for my T43p.\n# /etc/fstab: static file system information. # # \u0026lt;file system\u0026gt; \u0026lt;mount point\u0026gt; \u0026lt;type\u0026gt; \u0026lt;options\u0026gt; \u0026lt;dump\u0026gt; \u0026lt;pass\u0026gt; proc /proc proc defaults 0 0 LABEL=root / btrfs defaults,noatime,compress=lzo,ssd 0 1 LABEL=boot /boot ext4 defaults,noatime 0 2 LABEL=home /home ext4 defaults,relatime 0 2 LABEL=swap none swap sw 0 0 Upgrade MATE 1.6 and remove legacy MATE 1.4 packages MATE 1.6 has been released for LMDE 201203 so it is a good idea to upgrade and remove legacy packages before the first boot to ensure a clean configuration. Open a Terminal.\nsudo chroot /target apt-get update apt-get install apt-show-versions apt-get dist-upgrade Some MATE 1.4 packages will be left behind that are no longer required. The following can help identify them.\napt-show-versions | grep 1\\.4\\.[0-9]\\-[0-9]\\+wheezy | cut -f1 -d\u0026#39; \u0026#39; Purge the old MATE 1.4 packages.\nPKGS=`apt-show-versions | grep 1\\.4\\.[0-9]\\-[0-9]\\+wheezy | cut -f1 -d\u0026#39; \u0026#39;` apt-get purge ${PKGS} Exit the chroot.\nexit Finish the install Return to the Linux Mint Debian Installer.\nClick Forward. Some final installation steps will now complete. A pop-up, titled Installation finished, will appear. Click Yes. Your computer will reboot and start LMDE.\nReferences http://forums.linuxmint.com/viewtopic.php?f=189\u0026amp;t=129381 http://forums.linuxmint.com/viewtopic.php?f=185\u0026amp;t=143547 ","permalink":"https://wimpysworld.com/posts/linux-mint-lmde-on-hybrid-disk-laptop/","tags":["Linux Mint","Debian","LMDE","MATE Desktop","Python","btrfs","F2FS","ThinkPad T43p"],"title":"Linux Mint LMDE on Hybrid Disk Laptop"},{"categories":["Linux","Open Source","Tutorial","Self Hosting","Home Cinema"],"contents":"I\u0026rsquo;ve recently started using Plex Media Server to handle most media streaming duties around the house. I run in on Open Media Vault 0.5.x. At the time of writing Open Media Vault is based on Debian (Squeeze) 6.0.\nPlex Media Server Anyway, it turns out that installing Plex Media Server on Open Media Vault is super simple thanks to the hard work of Christian Svedin who has packaged everything and made it available via an apt repository.\nsudo apt-get install curl echo \u0026#34;deb http://shell.ninthgate.se/packages/debian squeeze main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/plexmediaserver.list curl http://shell.ninthgate.se/packages/shell-ninthgate-se-keyring.key | sudo apt-key add - sudo apt-get update sudo apt-get install plexmediaserver The instructions above also work for Debian Wheezy, just change squeeze to wheezy in /etc/apt/sources.list.d/plexmediaserver.list.\nWhen the install is complete point your browser at Plex/Web, for example:\nhttp://plex.example.org:32400/web Replace plex.example.org with your Plex Media Server hostname/ip address.\nIf you have PlexPass then head over to the Preview Releases for Debian and download and install the latest .deb.\nPlex Clients I use the Plex Client for Android on phone and tablet, a Roku 2 XS in the lounge and Roku 2 LT in the bedroom.\nI\u0026rsquo;ve successfully tested Plex Home Theatre on Ubuntu 12.04 and Raspbmc with the PleXBMC plug-in on Raspberry Pi.\nReferences http://forums.plexapp.com/index.php/topic/51427-plex-media-server-for-debian/ http://forums.plexapp.com/index.php/topic/48865-debian-package/ ","permalink":"https://wimpysworld.com/posts/plex-media-server-on-open-media-vault/","tags":["Debian","Plex","Open Media Vault"],"title":"Plex Media Server on Open Media Vault"},{"categories":["Linux","Open Source","Tutorial","Self Hosting","Home Cinema"],"contents":"I have Open Media Vault running on a HP ProLiant MicroServer G7 N54L.\nOpenMediaVault (OMV) is a network attached storage (NAS) solution based on Debian Linux. At the time of writing OMV 0.5.x is based on Debian 6.0 (Squeeze).\nIn recent months Plex has taken over just about all media streaming duties in our house, with the expectation of streaming music because Plex music playback and streaming is seriously lacking (no playlists!). So, MiniDLNA is still required for serving up music around the house.\nInstall MiniDLNA on OMV There is a 3rd party plugin repository for Open Media Vault which includes packages to install MiniDLNA and a WebUI plugin for managing MiniDLNA via OMV. I upgraded to OMV 0.5.x this morning. and with the 0.5.x the Plugin API changed and as of the time of writing none of the 3rd party plugins had not been migrated to OMV 0.5.x. That said, MiniDLNA is super simple to configure so a WebUI is not a requirement for me.\nMiniDLNA is not currently packaged for Debian Squeeze in the official repositories but Steve Kemp has packaged a fairly up-to-date version of MiniDLNA for Squeeze. Brilliant! Do the following as root to install MiniDLNA.\nwget http://packages.steve.org.uk/minidlna/apt-key.pub apt-key add apt-key.pub echo deb http://packages.steve.org.uk/minidlna/squeeze/ ./\u0026#34; \u0026gt; /etc/apt/sources.list.d/minidlna.list echo \u0026#34;deb-src http://packages.steve.org.uk/minidlna/squeeze/ ./\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list.d/minidlna.list Once you\u0026rsquo;ve done that run the following.\napt-get update apt-get install minidlna The MiniDLNA defaults in Steve\u0026rsquo;s package assume you have your music in /srv/music. So you\u0026rsquo;ll probably need to modify /etc/minidlna/minidlna.conf accordingly. From this point man minidlna and man minidlna.conf will guide you.\nReferences http://blog.steve.org.uk/minidlna_is_now_packaged.html http://packages.steve.org.uk/minidlna/ http://sourceforge.net/projects/minidlna/ ","permalink":"https://wimpysworld.com/posts/setting-up-minidlna-on-open-media-vault/","tags":["Debian","Open Media Vault","MiniDLNA","DLNA"],"title":"Setting up MiniDLNA on Open Media Vault"},{"categories":["Linux","Open Source","Tutorial"],"contents":"I use SketchUp at work to manipulate models for use in Google Earth. Here is how I got SketchUp Make 2013 installed and working on Arch Linux under Wine 1.7.\nWine for Arch Linux Install Wine on Arch Linux as follows.\nsudo pacman -S --needed icoutils libwbclient libxslt lib32-mpg123 p11-kit lib32-p11-kit samba wine winetricks wine-mono wine_gecko sudo packer -S --noedit --noconfirm ttf-ms-fonts For 64-bit also install the following.\nsudo packer -S --noedit --noconfirm lib32-libwbclient lib32-libxslt Installing SketchUp Make Once Wine is installed download SketchUp Make 2013.\nhttp://www.sketchup.com/download Create a clean wine prefix.\nexport WINEPREFIX=\u0026#34;${HOME}/.sketchup\u0026#34; export WINEARCH=\u0026#34;win32\u0026#34; wineboot Install corefonts using winetricks\nwinetricks corefonts Start the SketchUp Make setup.\nwine SketchUpWEN.exe Follow the installation wizard, I just went with the defaults.\nThat\u0026rsquo;s it. SketchUp is installed and should be associated with the appropriate file types.\nVideo Corruption My workstation has a Radeon 5000 series graphics card and I use the Open Source radeon driver. I don\u0026rsquo;t know if this problem is specific to my hardware/drivers but SketchUp will eventually (sometimes immediately) encounter video corruption. Once that happens I can\u0026rsquo;t see or manipluate the models.\nThe solution that works for me is:\nenv WINEPREFIX=\u0026#34;${HOME}/.sketchup\u0026#34; LIBGL_ALWAYS_SOFTWARE=1 vblank_mode=0 wine \u0026#34;C:\\Program Files\\SketchUp\\SketchUp 2013\\SketchUp.exe\u0026#34; If this also works for you then SketchUp.desktop can be modified to persist these settings.\nnano ~/.local/share/applications/wine/Programs/SketchUp\\ 2013/SketchUp.desktop Replace the contents with what follows but change USER with your username.\n[Desktop Entry] Name=SketchUp Exec=env WINEPREFIX=\u0026#34;/home/USER/.sketchup\u0026#34; LIBGL_ALWAYS_SOFTWARE=1 vblank_mode=0 wine C:\\\\\\\\windows\\\\\\\\command\\\\\\\\start.exe /Unix /home/USER/.sketchup/dosdevices/c:/users/USER/Start\\\\ Menu/Programs/SketchUp\\\\ 2013/SketchUp.lnk Type=Application StartupNotify=true Icon=1871_SketchUpIcon.0 Uninstalling SketchUp Make Should you ever need to, you can uninstall SketchUp Make as follows.\nrm -rfv ${HOME}/.sketchup/ rm -rfv ~/.local/share/applications/wine/Programs/SketchUp\\ 2013/ References http://appdb.winehq.org/objectManager.php?sClass=version\u0026amp;iId=28620 ","permalink":"https://wimpysworld.com/posts/sketchup-make-on-arch-linux/","tags":["wine","SketchUp","Arch Linux"],"title":"SketchUp Make on Arch Linux"},{"categories":["Linux","Open Source","Tutorial","Self Hosting"],"contents":"I\u0026rsquo;ve installed Open Media Vault (OMV) on my new HP ProLiant MicroServer G7 N54L to replace my aging, and lackluster, ReadyNAS NV.\nOpenMediaVault (OMV) is a network attached storage (NAS) solution based on Debian Linux. At the time of writing OMV 0.5.x is based on Debian 6.0 (Squeeze).\nThis blog post is not going to cover the extremely simple OMV installation procedure, it assumes OMV 0.5.x is already installed. This post explains how to upgrade the kernel, install some addtional plugins and some hackery to update Transmission.\nThis blog post is basically the essential notes I need to recreate my server setup.\nN54L Custom BIOS I\u0026rsquo;ve installed one of the custom BIOS mods for the N54L.\nHP N36L/N40L/N54L Microserver Updated AHCI BIOS Support I selected the BIOS mod above because the guy who created was an HP engineer and this BIOS mod only enables additional features that the N54L can actually support. Using this BIOS mod I\u0026rsquo;ve been able to:\nEnable AHCI for the Optical Disk Drive (ODD) port. Enable AHCI and port multiplier for the the e-SATA port. Make all drives hot-pluggable. The 250GB hard drive that came with N54L is now relocated in the optical drive day and being used as the OS drive, leaving all 4 bays for data.\nAs some point in the future I may want to hook up a 4 bay e-SATA enclosure and this BIOS mod makes that possible.\nOpen Media Vault Once Open Media Vault is installed, I do the following.\nEnable SSH OMV actually has a really good WebUI that can be used to accomplish most update/upgrade tasks but I can\u0026rsquo;t help myself. I must have shell access. From the OMV WebUI:\nServices -\u0026gt; SSH Put a tick in Enable and click the OK button. Shell Tools Things crave when at the a shell.\nLogin to your OMV server as root using SSH and then do the following.\napt-get install less lsb-release rsync screen tree OMV Plugins OMV has a number of built-in plugins and a third party repository of plugins.\nBuilt-in Plugins Update the built-in plugins.\nSystem -\u0026gt; Plugins Click the Check icon. Logical Volume Manager I use LVM. There, I said it. Enable the LVM2 plugin as follows from the OMV WebUI.\nSystem -\u0026gt; Plugins Highlight the openmediavault-lvm2 plugin. Click the Install icon and then Yes. When the install is Done ..., click Close. 3rd Party OMV-Plugins Follow the instructions on the following page to enable the OMV-Extras plugin repository.\nhttp://omv-extras.org/simple/index.php?id=how-to-install-omv-extras-plugin Backports 3.2 Kernel I updated the Kernel to 3.2 because it better supports the N54L hardware, in particular the embedded graphics controller. The Linux 3.2 kernel can be installed via OMV-Extras.\nSystem -\u0026gt; OMV-Extras.org -\u0026gt; Install Backports 3.2 kernel Plex Media Server Plex Media Server is available as a plugin once the OMV-Extras plugin repository is enabled. Plex is managed via the OMV WebUI.\nServices -\u0026gt; Plex Transmission Transmission is available as a plugin once the OMV-Extras plugin repository is enabled. Transmission is managed via the OMV WebUI.\nServices -\u0026gt; BitTorrent -\u0026gt; Server. It\u0026rsquo;s all very straight forward. I use the following block list.\nhttp://list.iblocklist.com/?list=bt_level1\u0026amp;fileformat=p2p\u0026amp;archiveformat=gz That pretty much covers the stuff I won\u0026rsquo;t remember in the future. I\u0026rsquo;m considering adding LXC and Dropbox in the coming that will require some manual steps.\nReferences http://thekentishman.wordpress.com/guides-2/open-media-vault-set-up/ http://myhpmicroserver.com/wiki/Main_Page ","permalink":"https://wimpysworld.com/posts/setting-up-open-media-vault-on-the-hp-microserver-n54l/","tags":["Debian","Open Media Vault","HP MicroServer","N54L","BIOS","Transmission","Plex","Hacking"],"title":"Setting up Open Media Vault on the HP MicroServer N54L"},{"categories":["Linux","Open Source","Tutorial","Security"],"contents":"Recently I\u0026rsquo;ve been deploying Debian 6.0 (Squeeze) and 7.0 (Wheezy) servers for some personal projects. These servers are provisioned in different ways:\nOpen Media Vault using a Squeeze pre-seed VPS powered by LXC deployed via debootstrap VPS powered by KVM using the hosting providers Wheezy pre-seed Consequently the basic install differs on each instance and requires a little bit of post install tweaking to get them all consistent. This blog post is a quick reference for the post install steps I complete on Debian servers.\nTimezone \u0026amp; Locale Select your timezone.\ndpkg-reconfigure tzdata Select your locale(s).\ndpkg-reconfigure locales Make sure the locales are correctly generated. Replace en_GB.UTF-8 with your default locale.\nupdate-locale LANG=en_GB.UTF-8 LANGUAGE=en_GB.UTF-8 LC_ALL=en_GB.UTF-8 LC_TIME=en_GB.UTF-8 LC_CTYPE=en_GB.UTF-8 locale -a locale-gen Hostname echo box.example.org \u0026gt; /etc/hostname /bin/hostname -F /etc/hostname Update /etc/hosts accordingly.\nTime Keeping time is essential.\napt-get install ntp ntpdate Force a clock sync.\nservice ntp stop ntpdate -s pool.ntp.org service ntp start If your VPS is a Xen DomU then checkout the following.\nhttp://jinntech.blogspot.co.uk/2009/03/xen-and-keeping-time.html Essentials These are the essential tools I require.\napt-get install build-essential curl git htop less lsb-release nano \\ rsync screen sudo tree whois Users The following will create a user with sudo capabilities.\nuseradd user_a --create-home --shell /bin/bash --user-group \\ --groups adm,dialout,cdrom,plugdev,sudo This will create a regular user.\nuseradd user_b --create-home --shell /bin/bash --user-group --groups adm,dialout,cdrom,plugdev Assign a password.\necho user_a:mypassword | chpasswd An existing user can be made a sudoer by simply adding them to the sudo group.\nadduser user_b sudo Firewall I use firewall my VPS server with ufw. This is my initial configuration that allow access via SSH only.\nsudo apt-get install ufw Configuring ufw is simple but make sure you have console access to the host you are configuring just in case you lock yourself out.\nNOTE! When enabling ufw the chains are flushed and connections may be dropped. You can add rules to the firewall before enabling it however, so if you are testing ufw on a remote machine it is recommended you perform\u0026hellip;\nufw allow ssh/tcp \u0026hellip;before running sudo ufw enable. Once the firewall is enabled, adding and removing rules will not flush the firewall, although modifying an existing rule will.\nSet the default behaviour to deny all incoming connections.\nsudo ufw default deny Open up TCP port 22 but with rate limiting enabled which will deny connections from an IP address that has attempted to initiate 6 or more connections in the last 30 seconds. Ideal for protecting sshd but you should conisder other SSH brute force defense techniques as well.\nsudo ufw limit ssh To enable the firewall you also have to do the following.\nsudo ufw enable On low-end servers it might be beneficial to disable logging.\nsudo ufw logging off You can see the status of the firewall using sudo ufw status.\nIntrusion prevention I use either denyhosts\nsudo apt-get install denyhosts Purge entries older than 5 days, denied hosts will only be purged twice and disable email alerts.\nsudo sed -i \u0026#39;s/#PURGE_DENY = 5d/PURGE_DENY = 5d/\u0026#39; /etc/denyhosts.conf sudo sed -i \u0026#39;s/#PURGE_THRESHOLD = 2/PURGE_THRESHOLD = 2/\u0026#39; /etc/denyhosts.conf sudo sed -i \u0026#39;s/root@localhost//\u0026#39; /etc/denyhosts.conf Restart denyhosts.\nsudo service denyhosts restart Also see SSH brute force defence.\nBoot options These servers are headless and often remote, therefore I enable fsck auto repair.\nSqueeze sed -i \u0026#39;s/FSCKFIX=no/FSCKFIX=yes/\u0026#39; /etc/default/rcS Wheezy sed -i \u0026#39;s/#FSCKFIX=no/FSCKFIX=yes/\u0026#39; /etc/default/rcS Repositories lsb-release was installed earlier. This is what I put in /etc/apt/sources.list.\ncat \u0026gt;/etc/apt/sources.list\u0026lt;\u0026lt;EOF deb http://ftp.uk.debian.org/debian/ $(lsb_release -cs) main contrib non-free deb-src http://ftp.uk.debian.org/debian/ $(lsb_release -cs) main contrib non-free deb http://security.debian.org/ $(lsb_release -cs)/updates main contrib non-free deb-src http://security.debian.org/ $(lsb_release -cs)/updates main contrib non-free # $(lsb_release -cs)-updates, previously known as \u0026#39;volatile\u0026#39; deb http://ftp.uk.debian.org/debian/ $(lsb_release -cs)-updates main contrib non-free deb-src http://ftp.uk.debian.org/debian/ $(lsb_release -cs)-updates main contrib non-free EOF I replace ftp.uk with ftp.us for servers located in the United States.\nsed -i \u0026#39;s/ftp\\.uk/ftp\\.us/g\u0026#39; /etc/apt/sources.list Backports I add the Backports repository in order to access some updated packages.\nSqueeze cat \u0026gt;/etc/apt/sources.list.d/backports.list \u0026lt;\u0026lt;EOF deb http://ftp.uk.debian.org/debian-backports $(lsb_release -cs)-backports main contrib non-free deb-src http://ftp.uk.debian.org/debian-backports $(lsb_release -cs)-backports main contrib non-free EOF Wheezy cat \u0026gt;/etc/apt/sources.list.d/backports.list \u0026lt;\u0026lt;EOF deb http://ftp.uk.debian.org/debian $(lsb_release -cs)-backports main contrib non-free deb-src http://ftp.uk.debian.org/debian $(lsb_release -cs)-backports main contrib non-free EOF Update.\nsudo apt-get update All backports are deactivated by default (i.e. the packages are pinned to 100 by using ButAutomaticUpgrades: yes in the Release files. If you want to install something from backports run:\napt-get -t wheezy-backports install \u0026#34;package\u0026#34; MTA sSMTP is a simple MTA to deliver mail from a computer to a mail hub. sSMTP is simple and lightweight.\nRemove exim4 Some VPS Debian templates from VPS providers have exim4 installed and running by default. Remove it.\nsudo service exim4 stop sudo apt-get purge exim4 exim4-base exim4-config Install sSMTP apt-get install ssmtp bsd-mailx sSMTP Gmail Configuration I use Gmail as my smart host, here is an example configuration for /etc/ssmtp/ssmtp.conf.\n# # Config file for sSMTP sendmail # # The person who gets all mail for userids \u0026lt; 1000 # Make this empty to disable rewriting. root=root@example.org # The place where the mail goes. The actual machine name is required no # MX records are consulted. Commonly mailhosts are named mail.domain.com mailhub=smtp.gmail.com:587 # Where will the mail seem to come from? rewriteDomain= # The full hostname hostname=box.example.org # Are users allowed to set their own From: address? # YES - Allow the user to specify their own From: address # NO - Use the system generated From: address FromLineOverride=YES # Gmail requires TLS UseTLS=YES UseSTARTTLS=YES # Username and password for Gmail servers AuthUser=yourgmailname@gmail.com AuthPass=youpassword AuthMethod=LOGIN Then add each account that you want to be able to send mail from by editing /etc/ssmtp/revaliases:\nroot:username@gmail.com:smtp.gmail.com:587 user_a:username@gmail.com:smtp.gmail.com:587 user_b:username@gmail.com:smtp.gmail.com:587 https://wiki.debian.org/sSMTP Log and package monitoring My personal VPS server are dotted about the place but I like to keep an eye on them and I find apticron and logwatch are very useful for that.\napticron apticron is a simple tool to mail about pending package updates.\nsudo apt-get install apticron logwatch Logwatch is a modular log analyser that runs every night and mails you the results.\nsudo apt-get install logwatch Lighter Some of my servers have fairly low resources, these are some simple changes that can save a bit of RAM or disk space.\naptitude I don\u0026rsquo;t use it.\nsudo apt-get purge aptitude D-Bus D-Bus is a message bus, used for sending messages between applications. Some VPS provider Debian templates have D-Bus and avahi installed. I don\u0026rsquo;t require these on Internet facing servers so I remove them. If an application pull in D-Bus as a requirement that is fine, but for this initial server state I remove it.\nsudo apt-get purge dbus at at provides delayed job execution and batch processing. I don\u0026rsquo;t use it.\nsudo service atd stop sudo apt-get purge at ngetty Ngetty is a single-process getty replacement, so instead of running 6 getty processes consuming up to 3MB of RAM each, you can use a single ngetty process using less than 1MB of RAM total.\nsudo apt-get install ngetty Edit /etc/inittab, comment out getty and add ngetty like so.\n#1:2345:respawn:/sbin/getty 38400 tty1 #2:23:respawn:/sbin/getty 38400 tty2 #3:23:respawn:/sbin/getty 38400 tty3 #4:23:respawn:/sbin/getty 38400 tty4 #5:23:respawn:/sbin/getty 38400 tty5 #6:23:respawn:/sbin/getty 38400 tty6 ng:2345:respawn:/sbin/ngetty 1 2 3 4 5 6 Restart inittab\ntelinit q http://haydenjames.io/replacing-getty-ngetty-debian/ That about covers the general post installation step I complete on my Debian servers.\nClean up. Remove any packages that are no longer required and clean up the package cache.\nsudo apt-get autoremove sudo apt-get autoclean sudo apt-get clean ","permalink":"https://wimpysworld.com/posts/basic-debian-setup-for-squeeze-and-wheezy/","tags":["Debian","LXC","QEMU","KVM","Open Media Vault"],"title":"Basic Debian Setup for Squeeze and Wheezy"},{"categories":["Linux","Open Source","Tutorial","Self Hosting"],"contents":"I have an NFS server at home and at work we have Windows (not Samba) servers. When I first switched to systemd I noticed that boot and shutdown were seriously delayed while NFS and CIFS were mounted/unmounted. systemd was designed to eliminate those kinds of delays, so I did some research to find out how to correctly mount NFS and CIFS using systemd.\nsystemd friendly fstab Below are some example /etc/fstab entries for NFS and CIFS mounts that are systemd friendly, the pertinent mount options are:\nnoauto,x-systemd.automount,_netdev I found that noauto,x-systemd.automount improved the boot performance and _netdev improved the shutdown performance.\nNFS This is typically what I have use for mounting my home NAS.\nnfs-server:/SomeData /media/SomeData nfs defaults,noauto,x-systemd.automount,_netdev,noatime 0 0 CIFS This is what I use at work to work correctly with Windows Server.\n//cifs-server/MoreData /media/MoreData cifs defaults,noauto,x-systemd.automount,_netdev,rw,noperm,credentials=/home/username/.smb-credentials 0 0 The contents of the credentials file looks something like this.\nusername=yourusername password=yourpassword domain=COMPANYDOMAIN References https://wiki.archlinux.org/index.php/Systemd#Filesystem_mounts ","permalink":"https://wimpysworld.com/posts/nfs-and-cifs-mounts-with-systemd/","tags":["systemd","CIFS","NFS"],"title":"NFS and CIFS mounts with systemd"},{"categories":["Linux","Open Source","Development"],"contents":"At work I maintain the Jenkins test and build servers. I\u0026rsquo;m just about to update our Windows build servers and thought I\u0026rsquo;d better check the available \u0026ldquo;Python Distributions\u0026rdquo; to see if our current choice (the brilliant Python(x,y) is still the most suitable for our needs.\nOur Flight Data Analyzer makes extensive use of Numpy, Scipy, h5py and other analysis tools. So, pre-built Python distributions on Windows save me a lot of pain time. On Linux we roll our own of course.\nWhat follows is a list of Python Distributions that include Python and the essential modules we require.\nAnaconda Completely free enterprise-ready Python distribution for large-scale data processing, predictive analytics, and scientific computing.\nhttps://store.continuum.io/cshop/anaconda/ Heard about this for the first time a couple of days ago. It looks very promising with 32-bit and 64-bit flavours and MKL optimised modules are available from the reasonably priced Anaconda Accelerate. While I roll my own Python Distribution for our Linux build servers, I am rather taken with the idea of using Anaconda on Linux and Windows to provide a consistent platform everywhere. I\u0026rsquo;m looking forward to testing Anaconda this week.\nContinuum appear to be taking on Enthought at their own game, and good luck to them as they have some really interesting projects on the go.\nhttp://www.continuum.io/developer-resources Enthought Canopy Enthought Canopy is a comprehensive Python analysis environment with easy installation \u0026amp; updates of the proven Enthought Python distribution - all part of a robust platform you can explore, develop and visualize on.\nhttps://www.enthought.com/products/canopy/ We used to use Entought EPD and Canopy builds on EPD. However, we decided to switch from EPD and consolidate analyst workstation and build server deployments around Python(x,y).\nThere were several factors to this decision, but the main issue was that updates to the EPD package repositories were slow for some essential modules we use. Canopy seems to have inherited package latency from EPD as Numpy is still at 1.6.1 while we now require Numpy 1.7.\nPaid versions of Canopy have MKL optimizations and 64-bit platform support.\nhttps://www.enthought.com/products/canopy/compare-subscriptions/ Python(x,y) Scientific-oriented Python Distribution based on Qt and Spyder.\nhttps://code.google.com/p/pythonxy/ This is what we currently use for Windows build servers and analyst workstations. The only reason I\u0026rsquo;m conisdering switching is that is it 32-bit only. Other than that, I love it and highly recommend it. Python(x,y) doesn\u0026rsquo;t offer MKL optimisations.\nWinPython WinPython is a portable scientific Python 2/3 32/64bit distribution for Windows\nhttp://code.google.com/p/winpython/ From the same stable as Python(x,y) but has 32-bit and 64-bit flavours, yummy. WinPython includes everything I need so will definately get fully tested this week.\nPortable Python Portable Python is a Python programming language pre-configured to run directly from any USB storage device, enabling you to have, at any time, a portable programming environment.\nhttp://portablepython.com/ Not looked at this in any real detail. Appears to be 32-bit only but does include a number of essential packages.\nUnofficial Windows Binaries for Python Extension Packages Provides 32- and 64-bit Windows binaries of many scientific open-source extension packages for the official CPython distribution of the Python programming language.\nhttp://www.lfd.uci.edu/~gohlke/pythonlibs/ OK, so this is not a Python distribution but it is compelling. 32-bit and 64-bit platforms are catered for and MKL optimizations are available at no cost. Each package needs to be installed individually, which can be seen as both good and bad. Good because you only install what you actually require and bad because the initial installation is protracted. That said, it is on my evaluation list for this week.\nAnymore? Those are the Python Distributions I\u0026rsquo;m aware of. Are there any others I should consider?\n","permalink":"https://wimpysworld.com/posts/python-distributions/","tags":["Python","Numpy","Scipy","h5py","Flight Data"],"title":"Python Distributions"},{"categories":["Linux","Open Source","Tutorial"],"contents":"About a year ago I migrated all my workstations, laptops and netbooks to Arch Linux. Since then, I\u0026rsquo;ve setup Arch Linux on a Raspberry Pi and this server was also recently migrated to Arch Linux.\nI\u0026rsquo;ve had no major issues issues during the last year and have upgraded through five major Linux kernels, transitioned to systemd and upgraded from GNOME 3.2 to 3.8.\nAlthough I have been disciplined about merging .pacnew files frequently, during the upgrades and experimentation\u0026rsquo;s I have packages installed that I no longer require and obsolete files kicking about.\nAfter the upgrade to GNOME 3.8 I decided to clean up a little. I rarely dip into the AUR, but when I do I always use packer to clearly separate what is official from what is not.\nFinding what is installed The following commands are useful for identifying installed packages based on where they were installed from. The package lists generated from the commands below can be quite big but often highlight packages that I know I\u0026rsquo;m no longer using nor require.\nListing installed packages List packages installed from the official repositories.\npacman -Qq | grep -Fv -f \u0026lt;(pacman -Qqm) List packages installed from the AUR.\npacman -Qqm Listing installed packages by size Use pacsysclean to list installed packages sorted by size, it helps identify large packages that are no longer required which can the be manually uninstalled.\nListing orphaned packages List orphaned packages install from the official repositories.\npacman -Qqtd | grep -Fv -f \u0026lt;(pacman -Qqtdm) List ophaned packages from the AUR.\npacman -Qqmtd Getting package information Get package information for a package in the official repositories.\npacman -Si \u0026lt;package\u0026gt; Get package information for a package in the AUR.\npacker -Si \u0026lt;package\u0026gt; Removing orphaned packages Removing orphaned packages manually can be very time consuming, but is by far the safer option. However, I decided to take a brave pill a uninstall all orphaned packages automatically.\nRemove all orphaned packages installed from the official repositories.\nsudo pacman -Rs `pacman -Qqtd | grep -Fv -f \u0026lt;(pacman -Qqtdm)` Remove all ophanced packages install from the AUR.\nsudo pacman -Rs $(pacman -Qqtdm) Re-installing what you do need When you do something scary like removing all the obsolete packages automatically, then you should really make sure you do have everything install that you require.\nRe-install 64-bit base sudo pacman -S --needed `pacman -Sqg base multilib-devel | grep -v gcc-libs | tr \u0026#39;\\n\u0026#39; \u0026#39; \u0026#39;` Re-install 32-bit base sudo pacman -S --needed `pacman -Sqg base base-devel | tr \u0026#39;\\n\u0026#39; \u0026#39; \u0026#39;` Reinstall the groups required for a GNOME 3 desktop.\nsudo pacman -S --needed `pacman -Sqg gnome gnome-extra telepathy | tr \u0026#39;\\n\u0026#39; \u0026#39; \u0026#39;` Install all missing dependencies for packages in the official repositories.\nsudo pacman -S --needed `pacman -Si $@ 2\u0026gt;/dev/null | awk -F \u0026#34;: \u0026#34; -v filter=\u0026#34;^Depends\u0026#34; \\ \u0026#39;$0 ~ filter {gsub(/[\u0026gt;=\u0026lt;][^ ]*/,\u0026#34;\u0026#34;,$2) ; gsub(/ +/,\u0026#34;\\n\u0026#34;,$2) ; print $2}\u0026#39; | grep -v smtp- | sort -u` Install all missing dependencies for packages in the AUR. This will re-install even if the package is already installed. I can\u0026rsquo;t be arsed to filter it out for a one liner.\nsudo packer -S --noedit --noconfirm `packer -Si $(pacman -Qqm) 2\u0026gt;/dev/null | awk -F \u0026#34;: \u0026#34; -v filter=\u0026#34;^Depends\u0026#34; \\ \u0026#39;$0 ~ filter {gsub(/[\u0026gt;=\u0026lt;][^ ]*/,\u0026#34;\u0026#34;,$2) ; gsub(/ +/,\u0026#34;\\n\u0026#34;,$2) ; print $2}\u0026#39; | grep -v java- | sort -u` Find files not associated with a package When packages are removed they may leave some files behind. The following will find all files not associated with a package. These files can not be automatically deleted, each entry requires assessment.\npacman -Qlq | sort -u \u0026gt; /tmp/db sudo find /bin /etc /sbin /usr ! -name lost+found \\( -type d -printf \u0026#39;%p/\\n\u0026#39; -o -print \\) | sort \u0026gt; /tmp/fs comm -23 /tmp/fs /tmp/db As with all spring cleaning chores, I got bored by this stage as my workstation was looking pretty tidy. Much of what is presented in this blog post is a rehash of what others have already contributed to the Arch Linux Wiki. I\u0026rsquo;ve just organised what \u0026ldquo;Works For Me ‚Ñ¢\u0026rdquo; so I know what to do next year.\nReferences https://wiki.archlinux.org/index.php/Pacman_Tips ","permalink":"https://wimpysworld.com/posts/spring-cleaning-arch-linux/","tags":["Arch Linux","pacman","packer"],"title":"Spring cleaning Arch Linux"},{"categories":["Linux","Open Source","Tutorial","Entertainment"],"contents":"I use get-iplayer to download TV programs so I can watch them on the devices that suit me, when it suits me. What follows is how I install get-iplayer on a headless Debian 6.0 server I have a home. The server in question is really low powered so building from source was not an option.\nIn order to install the latest version of get-iplayer (currently 2.82) on Debian Squeeze a couple of additional package repositories need enabling.\nDebain Multimedia Debian Backports Enable the Debain Backports repository by adding the following line to /etc/apt/sources.list.d/backports.list.\ndeb http://backports.debian.org/debian-backports squeeze-backports main Enable the Debain Multimedia repository by adding the following lines to /etc/apt/sources.list.d/multimedia.list.\ndeb http://www.deb-multimedia.org squeeze main non-free deb http://www.deb-multimedia.org squeeze-backports main Update the repositories.\nsudo apt-get update Install the deb-multimedia-keyring package.\nsudo apt-get --allow-unauthenticated install deb-multimedia-keyring Install get-iplayer (currently v2.78) from the official Debian repositories, this will also install the dependencies.\nsudo apt-get install get-iplayer Install the get-iplayer suggested packages.\nsudo apt-get install ffmpeg rtmpdump libdata-dump-perl libid3-tools libcrypt-ssleay-perl libio-socket-ssl-perl I have seen it suggested that mplayer should also be installed. I\u0026rsquo;ve not determined if that is an absolute requirement. But this is how to install it on a headless Debian computer.\nsudo apt-get --no-install-recommends install mplayer Finally, upgrade get-iplayer to v2.82.\nsudo apt-get install libmp3-tag-perl libxml-simple-perl wget http://ftp.uk.debian.org/debian/pool/main/g/get-iplayer/get-iplayer_2.82-2_all.deb sudo dpkg -i get-iplayer_2.82-2_all.deb At this point get-iplayer should be good to go and the get-iplayer website and man get-iplayer will assist you.\nReferences http://www.infradead.org/get_iplayer/html/get_iplayer.html http://www.deb-multimedia.org/ http://backports-master.debian.org/ http://lists.infradead.org/pipermail/get_iplayer/2012-June/003065.html http://tech.leeporte.co.uk/get_iplayer-under-debian-squeeze/ ","permalink":"https://wimpysworld.com/posts/get-iplayer-on-debian-6.0/","tags":["Debian","iPlayer","get-iplayer","BBC"],"title":"get-iplayer on Debian 6.0"},{"categories":["Linux","Open Source","Computer Hardware","Gadgets"],"contents":"I bought a budget Android tablet a little while back that turned out to be really rather good. However, there were issues with the initial firmware.\nConnecting to, or maintaining connection with, some wireless networks was unreliable. When the internal NAND was under moderate load the tablet would become unresponsive. Ployer released a firmware update in November 2012 and again in April 2013 which addressed these issues. Here\u0026rsquo;s the translated change log.\nIncrease the volume buttons on the vertical screen. System, audio and video decoding, browser, Flash player, 3G module, boot animation module BUG repair. Update NandFlash, Mali, Wifi module drivers, while addressing some CTS tests BUG and the stability of the system as a whole has been further enhanced. Optimize Flash stability, improve the efficiency of the implementation of the DDR. Default input method Sogou input method. Update Google Pinyin input method. However, the official Ployer firmware comes pre-loaded with a selection of Chinese applications and defaults to a Chinese language.\nObjectives I decided to have a go a making my own custom firmware for the Ployer Momo8 IPS with the following goals.\nPre-rooted. Removal of pre-installed Chinese apps. Removal of bloatware. Extend /data partition. Make it a \u0026ldquo;Google Experience\u0026rdquo; device. ClockWorkMod Recovery (available to donors) I think I\u0026rsquo;ve been fairly successful. My firmware includes Android 4.1.2 features and even some Android 4.2 features. Until someone successfully ports cyanogenmod to the Ployer Momo8 IPS or Ployer release a 4.2.x update then my firmware is the most complete \u0026ldquo;Google Experience\u0026rdquo; you\u0026rsquo;ll find for the device.\nChanges Below are the changes I made to the official Ployer Momo8 IPS firmware.\n13.164 This release is mainly a fix for Google+. The builds are running now and will be available for download later today.\nIntegrated SuperSU 1.32 http://forum.xda-developers.com/showthread.php?t=1538053 Tweaked WiFi 2.4Ghz Transmit Power. maxp2ga0 is now 76 in: This appears to be the default for other devices with the same chipset, feedback welcomed. Reverted PlusOne.apk to the version in 13.137 This should fix the force closes. 13.149 The purpose of this release is to refresh some system apps, address some compatibility issues and to offer versions of my custom firmware based on both 20130325 and 20121120.\nBased on the Official Ployer MOMO8(IPS)-4.1.1-Firmware-20130325 and the Official Ployer MOMO8(IPS)-4.1.1-Firmware-20121120. Feedback suggests that WiFi works better for some when using firmware based on the 20121120 version. Only donors will have access to the 20121120 versions. Integrated SuperSU 1.30 http://forum.xda-developers.com/showthread.php?t=1538053 Removed the framework.jar patch as it introduces incompatibilities of its own. Removed the PicoTTS voice data files from the /system partition. PicoTTS voices can be selectively installed via Settings -\u0026gt; Language and Input. This is a space saving measure and essential for the 20121120 version. Updated the following, as of May 25th 2013: Magazines.apk (Google Play Magazines) Music2.apk (Google Play Music) PlusOne.apk (Google+) Talk.apk (Hangouts) 13.137 This release is focused on stability, adding the new Google Play features announced at Google I/O 2013 and also includes everything from the previous releases.\nIntegrated Android 4.2 sounds, fonts and boot animation Boot animation is now the correct size, higher quality and doesn\u0026rsquo;t flicker at the end of a boot. All Android 4.2 sounds and fonts are now included. Fixed default notification sound. Lock screen font looks much nicer. http://forum.xda-developers.com/showthread.php?t=1991734 Integrated Android 4.2.2 keyboard http://forum.xda-developers.com/showthread.php?p=38124560 Integrated Nova Launcher 2.1 http://novalauncher.com Integrated Feedly 15.0.1 http://www.feedly.com Integrated Power Toggles 4.6.6 http://www.powertoggles.com Tweaked WiFi 2.4Ghz Transmit Power. maxp2ga0 is now 100 in: /etc/firmware/nvram_RK901.txt was previously 74. /etc/firmware/nvram_RK903.cal was previously 76. /etc/firmware/nvram_RK903.txt was previosuly 72. /etc/firmware/nvram_RK903_26M.cal was previously 60. Tweaked WiFi 5.0Ghz Transmit Power. maxp5ga0, maxp5gla0 and maxp5gha0 are now 100 in: /etc/firmware/nvram_RK903.cal were all previously 80. /etc/firmware/nvram_RK903_26M.cal were all previously 80. Added camera icon to the application drawer. Fixed boot up time Boot up time is significantly faster, with the exception of the first boot after a firmware flash. Fixed apps disappearing from the Settings and the Play Store. Replaced Google Talk with Hangouts Removed Google Drive and Google Earth When pre-installed they would Force Close. Updated the following, as of May 16th 2013: Books.apk (Google Play Books) GestureSearch.apk Currents.apk GoogleEars.apk (Sound Search) GmsCore.apk (Google Play Services) Magazines.apk (Google Play Magazines) Maps.apk Music2.apk (Google Play Music) Phonesky.apk (Play Store) Talk.apk (Hangouts) TalkBack.apk (Accessibility) Videos.apk (Google Play Movies) 13.129 This version includes everything from the previous release plus the changes below.\nBased on the Official Ployer MOMO8(IPS)-4.1.1-Firmware-20130325 http://download.ployer.cn/downdetail.asp?id=763 Boot loader upgraded to 1.22 Switching to Upgrade mode in Rockchip Batch Tool is much quicker. Extended /system partition from 375M to 428M Removed more Chinese applications and bloatware Removed UCBrowser shared objects from /system/lib Removed QQMiniHD shared objects from /system/lib Removed more Adobe Reader shared objects from /system/lib and fonts from /system/fonts/adobefonts Integrated Clockworkmod Recovery to 6.0.31 (donors only) http://androtab.info/clockworkmod/rockchip/changelog/ Integrated Adobe Flash 11.1.115.54 http://helpx.adobe.com/flash-player/kb/archived-flash-player-versions.html Integrated File Wrangler 1.5 https://play.google.com/store/apps/details?id=com.amon.filewrangler Integrated AdAway 2.3 (Google now blocks all advert blockers from the Play Store) http://code.google.com/p/ad-away/ Replaced Launcher2 4.1.5 with Nova Launcher 2.0.2 http://novalauncher.com Replaced the default wallpaper with the default wallpaper from the Nexus 10. Removed User Management - it was not reliable. Removed Chrome.apk but updated /system/lib/libchromeview.so from Chrome 26.0.1410.58 This is a space saving measure but ensures the ROM is Chrome compatible. Updated the following, as of May 10th 2013: Authenticator.apk CalendarGoogle.apk Currents.apk Drive.apk Earth.apk Gmail.apk GooglePlayBooks.apk GooglePlayMagazines.apk GooglePlayMovies.apk GooglePlayMusic.apk GooglePlayServices.apk Keep.apk Maps.apk Phonesky.apk (Play Store) PlusOne.apk (Google+) Street.apk YouTube.apk 13.080 Based on the Official Ployer MOMO8(IPS)-4.1.1-Firmware-20121120 http://download.ployer.cn/downdetail.asp?id=763 Extended /data partition to 2GB. http://www.freaktab.com/showthread.php?287-RockChip-ROM-Building-Tips-and-Tricks-by-Finless\u0026amp;p=4054\u0026amp;viewfull=1#post4054 Removed Chinese applications. UCBrowser_V2.1.1.219_Android3_pf147_(Build12110718).apk dopoolplayer iReader_android_v2000_108044_guanwang.apk including shared objects from /system/lib. market_hd.apk qiyiyingshi_V3.0_mumayi_e3d3e.apk qq_mini_hd_1.9.1.apk sougoushurufa.apk including shared objects from /system/lib. zhonghuawannianli_ECalendar_V3.2.3_mumayi_3ee39.apk Cleaned up build.prop Changed Chinese strings to ASCII Configured English (UK) as default language/locale. Configured Europe/London as default time zone. Default display brightness set at 50% Deleted settings for Chinese applications that have been removed. Removed Rockchip Utilities. ApkInstaller.apk RkExplorer.apk RKUpdateService.apk including shared objects from /system/lib. RkVideoPlayer.apk Removed bloatware. Adobe Reader including shared objects from /system/lib. DocsToGo. Integrated SuperSU 1.25 http://forum.xda-developers.com/showthread.php?t=1538053 Integrated Clockworkmod Recovery 6.0.28 http://androtab.info/clockworkmod/rockchip/ http://forum.xda-developers.com/showthread.php?t=2102679 Integrated Google Apps (JZO54K) 4.1.2 Adds the first boot Setup Wizard. Adds Picasa photo syncing. Face Unlock 4.1.2 Google Talk 4.1.2 http://rootzwiki.com/topic/31532-gapps-412-485486-jzo54k-gapps-package-1012/ Integrated Launcher2 4.2, includes 50% transparency on app drawer. http://forum.xda-developers.com/showthread.php?t=1995812 Integrated some Jelly Bean 4.2 features: Jelly Bean 4.2 clock. Jelly Bean 4.2 keyboard with gesture. Movie Studio video editor. http://forum.xda-developers.com/showthread.php?t=2010535 Integrated Cyanogenmod 10.0 APKs Calculator.apk : Adds different calculator panels. Galaxy4.apk : Smaller APK HoloSpiralWallpaper.apk : Smaller APK LiveWallpapers.apk : Smaller APK LiveWallpapersPicker.apk : Smaller APK MagicSmokeWallpapers.apk : Smaller APK NoiseField.apk : Smaller APK PhaseBeam.apk : Smaller APK SoundRecorder.apk : Smaller APK VisualizationWallpapers.apk : Smaller APK Integrated Adobe Flash 11.1.115.47 http://helpx.adobe.com/flash-player/kb/archived-flash-player-versions.html Integrated Quick Boot 4.2 https://play.google.com/store/apps/details?id=com.siriusapplications.quickboot Integrated File Wrangler 1.4 https://play.google.com/store/apps/details?id=com.amon.filewrangler Integrated User Management http://forum.xda-developers.com/showthread.php?t=1824066 https://play.google.com/store/apps/details?id=com.appaholics.um Integrated busybox 1.20.2 Added additional permissions files for increased compatibility. android.hardware.camera.autofocus.xml android.hardware.camera.front.xml android.hardware.ethernet.xml android.hardware.sensor.accelerometer.xml android.hardware.sensor.light.xml android.hardware.touchscreen.multitouch.xml Replaced ring tones, alerts and notifications with the audio from Nexus 4. Replaced boot animation with the Nexus animation. Replaced the default wallpaper with one from the Jelly Bean SDK. Updated the following, as of March 18th 2012: CalendarGoogle.apk Gmail.apk GooglePlayMovies.apk GooglePlayMusic.apk GooglePlayServices.apk PlusOne.apk (Google+) Maps.apk Phonesky.apk (Google Play Store) Street.apk YouTube.apk Removed Chrome.apk but updated /system/lib/libchromeview.so. This is a space saving measure but ensures the ROM is Chrome compatible. Patched framework.jar so that Gameloft titles work. http://www.slatedroid.com/topic/50354-gameloft-game-fix-for-license-check-or-loop/ http://dragondevs.com/index.php?/topic/1265-gameloft-game-fix-for-license-check-or-loop/ http://forum.xda-developers.com/showthread.php?t=955847 All APKs are ZipAligned. What didn\u0026rsquo;t change I haven\u0026rsquo;t modified build.prop to make the Ployer Momo8 IPS masquerade as another brand or model of Android device. I will not be making this change, please don\u0026rsquo;t request it. Although my firmware includes many features from Android 4.1.2 and some from Android 4.2 I haven\u0026rsquo;t bumped the Android version or Build number. That would be dishonest and misleading. Known Issues Adobe Flash is enabled the first time the Browser app (not Chrome) is executed. Hangouts app does not work on the first boot following a firmware flash. It does works correctly on subsequent boots. Although busybox is included in the ROM, no sym-links are created. Some Gameloft titles may not work, Asphalt 7 for example. Do other Gameloft titles work properly? This problem is present in the official Ployer firmware too, there are framework patches to fix this problem but they seem to introduce other incompatibilities. Donate Please consider donating to this project. It is nice to have the effort I\u0026rsquo;ve put into this custom firmware recognized. I don\u0026rsquo;t ask for much, it is at your discretion, but just think how happy I\u0026rsquo;ll look when I am sipping the beer you bought me üòÑ\nDownloads You\u0026rsquo;ll need Rockchip Batch Tool which include the RockChip USB drivers and the firmware flashing utility. I\u0026rsquo;ve modified Rockchip Batch Tool to default to English language and removed old logs and transient data to reduce the size of the download. You\u0026rsquo;ll also need the firmware itself.\nPloyer MOMO8 IPS Firmware Download Rockchip Batch Tool and the STOCK RECOVERY version of the ROM. Unzip both archives once they are downloaded.\nHow to Flash Warning Always (I can't stress this enough) flash the STOCK RECOVERY version of my custom ROM. Never flash the CWM RECOVERY version without first having flashed the STOCK RECOVERY version. If you are upgrading from another ROM (even one of mine) always flash the STOCK RECOVERY version first. Flashing this ROM will will effectively factory reset your tablet, wipe your installed apps, app data and preferences. If you have rooted your tablet you might want to consider making a backup with Titanium Backup * root. If you have not rooted your tablet then you could use Helium - App Sync and Backup.\nInstall the Rockchip USB drivers included with Rockchip Batch Tool. This was simple of Windows XP but I couldn\u0026rsquo;t get Windows 7 to accept the Rockchip drivers. However, installing MoboRobo on Windows 7 provided the correct driver. Turn the Ployer Momo8 IPS on. On the tablet go to Settings -\u0026gt; Developer options and untick USB debugging. Start RKBatchTool.exe. In RKBatchTool choose firmware file, click the Switch button. The device icon should change to green to indicate a successful connection. Note The very first time your `Switch` to upgrade mode, Windows may prompt you to install additional Rockchip USB drivers. Only if the device icon changed to Green, click Upgrade. The firmware will be flashed and the tablet will automatically reboot into Recovery. You will see a green Android and then the paritions (/data, /cache and /mnt/sdcard) will be formatted. /mnt/sdcard is the internal memory, not the microSDHC card inserted in the card reader. When the formatting is complete the tablet will reboot. The first boot may take a little longer than usual. You will be presented with the Welcome wizard where you can configure language and locale, etc. You can optionally enter your Google Apps or Gmail account credentials and doing so will prompt for which Wifi network to associate with.\nRockchip Batch Tool Video I\u0026rsquo;ve also made a video showing how to flash the firmware. Frankly, the hardest part is getting the Rockchip drivers installed.\nHow to Flash the CWM version Warning Like I said, never flash the CWM RECOVERY version of my ROM without first having flashed the STOCK RECOVERY version. The CWM version is made available to donors. Flash the STOCK RECOVERY version of the ROM as detailed above. Follow the same procedure, but this time flash the CWM RECOVERY version. When the CWM RECOVERY flash is complete the tablet will boot into CWM recovery. Do the following: wipe cache partition advanced -\u0026gt; wipe dalvik cache ++++++Go Back++++++ reboot system now The tablet will reboot, it will be a slower boot than usual but subsequent boots will be quicker. ClockWorkMod Recovery Booting to recovery can be achieved using the pre-install Quick Boot app.\nThe Ployer Momo8 IPS only has one hardware button (power) so CWM is controlled with gestures.\nSwipe up/down: up/down Swipe left: select Swipe right: back The Power button also acts as select, which I find to be the most reliable way to select an action.\nFAQ Does this custom firmware fix WiFi connectivity? Short answer, possibly.\nOf all the WiFi networks I have access to, only one causes the Ployer Momo8 IPS to encounter weak signal and intermittent connections. When using the Official Ployer firmware on that WiFi network, connecting more than 5 meters from the access point is unreliable and maintaining a connection is almost impossible.\nUsing my firmware I can connect and maintain a connection up to about 10 meters from the access point. My testing, and the feedback from others suggests the my firmware improves the WiFi signal by 8 to 10dBm.\nFrom my testing the Momo8 IPS appears to have issues with some wireless access points, possibly related to the chipset in the access point or the Momo8 IPS, but I\u0026rsquo;ve not been able to pin it down. That said, I\u0026rsquo;ve got access to 2 Draytek Vigor routers and the Momo8 IPS does not work well with either of them. Every other wireless network I\u0026rsquo;ve connected to works well.\nFor example, at home I stream 720p movies via DLNA over WiFi and watch them on the Momo8 IPS using MX Player. It works perfectly and never buffers or lags. However, your mileage may vary.\nWhy should I always flash the STOCK RECOVERY version first? Short answer, it\u0026rsquo;s the safest option.\nThere are 6 different ROMs (official or otherwise) that I am aware of for the Ployer Momo8 IPS. They all have slightly different partition layouts. If you flash one of my CWM RECOVERY ROMs over a ROM using a slightly different partition layout, it will almost certainly soft brick the tablet. The STOCK RECOVERY will always correctly format the partitions directly after a flash, thereby mitigating the risk of soft bricking the tablet.\nOoops, I\u0026rsquo;ve soft bricked my tablet. What do I do? Read the comments here, there are several useful tips. You can also use the comments here to see if anyone can offer assistance. Alternatively, go the Ployer Momo8 forum on Slatedroid, read what others have done and ask for help.\nhttp://www.slatedroid.com/forum/445-momo8/ How do the 20130325 and 20121120 versions differ. The differences Ployer made between 20130325 and 20121120 is not well documented. I did some additional analysis of what changed between the November 2012 and April 2013 releases from Ployer, you can find my notes here:\nNew Official Firmware: MOMO8 (IPS) -4.1.1 firmware 20130325 In addition to whatever Ployer changed, this is how my 20121120 differs from 20130325.\nThe /system partition on the 20121120 version is 375MB, therefore the following system apps are not included: AdAway.apk Authenticator.apk Books.apk Currents.apk Feedly.apk GestureSearch.apk Keep.apk Magazines.apk Videos.apk YouTube.apk All of the above can be installed from the Play Store, which the exception of AdAway which can be side-loaded. Boot loader is version 1.20 rather than the newer 1.22. All other tweaks and modifications are the same. Some people have reported that WiFi is more reliable when using a firmware based on 20121120. Due to the size of the custom firmwares and the bandwidth they consume, custom versions of my firmware based on 20121120 are only available to donors.\nFeedback Your feedback is welcome, please use the comments are below.\n","permalink":"https://wimpysworld.com/posts/ployer-momo8-ips-custom-firmware/","tags":["Android","Tablet","Ployer Momo8 IPS","RK3066","Firmware","Hacking","ClockWorkMod","KANG","ROM"],"title":"Ployer Momo8 IPS Custom Firmware"},{"categories":["Linux","Open Source","Tutorial","Self Hosting"],"contents":"I recently switched ISPs at home and now have unlimited high speed broadband.\nFinally I can participate in torrenting Linux .ISO images. I always download the latest distros using BitTorrent and can now contribute to the community by seeding the distros I\u0026rsquo;ve downloaded.\nI have a small (in size and resources) Debian 6.0 headless server at home that I wanted to turn into a torrent box. I\u0026rsquo;m a big fan of Transmission since it can be managed from the shell, web and Android phone/tablet. Sadly, the Transmission packages in the official Debain squeeze repositories are quite old, 2.03 at the time of writing, and there are no Transmission packages in Debian Backports.\nHowever after flexing my google-fu I found a 3rd party Debian Squeeze repository that includes fairly current (2.73 at the time of writing) Transmission packages specifically for headless use. Yah!\nInstall Transmission Daemon First become root.\nsudo -s -H Add the repository key.\napt-key adv --keyserver keyserver.ubuntu.com --recv-key 92B84A1E Add the repository.\necho \u0026#34;deb http://apt.balocco.name squeeze main\u0026#34; \u0026gt; /etc/apt/sources.list.d/balocco.list Update the package list.\napt-get update Install Transmission.\napt-get install transmission-cli transmission-daemon transmission-webinterface Basic Configuration The Transmission settings can be found in /etc/transmission-daemon/settings.json.\nIf transmission-daemon is running when you make changes to settings.json the changes you make will be discarded the next time transmission-daemon is started.\nTherefore either stop transmission-daemon before you make any changes or you can make the daemon reload settings.json by sending it the SIGHUP signal.\nConnect from anywhere If you want to be able to connect to Transmission from anywhere on the Internet stop transmission-daemon, make the following changes to settings.json and then start transmission-daemon.\n\u0026#34;rpc-password\u0026#34;: \u0026#34;YourPlainTextPassword\u0026#34;, \u0026#34;rpc-username\u0026#34;: \u0026#34;YourUsername\u0026#34;, \u0026#34;rpc-whitelist-enabled\u0026#34;: false, The rpc-username field will need adding but you can edit the existing entry for rpc-password. Enter the rpc-password as a plain text string, Transmission will automatically convert the password to a hash the next time it is started.\nConnect via a browser You should now be able to access the Transmission web interface via http://yourhost.example.org:9091. If you didn\u0026rsquo;t change the username and password (you really should) the defaults are:\nUsername : transmission Password : transmission Connect via Android I have an Android phone and an Android tablet. I use Remote Transmission on my Android devices to manage my torrent box.\nConnect via the shell If, like me, you spend the majority of you time at the shell. Then transmission-remote-cli is probably for you. All my workstation run Arch Linux so I install transmission-remote-cli as follows.\nsudo pacman -S transmission-remote-cli See the GitHub project page for tramission-remote-cli for instructions on how to connect to a remote Transmission daemon.\nBlock List Regardless of how you intend to use Transmission you should enable a block list, this can be done via settings.json and the web interface. The following block lists are a good start.\nhttp://list.iblocklist.com/?list=bt_level1\u0026amp;fileformat=p2p\u0026amp;archiveformat=gz http://www.bluetack.co.uk/config/level1.gz That covers the basics for getting Transmission running on headless Debian 6.0 and how to connect to it from just about anywhere and on any device. I recommend reading the Trasmission Wiki as Transmission is capable of so much more than I have covered in this blog post.\nHappy torrenting.\nReferences http://apt.balocco.name/changelog.txt http://www.lowendtalk.com/discussion/1001/squeeze-repository https://trac.transmissionbt.com/wiki/EditConfigFiles https://github.com/fagga/transmission-remote-cli http://www.iblocklist.com/ ","permalink":"https://wimpysworld.com/posts/headless-debian-6.0-torrent-server/","tags":["Debian","Torrent","Transmission","Headless","Android"],"title":"Headless Debian 6.0 Torrent Server"},{"categories":["Linux","Open Source","Tutorial","Self Hosting"],"contents":"My webserver of choice is nginx, it\u0026rsquo;s resource friendly, fast, reliable and versatile.\nI have a resource constrained Debian 6.0 \u0026ldquo;server\u0026rdquo; and wanted to deploy nginx on it for testing. Sadly, the nginx package in the Squeeze repositories is very old. Fortunately, the nginx team maintain a Debian package repository.\nAdd the nginx repository.\nsudo nano /etc/apt/sources.list.d/nginx.list Squeeze deb http://nginx.org/packages/debian/ squeeze nginx deb-src http://nginx.org/packages/debian/ squeeze nginx Wheezy deb http://nginx.org/packages/debian/ wheezy nginx deb-src http://nginx.org/packages/debian/ wheezy nginx Download the nginx package signing key.\nwget http://nginx.org/keys/nginx_signing.key Add the nginx package signing key to the keyring.\nsudo apt-key add nginx_signing.key Update the repositories.\nsudo apt-get update Install nginx.\nsudo apt-get install nginx I run ufw on my VPS so use the following to allow external access to my website.\nsudo ufw allow 80/tcp nginx is installed and can be configured in the usual way.\nReferences http://wiki.nginx.org/Install http://wiki.nginx.org/Pgp ","permalink":"https://wimpysworld.com/posts/install-nginx-on-debian/","tags":["Debian","nginx","ufw"],"title":"Install nginx on Debian"},{"categories":["Linux","Open Source","Tutorial","Self Hosting"],"contents":"I\u0026rsquo;ve been a fan of nullmailer for some years now, so much so that I took ownership of the nullmailer package for Arch Linux.\nnullmailer is a sendmail/qmail/etc replacement MTA for hosts which relay to a fixed set of smart relays. It is designed to be simple to configure, secure, and easily extendable.\nThe other advantage nullmailer has compared to similar tools is that is queues email until it is able to deliver it upstream.\nInstall nullmailer as follows.\npacker -S --noedit --noconfirm nullmailer Configuring nullmailer to relay via Gmail can be achieved using SMTPS or MSA. nullmailer has had these capabilities since 1.10. The following provides some useful clues /usr/lib/nullmailer/smtp --help.\nWhile these examples are specific to relaying via Gmail, you can see it is trivial to adapt them to any other mail host.\nRelay via Gmail using MSA Add to following to /etc/nullmailer/remotes. I prefer this technique.\nsmtp.gmail.com smtp --port=587 --auth-login --user=you@gmail.com --pass=Yourpassword --starttls Relay via Gmail using SMTPS Add to following to /etc/nullmailer/remotes.\nsmtp.gmail.com smtp --port=465 --auth-login --user=you@gmail.com --pass=Yourpassword --ssl Once you\u0026rsquo;ve got /etc/nullmailer/remotes configured start the nullmailer service.\nsudo systemctl start nullmailer To test nullmailer can relay email correctly do the following.\necho \u0026#34;Test 1\u0026#34; | mailx -s \u0026#34;Test One\u0026#34; me@example.org You can see what nullmailer is up to by checking the systemd journal or syslog (if you\u0026rsquo;ve syslog enabled systemd). This is how to get the logs from the systemd journal.\njournalctl _SYSTEMD_UNIT=nullmailer.service Or via syslog.\nsudo grep nullmailer /var/log/daemon.log When you\u0026rsquo;re happy nullmailer is working enable the systemd unit.\nsudo systemctl enable nullmailer Email will now flow as required.\n","permalink":"https://wimpysworld.com/posts/nullmailer-on-arch-linux/","tags":["Arch Linux","nullmailer","MTA","MSA","SMTP","SMTPS","Gmail"],"title":"nullmailer on Arch Linux"},{"categories":["Linux","Open Source","Tutorial","Security"],"contents":"While migrating one of my VPS servers to Arch Linux I deployed Uncomplicated Firewall (UFW) to handle basic firewall duties. I like ufw as it provides simple host-based firewall management and, in my opinion, one of the better projects to come out of the Ubuntu camp.\nInstall ufw as follows.\nsudo pacman -Syy -noconfirm --needed ufw Configuring ufw is simple but make sure you have console access to the host you are configuring just in case you lock yourself out.\nNOTE! When enabling ufw the chains are flushed and connections may be dropped. You can add rules to the firewall before enabling it however, so if you are testing ufw on a remote machine it is recommended you perform\u0026hellip;\nufw allow ssh/tcp \u0026hellip;before running sudo ufw enable. Once the firewall is enabled, adding and removing rules will not flush the firewall, although modifying an existing rule will.\nSet the default behaviour to deny all incoming connections.\nsudo ufw default deny Open up TCP port 22 but with rate limiting enabled which will deny connections from an IP address that has attempted to initiate 6 or more connections in the last 30 seconds. Ideal for protecting sshd but you should conisder other SSH brute force defense techniques as well.\nsudo ufw limit tcp/22 I\u0026rsquo;m hosting a few websites on my VPS so I open http and https.\nsudo ufw allow 80/tcp sudo ufw allow 443/tcp Enable the ufw systemd unit.\nsudo systemctl enable ufw sudo systemctl start ufw However, ufw is not enabled at this point. To enable the firewall you also have to do the following.\nsudo ufw enable You can see the status of the firewall using sudo ufw status.\nOn low-end servers it might be beneficial to disable logging.\nsudo ufw logging off At this point you should have a basic firewall configured and ufw help or the references below will assist you.\nReferences https://wiki.archlinux.org/index.php/Uncomplicated_Firewall https://wiki.ubuntu.com/UncomplicatedFirewall https://launchpad.net/ufw ","permalink":"https://wimpysworld.com/posts/uncomplicated-firewall-ufw-on-arch-linux/","tags":["Arch Linux","Firewall","ufw"],"title":"Uncomplicated Firewall (UFW) on Arch Linux"},{"categories":["Linux","Open Source","Tutorial","Content Creation"],"contents":"I\u0026rsquo;ve decided to migrate one of my servers to Arch Linux. I\u0026rsquo;m not sure that a rolling release distro really suits servers but I\u0026rsquo;ve enjoyed using Arch Linux over the last year on my workstations and the only way to assess it\u0026rsquo;s suitability on a server is to try it. So, I\u0026rsquo;ve decided to migrate my blog to an Arch Linux server.\nThis blog post describes how to install Nikola on Arch Linux. Nikola is a static site and blog generator written in Python that I\u0026rsquo;ve been using for a few months.\nFirst you\u0026rsquo;ll need Python and virtualenvwrapper so read my Python and virtualenv on Arch Linux and Ubuntu blog post and get yourself equipped.\nInstall the Nikola dependencies.\nsudo pacman -S --noconfirm --needed freetype2 libxslt libxml2 sudo packer -S --noconfirm --noedit libjpeg6 Create a virtualenv for Nikola.\nmkvirtualenv -p /usr/bin/python2.7 nikola-640 You will notice your shell prompt has changed to indicate that the nikola-640 virtualenv is now active. Install Nikola and the optional libraries I use.\npip install https://github.com/getnikola/nikola/archive/v6.4.0.zip If you intend to use the Nikola planetoid (Planet generator) plugin you\u0026rsquo;ll also need to following.\npip install peewee feedparser Nikola is now installed. nikola help and the Nikola Handbook will assist you from here on.\n","permalink":"https://wimpysworld.com/posts/installing-nikola-on-arch-linux/","tags":["Nikola","Python","Content Management","Arch Linux","Static Site Generator","virtualenv"],"title":"Installing Nikola on Arch Linux"},{"categories":["Linux","Open Source","Tutorial","Content Creation"],"contents":"When I migrated my site to Nikola I wanted to ensure I could manage my blog from the shell, the web, Android smartphone or Android tablet. I took some inspiration from Joe Hewitt\u0026rsquo;s article Dropbox is my publish button and created a free Dropbox account which links to a shared folder on my Dropbox Pro account. I created a simple shell script (invoked via cron every minute) that looks for a trigger file, if the trigger file exists Nikola publishes and deploys the site.\nI am able to edit content from anywhere, on any device, and trigger publishing. Very happy.\nWhat follows is how I install Dropbox on headless servers running Arch Linux and Debian/Ubuntu.\nInstalling Dropbox daemon - all distros Download the latest Dropbox stable release for 32-bit or 64-bit.\nwget -O dropbox.tar.gz \u0026#34;http://www.dropbox.com/download/?plat=lnx.x86\u0026#34; wget -O dropbox.tar.gz \u0026#34;http://www.dropbox.com/download/?plat=lnx.x86_64\u0026#34; Extract the archive and install Dropbox in /opt.\ncd tar -xvzf dropbox.tar.gz sudo mv ~/.dropbox-dist /opt/dropbox sudo find /opt/dropbox/ -type f -exec chmod 644 {} \\; sudo chmod 755 /opt/dropbox/dropboxd sudo chmod 755 /opt/dropbox/dropbox sudo ln -s /opt/dropbox/dropboxd /usr/local/bin/dropboxd Run dropboxd.\n/usr/local/bin/dropboxd You should see output like this:\nThis client is not linked to any account... Please visit https://www.dropbox.com/cli_link?host_id=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx to link this machine. Visit the URL, login with your Dropbox account and link the account. You should see the following.\nClient successfully linked, Welcome Web! dropboxd will now create a ~/Dropbox folder and start synchronizing. Stop dropboxd with CTRL+C.\nArch Linux - systemd Run Dropbox as daemon with systemd. Create /usr/lib/systemd/system/dropbox@.service with the following content.\n[Unit] Description=Dropbox After=local-fs.target network.target [Service] Type=simple ExecStart=/usr/local/bin/dropboxd ExecReload=/bin/kill -HUP $MAINPID KillMode=process Restart=always User=%I [Install] WantedBy=multi-user.target Enable the daemon for your user, run the following replace\u0026lt;user\u0026gt; with your username. This will ensure Dropbox is started when the system boots.\nsudo systemctl enable dropbox@\u0026lt;user\u0026gt; sudo systemctl start dropbox@\u0026lt;user\u0026gt; Debian/Ubuntu - init.d Run Dropbox as daemon with init.d. Create /etc/init.d/dropbox with the following content, replacing \u0026lt;user\u0026gt; with your username.\n#!/bin/sh ### BEGIN INIT INFO # Provides: dropbox # Required-Start: $local_fs $remote_fs $network $syslog $named # Required-Stop: $local_fs $remote_fs $network $syslog $named # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # X-Interactive: false # Short-Description: dropbox service ### END INIT INFO DROPBOX_USERS=\u0026#34;\u0026lt;user\u0026gt;\u0026#34; DAEMON=/opt/dropbox/dropbox start() { echo \u0026#34;Starting dropbox...\u0026#34; for dbuser in $DROPBOX_USERS; do HOMEDIR=`getent passwd $dbuser | cut -d: -f6` if [ -x $HOMEDIR/$DAEMON ]; then HOME=\u0026#34;$HOMEDIR\u0026#34; start-stop-daemon -b -o -c $dbuser -S -u $dbuser -x $HOMEDIR/$DAEMON fi done } stop() { echo \u0026#34;Stopping dropbox...\u0026#34; for dbuser in $DROPBOX_USERS; do HOMEDIR=`getent passwd $dbuser | cut -d: -f6` if [ -x $HOMEDIR/$DAEMON ]; then start-stop-daemon -o -c $dbuser -K -u $dbuser -x $HOMEDIR/$DAEMON fi done } status() { for dbuser in $DROPBOX_USERS; do dbpid=`pgrep -u $dbuser dropbox` if [ -z $dbpid ] ; then echo \u0026#34;dropboxd for USER $dbuser: not running.\u0026#34; else echo \u0026#34;dropboxd for USER $dbuser: running (pid $dbpid)\u0026#34; fi done } case \u0026#34;$1\u0026#34; in start) start ;; stop) stop ;; restart|reload|force-reload) stop start ;; status) status ;; *) echo \u0026#34;Usage: /etc/init.d/dropbox {start|stop|reload|force-reload|restart|status}\u0026#34; exit 1 esac exit 0 Enable the init.d script.\nsudo chmod +x /etc/init.d/dropbox sudo update-rc.d dropbox defaults Install Dropbox client - all distros It is recommended to download the official Dropbox client to configure Dropbox and get its status.\nwget \u0026#34;http://www.dropbox.com/download?dl=packages/dropbox.py\u0026#34; -O dropbox-cli chmod 755 dropbox-cli sed -i s\u0026#39;/#!\\/usr\\/bin\\/python/#!\\/usr\\/bin\\/env python2/\u0026#39; dropbox-cli sudo mv dropbox-cli /usr/local/bin/ For usage instructions run dropbox-cli help.\nDisable LAN Sync Stop Dropbox from sending LAN Sync broadcasts every 30 seconds over port 17500.\ndropbox-cli lansync n I\u0026rsquo;m planning to make more use of Dropbox for content management and content delivery, blog posts to follow.\nReferences http://www.dropboxwiki.com/Text_Based_Linux_Install https://aur.archlinux.org/packages/dropbox/ https://wiki.archlinux.org/index.php/Dropbox ","permalink":"https://wimpysworld.com/posts/dropbox-is-my-nikola-publish-button/","tags":["Nikola","Python","Dropbox","Content Management","Static Site Generator"],"title":"Dropbox is my Nikola publish button"},{"categories":["Linux","Open Source","Tutorial"],"contents":"We have a mix of Linux and Windows users at work. My department use Linux and the rest of the business use Windows. We been running a mixture of LibreOffice and Microsoft Office, which works pretty well until you start trying to collaborate, then it gets messy pretty quickly.\nSo, it was decided at the end of 2012 to migrate everyone, including the Linux users, to Microsoft Office 2010.\nWhat follows is an installation guide for Wine and the 60 day trial version of Office Home and Business 2010 on Arch Linux and Ubuntu. Most of this information was sourced from the Wine AppDB\nhttp://appdb.winehq.org/objectManager.php?sClass=version\u0026amp;iId=17336 Wine for Ubuntu 12.04 LTS (or better) Install Wine on Ubuntu as follows.\nsudo apt-add-repository ppa:ubuntu-wine/ppa sudo apt-get update sudo apt-get install ttf-mscorefonts-installer samba wine1.5 wine-gecko1.8 wine-mono For 64-bit also install the following.\nsudo apt-get install ia32-libs Wine for Arch Linux Update I updated this section on August 8th 2013 to reflect recent changes in Arch Linux Install Wine on Arch Linux as follows.\nsudo pacman -S --needed icoutils libwbclient libxslt lib32-mpg123 p11-kit lib32-p11-kit samba wine winetricks wine-mono wine_gecko sudo packer -S --noedit --noconfirm ttf-ms-fonts For 64-bit also install the following.\nsudo packer -S --noedit --noconfirm lib32-libwbclient lib32-libxslt Installing Office 2010 Once Wine is installed, installing Office 2010 is the same for Arch Linux and Ubuntu.\nCreate a clean wine prefix.\nexport WINEPREFIX=\u0026#34;${HOME}/.msoffice2010\u0026#34; export WINEARCH=\u0026#34;win32\u0026#34; winecfg Click the Libraries tab, select riched20 and click Add. The default entry should read riched20 (native, builtin). Click Apply, then click OK. This will ensure that PowerPoint starts and selection boxes display correctly.\nInstall libxml6 and corefonts with winetricks\nwinetricks msxml6 corefonts Start the Office 2010 setup. In the example below X17-75058.exe is the name of the 60 day trial version of Office Home and Business 2010 that I downloaded.\nwine X17-75058.exe Follow the installation wizard, we are only interested in running the essentials, Word, Excel and PowerPoint. This is what I selected during the install.\nEnter your serial number. Leave ticked Attempt to automatically activate my product online. Click Continue Tick I accept the terms of this agreement Click Continue Click Customise Microsoft Access (Trial) [Not Available] Microsoft Excel [Run all from My Computer] Microsoft OneNote [Not Available] Microsoft Outlook [Not Available] Microsoft PowerPoint [Run all from My Computer] Microsoft Publisher (Trial) [Not Available] Microsoft Visio Viewer [Run from My Computer] Microsoft Word [Run all from My Computer] Office Shared Features [Defaults] Office Tools [Defaults] Click Instal Now. Click Close. That\u0026rsquo;s it. Office 2010 is installed and should be associated with the appropriate file types.\nSome Issues Here are some of the issues we noticed running Office 2010 under Wine.\nAlways install Office 2010 into it\u0026rsquo;s own WINEPREFIX. You are less likely to run into problem that way. Online updates do not work. Fortunately, the trial installer has SP1 integrated. If you purchase Office 2010 licenses you can still use the trial installer with your purchased license key(s). We did test a trial of CrossOver. However, it wouldn\u0026rsquo;t activate Office 2010 on Arch Linux but did activate on Ubuntu. Files saved to cifs mounts are set read-only. This might be a Wine issue or due to the unusual way we have our file server configured, we are still investigating. Uninstalling Office 2010 Should you ever need to, you can uninstall Office 2010 as follows.\nrm -rfv ${HOME}/.msoffice2010/ rm -rfv ~/.local/share/applications/wine-extension-* rm -rfv ~/.local/share/applications/wine/Programs/Microsoft\\ Office/ ","permalink":"https://wimpysworld.com/posts/microsoft-office-2010-on-arch-linux-and-ubuntu/","tags":["wine","Microsoft Office","Arch Linux","Ubuntu","winetricks"],"title":"Microsoft Office 2010 on Arch Linux and Ubuntu"},{"categories":["Linux","Open Source","Tutorial","Content Creation","Self Hosting"],"contents":"I use the nano text editor in preference to vim and have done for years. This is because we used Pine for email at university and my first job, the Pico text editor was used to compose mail messages. Due to the binary only distribution of pico, nano was created as an free software alternative. And that is why I use nano.\nSince I migrated my blog to Nikola I\u0026rsquo;m using nano more frequently as I typically write my blog posts on a remote shell, so I thought I\u0026rsquo;d spend some time to tweak nano a little.\nKeybindings I refreshed my memory of some of the keyboard shortcuts available in nano to be a little more efficient.\nhttp://mintaka.sdsu.edu/reu/nano.html http://www.tuxradar.com/content/text-editing-nano-made-easy http://www.cheatography.com/davechild/content/nano-shortcuts/ Syntax Highlighting Syntax Highlighting is the killer feature for nano that I\u0026rsquo;ve never bothered to configured in the past. I based my configuration one those provided by Craig Barnes. He uses mixins to ensure a consistent colour theme for all the language highlighters. I don\u0026rsquo;t use his custom key bindings however, it gets confusing when connecting to different hosts that have a default nano configuration.\nhttps://github.com/craigbarnes/nanorc ","permalink":"https://wimpysworld.com/posts/the-nano-text-editor/","tags":["nano","pico","Nikola"],"title":"The nano text editor"},{"categories":["Linux","Open Source","Tutorial","Development"],"contents":"We use Python for pretty much all our software development at work. We also use virtualenv and virtualenvwrapper extensively, both for development and deployment.\nWhy is virtualenv so great? It just is. Read the virtualenv documentation. If you\u0026rsquo;re a Python developer you need virtualenv in your life. You also need virtualenvwrapper too.\nvirtualenvwrapper is a set of extensions to Ian Bicking‚Äôs virtualenv tool for creating isolated Python development environments.\nInstalling Python and virtualenvwrapper Outlined below is how I install Python and virtualenvwrapper. We have not yet made the jump to Python 3 at work, hence the references to Python 2.6 and 2.7. Some of us develop on Arch Linux, but all deployments are on Ubuntu.\nArch Linux As Arch Linux is a rolling release we can simply install everything via pacman.\nsudo pacman -Syy sudo pacman -S --needed --noconfirm python-pip python-setuptools python-virtualenv sudo pacman -S --needed --noconfirm python2-pip python2-setuptools python2-virtualenv python-virtualenvwrapper\u0026#34; Simple.\nUbuntu The following was done on Ubuntu Lucid 10.04 LTS.\nAdd some essential PPAs.\nsudo apt-add-repository ppa:bzr/ppa sudo apt-add-repository ppa:git-core/ppa sudo apt-add-repository ppa:fkrull/deadsnakes Update the system and install Python 2.6 and 2.7.\nsudo apt-get update sudo apt-get install libpython2.6 python2.6 python2.6-dev python2.6-minimal sudo apt-get install libpython2.7 python2.7 python2.7-dev python2.7-minimal Remove any apt installed Python packages that we are about to repalce. The versions of these packages in the Ubuntu repos and PPAs are too old.\nsudo apt-get purge python-setuptools python-virtualenv python-pip python-profiler Install distribute.\ncurl -O http://python-distribute.org/distribute_setup.py sudo python2.6 distribute_setup.py sudo python2.7 distribute_setup.py Install pip.\ncurl -O https://raw.github.com/pypa/pip/master/contrib/get-pip.py sudo python2.6 get-pip.py sudo python2.7 get-pip.py Use pip to install virtualenv and virtualenv wrapper.\nsudo pip-2.6 install virtualenv --upgrade sudo pip-2.7 install virtualenv --upgrade sudo pip install virtualenvwrapper Fairly simple.\nThe Snakepit This step is common to Arch Linux and Ubuntu. Create a \u0026ldquo;Snakepit\u0026rdquo; directory for storing all the virtualenvs.\nmkdir ~/Snakepit Add the following your ~/.bashrc to enable virtualenvwrapper.\nexport WORKON_HOME=${HOME}/Snakepit if [ -f /usr/local/bin/virtualenvwrapper.sh ]; then source /usr/local/bin/virtualenvwrapper.sh elif [ -f /usr/bin/virtualenvwrapper.sh ]; then source /usr/bin/virtualenvwrapper.sh fi Creating a virtualenv Open a new shell to ensure that the virtualenvwrapper configuration is active.\nThe following will create a new virtualenv called Nikola5 based on Python 2.7 and will not give access to the global site-packages directory.\nmkvirtualenv -p python2.7 --no-site-packages ~/Snakepit/Nikola5 mkvirtualenv_help shows a full list of arguments, the -r switch can install all the packages listed in a pip requirements file into the newly created virtualenv. Very useful.\nWorking on a virtualenv To workon, or activate, an existing virtualenv do the following.\nworkon Nikola5 You can switch to another virtualenv at any time, just use workon envname. Your shell prompt will change while a virtualenv is being worked on to indicate which virtualenv is currently active.\nWhile working on a virtualenv you can pip install what you need or manually install any Python libraries safe in the knowledge you will not adversely damage any other virtualenvs or the global packages in the process. Very useful for developing a new branch which may have different library requirements than the master/head.\nWhen you are finished working in a virtualenv you can deactivate it by simply executing:\ndeactivate That just about sums up my notes.\n","permalink":"https://wimpysworld.com/posts/python-and-virtualenv-on-arch-linux-and-ubuntu/","tags":["Python","Arch Linux","Ubuntu","virtualenv"],"title":"Python and virtualenv on Arch Linux and Ubuntu"},{"categories":["Linux","Open Source","Tutorial","Security"],"contents":"I have several VPS hosts with different providers using different virtualisation platforms. Naturally I have OpenSSH running on these VPS hosts and deploy either DenyHosts or Fail2Ban to add an extra security layer to thwart SSH brute force attacks and other abuse.\nDenyHosts blocks brute force attacks by adding offending IP addresses to /etc/hosts.deny. It therefore requires the SSH server is configured with tcp_wrappers. Arch Linux dropped support for tcp_wrappers so DenyHosts is not suitable for Arch. Fail2Ban supports blocking via iptables and/or tcp_wrappers and can also block offending hosts that are abusing services other than just sshd.\nDenyHosts on Ubuntu Here is a simple example for DenyHosts on Ubuntu Lucid 10.04 LTS Server.\nsudo apt-get install denyhosts That\u0026rsquo;s it. The default configuration will provide suitable prevention, but do take a look at /etc/denyhosts.conf for a full run down of all available options. I use the defaults with the following exceptions:\nPURGE_DENY = 5d PURGE_THRESHOLD = 2 ADMIN_EMAIL = SYSLOG_REPORT=NO You might want to consider whitelisting some of your own IP address. Create a file called allowed-hosts in /var/lib/denyhosts and list each of your \u0026ldquo;trusted\u0026rdquo; IP addresses.\nDenyHosts can be restarted by executing:\nsudo /etc/init.d/denyhosts restart Fail2Ban on Arch Linux Fail2Ban now supports systemd.\nConfiguration files are stored in /etc/fail2ban. General configuration is /etc/fail2ban/jail.conf, but this file might be overwritten in the future. To preserve customisations, create /etc/fail2ban/jail.local and add your local configuration settings to it. In the example below some IP addresses are whitelisted and the default backend is set to systemd:\n[DEFAULT] ignoreip = 172.16.0.2/32 backend = systemd Next create a custom sshd configuration in /etc/fail2ban/jail.d/sshd.conf which will temporarily ban offending IP addresses.\n# fail2ban SSH # block ssh after 3 unsuccessful login attempts for 10 minutes [sshd] enabled = true action = iptables[chain=INPUT, protocol=tcp, port=22, name=sshd] maxRetry = 3 findtime = 600 bantime = 600 port = 22 The \u0026lsquo;action\u0026rsquo; creates DROP rule in iptables after 3 unsuccessful login attempts, valid for 10 minutes (bantime). Findtime defines time frame in which fail2ban will count failed login attempts from logs, so if one IP has 3 incorrect login attempts in last 10 minutes, it will be banned.\nEnable and start the Fail2Ban daemon.\nsudo systemctl enable fail2ban sudo systemctl start fail2ban Basic commands for fail2ban-client:\nfail2ban-client start sshd fail2ban-client stop sshd fail2ban-client reload sshd fail2ban-client status sshd fail2ban-client set sshd unbanip 172.16.0.4 See the Arch Linux Fail2Ban Wiki page for more details.\nReferences\nhttp://krisko210.blogspot.co.uk/2014/03/setting-up-fail2ban.html SSH best practice DenyHosts and Fail2Ban do not provide complete protection against SSH brute force attacks. I employ other SSH best practice to better secure the SSH services I expose to the Internet, and so should you. The following is a good reference.\nGetting started with SSH security and configuration Other SSH brute force prevention tools In the interests of fairness, other SSH brute force preventation tools are available.\nSshgaurd sshdfilter Uncomplicated Firewall Rate Limiting Do you know any other tools that help prevent SSH brute force attacks?\n","permalink":"https://wimpysworld.com/posts/ssh-brute-force-defense/","tags":["Arch Linux","Ubuntu","OpenSSH","DenyHosts","Fail2Ban"],"title":"SSH brute force defense"},{"categories":["Linux","Entertainment"],"contents":"Something wonderful has happened! Jesus Alvarez has created pre-compiled packages for netflix-desktop for Arch Linux.\nThere is no need for me to repeat the installation instructions as they are clearly documented on the page below.\nArch Netflix - Netflix on the desktop through WINE The source code for both of the packages can be found at archnetflix-github.\nFor reporting problems, please see the AUR page at netflix-desktop-aur or the announcement forum posting.\n","permalink":"https://wimpysworld.com/posts/netflix-for-archlinux/","tags":["Arch Linux","Netflix","wine"],"title":"Netflix for ArchLinux"},{"categories":["Linux","Security"],"contents":"We use two server monitoring services at work, one that does external availability checks of critical services and another agent based monitor that reports various system metrics. Neither of these monitoring tools offer sensible free plans.\nI recently setup monitor.us to do external monitoring of my VPS hosts. It\u0026rsquo;s very good and offers many tests (internal and external), smartphone apps and reports. All are available on the free plan. However, the user interface is cumbersome, the reports are ugly and it feels too formal for my personal use. Therefore I no longer use it, but it does a job, so give it a try.\nI don\u0026rsquo;t require agent based systems monitoring. Simple external availability monitoring is all I need for the few personal websites and services I run. So I went off to find and alternative and after some google-fu I found StatusCake.\nStatusCake is easy to configure, offers monitoring of http(s), TCP ports and ICMP Ping. Notifications can be delivered via Boxcar, Pushover, NotiApp, Skype, Twitter, email and SMS. StatusCake also looks beautiful and their Real Browser Testing feature is very interesting.\nSeveral plans are available at attractive prices and the free plan supports unlimited sites. Brilliant! Perfect for personal use. StatusCake has only been around since August 2012 (as far as I can tell) but is already shaping up to be real contender to Pingdom.\nWhat monitoring services are you using?\n","permalink":"https://wimpysworld.com/posts/service-monitoring-with-statuscake/","tags":["Server Monitoring"],"title":"Service Monitoring with StatusCake"},{"categories":["Development","Tutorial"],"contents":"As I mentioned in a previous post we are prepairing to migrate our Bazaar repositories to Git, or more precisely to GitHub. This migration also heralds the Open Source releases of many of the core technologies we\u0026rsquo;ve been developing at Flight Data Services for the last few years.\nI want to track visits for our GitHub projects. A bit of Googling turned up githalytics which enables you to track visits and page views for your GitHub projects using [http://www.google.com/analytics/](Google Analytics).\nTo use it, create a new Google Analytics property ID for your GitHub project, head over to http://githalytics.com/ and complete the web form. You\u0026rsquo;ll be provided a Markdown snippet to insert in your projects README.md. It will look something like this:\n[![githalytics.com alpha](https://cruel-carlota.pagodabox.com/0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f \u0026#34;githalytics.com\u0026#34;)](http://githalytics.com/YourGitHubName/YourGitHubProject) Add the snippet to README.md and push the changes. When someone visits your GitHub project page, the visit will be tracked. Great!\nHowever, we write all our documentation using reStructuredText. But after a quick Twitter and email exchange with Dimitrios from githalytics and I had a reStructuredText snippet. It looks something like this:\nimage:: https://cruel-carlota.pagodabox.com/0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f :alt: githalytics.com :target: http://githalytics.com/YourGitHubName/YourGitHubProject Same drill, except add this snippet to README.rst and push the changes.\nSo there you have it, Google Analytics tracking of your GitHub project landing page. If you have more than one project, create a Google Analytics property ID and githalytics tracking snippet for each project.\nReferences http://githalytics.com/ http://githalytics.tumblr.com/ http://coderwall.com/team/githalytics http://stackoverflow.com/questions/4376560/add-google-analytics-to-github-wiki-pages ","permalink":"https://wimpysworld.com/posts/github-analytics/","tags":["Git","GitHub","Markdown","reStructuredText"],"title":"GitHub Analytics"},{"categories":["Linux","Open Source","Development","Tutorial"],"contents":"We have been using Bazaar for source control at work for nearly five years. We are about to Open Source most of our core technologies and decided that GitHub is the best way to encourage community participation. We have signed up for a Silver plan at GitHub and will migrate all our Bazaar repositories to Git.\nI have a few personal projects in Bazaar repositories hosted on Launchpad. I decided to migrate my projects to GitHub in order to learn the migration process. What follows is an overview of how I did it using a fresh virtual machine running Ubuntu 10.04 LTS Server. I used a little project of mine called nullserv in the examples below.\nAdd the Bazaar and Git PPAs.\nsudo apt-get install python-software-properties sudo apt-add-repository ppa:bzr/ppa sudo apt-add-repository ppa:git-core/ppa sudo apt-get update Install bzr (and its requirements), curl and git.\nsudo apt-get install bzr bzr-fastimport curl git python-paramiko Add the SSH keys and identify yourself.\nbzr whoami \u0026#34;Your Name \u0026lt;name@example.org\u0026gt;\u0026#34; git config --global user.name \u0026#34;Your Name\u0026#34; git config --global user.email you@example.org If your Bazaar repository is hosted on Launchpad assert your identity.\nbzr launchpad-login flexiondotorg Branch the Bazaar repository.\nbzr branch lp:~flexiondotorg/+junk/nullserv cd nullserv git init bzr fast-export --plain `pwd` | git fast-import This step is optional. It will delete and commit the deletions to the Bazaar repository.\nfor FILE in *; do rm -rfv \u0026#34;${FILE}\u0026#34;; done echo \u0026#34;This repository has been migrated to Git. https://github.com/flexiondotorg/nullserv\u0026#34; \u0026gt; README bzr add README bzr commit -m \u0026#34;This repository has been migrated to Git. https://github.com/flexiondotorg/nullserv\u0026#34; bzr push :parent Remove the Bazaar repository and reset the Git repository.\nrm -rf .bzr README git reset HEAD Create .gitattributes to normalise line endings.\ncat \u0026gt;.gitattributes\u0026lt;\u0026lt;ENDGITATTRIBS # Normalise line endings: * text=auto # Prevent certain files from being exported: .gitattributes export-ignore .gitignore export-ignore ENDGITATTRIBS git add .gitattributes Migrate .bzrignore to .gitignore.\ngit mv .bzrignore .gitignore echo \u0026gt;\u0026gt; .gitignore echo \u0026#34;# Keep empty directories:\u0026#34; \u0026gt;\u0026gt; .gitignore echo \u0026#34;!*/.git*\u0026#34; \u0026gt;\u0026gt; .gitignore Ensure empty directories are retained by git.\nfind -empty -type d -not -iwholename \u0026#39;*.git*\u0026#39; -exec touch \u0026#39;{}/.gitkeep\u0026#39; \u0026#34;;\u0026#34; git add **/.gitkeep Commit the migrated repository\ngit commit -a -m \u0026#34;Migrated from Bazaar to Git.\u0026#34; Thanks to Chris for pointing out git filter-branch in the comments. If you need to modify the author info in your repository history, you can do so with this, just replace the names and email addresses accordingly.\nBEWARE! This should not be performed on a repo that has been shared with others. Use at your own risk.\ngit filter-branch --commit-filter \u0026#39; if [ \u0026#34;$GIT_COMMITTER_NAME\u0026#34; = \u0026#34;Fred\u0026#34; ]; then GIT_COMMITTER_NAME=\u0026#34;Fred Flintstone\u0026#34;; GIT_AUTHOR_NAME=\u0026#34;Fred Flintstone\u0026#34;; GIT_COMMITTER_EMAIL=\u0026#34;fred@example.org\u0026#34;; GIT_AUTHOR_EMAIL=\u0026#34;fred@example.org\u0026#34;; git commit-tree \u0026#34;$@\u0026#34;; elif [ \u0026#34;$GIT_COMMITTER_NAME\u0026#34; = \u0026#34;Barney\u0026#34; ]; then GIT_COMMITTER_NAME=\u0026#34;Barney Rubble\u0026#34;; GIT_AUTHOR_NAME=\u0026#34;Barney Rubble\u0026#34;; GIT_COMMITTER_EMAIL=\u0026#34;barney@example.org\u0026#34;; GIT_AUTHOR_EMAIL=\u0026#34;barney@example.org\u0026#34;; git commit-tree \u0026#34;$@\u0026#34;; else git commit-tree \u0026#34;$@\u0026#34;; fi\u0026#39; HEAD If you want to delete any files from the commit history, you can optionally do that now.\ngit filter-branch -f --index-filter \u0026#34;git rm --cached --ignore-unmatch *.THIS *.THAT\u0026#34; \\ --prune-empty --tag-name-filter cat -- --all rm -rf .git/refs/original/ git reflog expire --expire=now --all git gc --prune=now Resume here, regardless of whether you deleted any files from the commit history or not. Remove everything from the index.\ngit rm --cached -r . Write both the index and working directory from git\u0026rsquo;s database.\ngit reset --hard Prepare to make a commit by staging all the files that will get normalized. This is your chance to inspect which files were never normalized. You may get lots of messages like: warning: CRLF will be replaced by LF in file.\ngit add . git commit -m \u0026#34;Forced line endings to eol=lf\u0026#34; Aggressively pack the repository.\ngit gc --aggressive --prune=now At this point you have a migrated git repository. You can poke about a check that everything is present and correct.\nOptionally you can create a new GitHub repository using their API. Replace USER and PASS with your GitHub login crednetials.\ncurl -u \u0026#39;USER:PASS\u0026#39; https://api.github.com/user/repos -d \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;nullserv\u0026#34;}\u0026#39; If you want to create repositories for an Organisation the following will work. Replace YourOrganisation with the organisation name your are a member of.\ncurl -u \u0026#39;USER:PASS\u0026#39; https://api.github.com/orgs/YourOrganisation/repos -d \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;nullserv\u0026#34;}\u0026#39; Private repositories can be created, providing you have a paid GitHub account, by changing the POST data as follows.\n\u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;nullserv\u0026#34;,\u0026#34;private\u0026#34;:\u0026#34;true\u0026#34;}\u0026#39; Lastly, push to the newly created GitHub repo.\ngit remote add origin git@github.com:flexiondotorg/nullserv.git git push -u origin master All done, the Bazaar repository has been crippled and the Git repository is ready for use on GitHub.\nReferences https://gist.github.com/624941 http://stackoverflow.com/questions/2423777/is-it-possible-to-create-a-remote-repo-on-github-from-the-cli-without-ssh http://stackoverflow.com/questions/750172/how-do-i-change-the-author-of-a-commit-in-git https://help.github.com/articles/changing-author-info http://developer.github.com/v3/repos/ https://help.github.com/articles/dealing-with-line-endings#platform-all ","permalink":"https://wimpysworld.com/posts/migrating-bazaar-to-git/","tags":["Bazaar","Git","GitHub"],"title":"Migrating Bazaar to Git"},{"categories":["Linux","Open Source","Content Creation","Tutorial"],"contents":"I recently migrated three sites from a self hosted Wordpress installation to Nikola. Nikola is a static site and blog generator written in Python.\nAlthough I use both reStructuredText and Markdown, I decided to migrate my Wordpress content to Markdown.\nThis is by no means an exhaustive Wordpress to Nikola migration guide but it should provide enough clues for anyone else wanting to do the same. The following was done on Ubuntu 10.04 LTS.\nExport the Wordpress content. Tools -\u0026gt; Export -\u0026gt; All Content\nUse xmllint to find any errors in the Wordpress XML export and fix them.\nNikola 5 UPDATE! I\u0026rsquo;ve added the instructions for install Nikola 5 since fist publishing this post.\nInstall Nikola 5 in a virtualenv using virtualenvwrapper.\ncd ~ sudo apt-get install libxslt1-dev libxml2-dev libjpeg62-dev python2.6-dev wget http://nikola-generator.googlecode.com/files/nikola-5.zip unzip ~/nikola-5.zip mkvirtualenv -i markdown -r ~/nikola-5/requirements.txt --use-distribute nikola-5 cd ~/nikola-5 python setup.py install Nikola 4 Install Nikola 4.0.3, in a virtualenv using virtualenvwrapper. Nikola 4.0.3 spits deprecation warnings with doit\u0026gt;=0.16.1 hence the use of sed.\ncd ~ sudo apt-get install libxslt1-dev libxml2-dev libjpeg62-dev python2.6-dev wget http://nikola-generator.googlecode.com/files/nikola-4.0.3.zip unzip ~/nikola-4.0.3.zip sed -i \u0026#39;s/\u0026gt;=0\\.16/==0\\.16/\u0026#39; ~/nikola-4.0.3/requirements.txt mkvirtualenv -i markdown -r ~/nikola-4.0.3/requirements.txt --use-distribute nikola cd nikola-4.0.3 python setup.py install Import the Wordpress content.\ncd nikola import_wordpress wordpress.linted.xml Use html2text to convert the HTML markup in new_site/posts/*.wp to real Markdown.\nUse the Disqus Wordpress Plug-in to migrate Wordpress comments to Disqus.\nIf required, generate a list of the Wordpress URLs for Nikola redirections.\ngrep \u0026#34;\u0026lt;link\u0026gt;\u0026#34; wordpress.linted.xml | sed -e \u0026#39;s/\u0026lt;link\u0026gt;//g\u0026#39; -e \u0026#39;s/\u0026lt;\\/link\u0026gt;//g\u0026#39; I migrated from several sub-domains to one top-level and the Wordpress URLs I was using can\u0026rsquo;t be persevered with Nikola. I use a combination of Nikola redirects and nginx configuration to handle the re-directions.\nAt this point the bulk of the migration is done. I tweaked the Nikola conf.py to use .md files instead of .wp, added some assets to the Nikola files directory, configured deployments and updated the theme. I also decided to axe some obsolete blog posts.\nMigrating to Disqus has been very frustrating and although my comments have now been migrated the Migrate Threads has yet reflect the new URLs of my posts. There is no visibility of what, if anything, is happening when you execute the Disqus URL Mapper. This is not a Nikola issue.\nI am extremely happy with Nikola itself and it has proved itself flexible and I can now capture my notes in a familiar format and in a familiar environment, Python. Next steps are to integrate Nikola with Dropbox so I can publish from any device with ease and add a search facility.\n","permalink":"https://wimpysworld.com/posts/migrating-wordpress-to-nikola/","tags":["Nikola","Python","Wordpress","Content Management","Static Site Generator"],"title":"Migrating Wordpress to Nikola"},{"categories":["Content Creation"],"contents":"Yesterday I needed to create a data flow diagram for one of our technology partners at work. They are presenting to the FAA and need to explain how we (Flight Data Services) can replay the data from tens of thousands of flights in extremely short order.\nAnyway, I went looking for a good tool to draw the diagram. I\u0026rsquo;ve tried several in the past and never really been satisfied. I found draw.io and it is really good. This is how they describe it.\ndraw.io is an online diagramming application and github project. It features the full range of visual configuration you expect, as well as web application features such as a full range of export options, a large collection of icons, real-time collaboration and embedded widget sharing.\nThe shape library is extensive and pretty consistent. I was able to export the diagram in the formats I wanted. Overall, it\u0026rsquo;s not half bad and completely free.\n","permalink":"https://wimpysworld.com/posts/drawio-draw-diagrams-online-free/","tags":["Web Applications"],"title":"draw.io - Draw diagrams online, free"},{"categories":["Linux","Computer Hardware","Gadgets"],"contents":"I\u0026rsquo;ve recently taken delivery of my first Android tablet, the Ployer Momo8 IPS.\nI purchased mine from GTR Electronics as they have a track record for excellent customer service, provide 12 month warranty and their devices are free from Chinese apps and bloatware. I wrote up a review on Amazon.co.uk, see below.\nA quality Android tablet with a budget price As I mention in the review above, I\u0026rsquo;ve rooted the Momo8 IPS. The following were useful references for the rooting.\nhttp://forum.xda-developers.com/showthread.php?t=1893504 http://flashmyandroid.com/forum/showthread.php?1183-How-to-root-the-Cube-U30GT\u0026amp;p=11116 http://www.pandawillforum.com/showthread.php?13111-How-to-Root-UG802-Rockchip-RK3066-mini-PC Update Since writing this blog post I\u0026#8217;ve made a pre-rooted custom firmware for the Ployer Momo 8 IPS. Installing it may be easier than following the instructions below. Ployer Momo8 IPS Custom Firmware Here are the basic steps to getting root on the Momo8 IPS.\nEnable USB Debugging on the Momo8 IPS - Settings ‚Äì\u0026gt; Developer Options Find a Windows computer. Download and install Momorobo 2.0.2.290. Start Moborobo and connect the Momo8 IPS to the Windows computer. Wait for Moborobo to establish a connection to the tablet. Download and install ZhuoDaShi 2.2.9. Start ZhuoDaShi. It is a Chinese language application only, so this is somewhat tricky. Wait for ZhuoDaShi connect to your Momo8 IPS. Click the highlighted text that includes the word ROOT among some Chinese text then click on the big ROOT button. After a short while you should see some Chinese text in green. Click the large button. You should now have root and the SuperSU app will be listed in your apps. Install Root Checker on the Momo8 IPS to ensure you have root. Once satisfied you have root (I ran Titanium Backup to be absolutely sure) you can uninstall the Momorobo daemon and ZhuoDaShi app the from your Momo8 IPS. The version of SuperSU installed by ZhuoDaShi is quite old and can\u0026rsquo;t be updated via the Google Play Store. To remedy this do the following. Under SuperSU -\u0026gt; Settings select Switch superuser app Now open Google Play Store and install SuperSU. Hope this is helpful to someone else, but proceed with caution.\n","permalink":"https://wimpysworld.com/posts/quality-android-tablet-on-a-budget-ployer-momo8-ips/","tags":["Android","Tablet","Ployer Momo8 IPS","RK3066"],"title":"Quality Android tablet on a budget - Ployer Momo8 IPS"},{"categories":["Gadgets"],"contents":"I recently migrated several domains I manage for family and friends to the \u0026ldquo;free\u0026rdquo; version of Google Apps.\nI setup the Gmail app on their Android phones for them and email arrives promptly and spam is pretty much eradicated. Happy days.\nHowever, the Gmail app for Android only supports a conversation view of emails. My wife and I hate that and have actually missed emails because new emails get burried in an earlier email conversation way down your inbox. Frustratingly changing the preferences on the Gmail website to disable the conversation view does not propagate to the Gmail app.\nThe best solution to this that I have found is to to not use the Gmail app and install K-9 Mail instead connected to Google App accounts via IMAP and SMTP. K-9 Mail (only?) supports a traditional list view of your emails and unlike the built in Email app for Android K9-Mail supports push notifications so you get near instantaneous notification of new email.\nIf you want to support the K-9 Mail developer then consider purchasing Kaiten Mail which is an enhanced version of K-9 Mail and is particularly good on Android tablets.\n","permalink":"https://wimpysworld.com/posts/android-gmail-conversation-view/","tags":["Android","Messaging","Gmail"],"title":"Android Gmail Conversation View"},{"categories":["Linux","Development","Open Source"],"contents":"The MATE Desktop Environment is the continuation of GNOME 2. MATE Desktop provides an intuitive and attractive desktop environment using traditional metaphors for Linux and other Unix-like operating systems.\nOrganisation: MATE Desktop Date: June 2012 - date Role: Developer \u0026amp; Community Manager ","permalink":"https://wimpysworld.com/projects/mate-desktop/","tags":["MATE Desktop","C","GTK","Python","make","Community"],"title":"MATE Desktop"},{"categories":["Linux","Open Source"],"contents":"I\u0026rsquo;ve been working a shell script for Arch Linux that automatically configures my preferred GNOME 3 setup on my netbook, laptops and workstations. The main features are:\nQuickly deploys Arch Linux to my specifications Supports i686 and x64_64. Detects ATI/AMD, Intel and Nvidia chipsets and configures the Open Source video drivers and enables early KMS. Hardware and location aware. Installation and configuration can be different for Home vs Work or Desktop vs Netbook. Detects and correctly configures some device specific hardware, such as touch screens and wireless drivers. Automatically configures DAEMONS array. Includes custom power management hooks for pm-utils. Designed to safely run multiple times so that it can be used as a tool for keeping all systems consistent. I\u0026rsquo;ve dubbed this script Arch Angel. I\u0026rsquo;m undecided if I\u0026rsquo;ll release it publicly since it is very much my personal preferences and to some extent my colleagues at work. I suppose the real reason for this post is that I\u0026rsquo;ve been wanting to take Shelr for a test drive, so click the Play button below to see an example run of Arch Angel.\n","permalink":"https://wimpysworld.com/posts/arch-linux-angel/","tags":["Arch Linux","GNOME","Bash","Installer"],"title":"Arch Linux Angel"},{"categories":["Linux","Open Source"],"contents":"In a recent Ubuntu community feedback session run on IRC Mark Shuttleworth said:\nif you are a super-technologist then there is value in learning all about linux from every angle try arch. try gentoo. try fedora. try debian. try suse. they are all good\nSo, I did. I tried Arch Linux and it is is not just good, it\u0026rsquo;s truly brilliant! The truth is, I didn\u0026rsquo;t take Mark Shuttleworth\u0026rsquo;s advice. I took the advice of a quietly spoken work colleague. Whenever he saw me getting frustrated with Ubuntu he reminded me (quietly) that he was running Arch Linux and that it was really rather good. It turns out I should have listened to my colleague years ago, because he was right all along. He often is.\nI started learning Arch Linux a few weeks ago and as of the time of writing all our home computers are running Arch Linux and so is my office workstation. I moved away from Ubuntu (which I\u0026rsquo;ve been using daily since 2004) because:\nI often find myself needing/wanting updated packages on my workstations. Ubuntu + PPAs just wasn\u0026rsquo;t doing it for me anymore. I concluded I needed a rolling release distribution. In my humble opinion, Unity is a software engineering solution developed (by programmers) not designed using UI-patterns (by user interface designers) consequently it sucks the big one. It was less hassle for me to switch to Arch Linux than bend Ubuntu to my will. That said, I do wish Canonical every success with Unity, they\u0026rsquo;ll need it, as it needs some polish and refinement as it stands today. For anyone interested in giving Arch Linux a try here are some observations.\nArch Linux does not hold you hand, you should be competent with a Linux based distribution. I\u0026rsquo;ve been using Linux since 0.99patch2 so I think I qualify. Read the Unofficial Beginners\u0026rsquo; Guide and Official Installation Guide before you install anything. Install Arch Linux in a virtual machine to get acquainted. Be prepared to fix your own problems. Fortunately the Arch Linux Wiki and Arch Linux Forums are a great source of good information. Here is a list of what I most like about Arch Linux:\nIt\u0026rsquo;s a rolling release. I\u0026rsquo;ve already progressed through several kernels and been upgraded from GNOME 3.2 to 3.4. No fuss, no mess. It keeps out of my way, I get to build the OS they way I want it. Yes, I\u0026rsquo;m looking at you Unity, Overlay Scrollbars, Unity App Indicators, Ubuntu One and upstart! The AUR. It\u0026rsquo;s like a great big PPA. Creating my own packages is super simple. Adding my own packages to the AUR is super simple. I\u0026rsquo;ve already contributed 8 packages. I\u0026rsquo;m learning more about Linux than I have done in years. Here\u0026rsquo;s what I\u0026rsquo;m not so keen about, but can live with.\nSome of the comments in the Forums and AUR are from real arse hats with a superiority complex. New comers may be put off by their tone and look elsewhere. The AUR. Package quality in the AUR is variable, some are pretty poor. So long as the maintainer is not one of the aforementioned arse hats then contributing fixes and improvements is easy. It\u0026rsquo;s a rolling release, so may not be suitable for serious server deployments. That said, I will migrate my own servers to Arch Linux in due course and see if I can prove myself wrong. So there you have it, I like Arch Linux very much and recommend it to other technically competent individuals looking to regain control of their computer(s).\n","permalink":"https://wimpysworld.com/posts/take-mark-shuttleworths-advice-try-arch-linux/","tags":["Ubuntu","Arch Linux"],"title":"Take Mark Shuttleworth's advice, try Arch Linux"},{"categories":["Linux","Open Source","Development"],"contents":"Canonical disabled my Java PPA at the end of last week. So I\u0026rsquo;ve developed another solution for installing Java on Ubuntu which doesn\u0026rsquo;t infringe any copyrights, licenses, terms of use or CoC\u0026rsquo;s. However, by running this script to download Java you acknowledge that you have read and accepted the terms of the Oracle end user license agreement.\nhttp://www.oracle.com/technetwork/java/javase/terms/license/ My script is an automated wrapper for Janusz Dziemidowicz Debian packaging scripts for Java 6. My new script simply downloads the Java binary installers from Oracle, builds the .deb packages locally on your computer and creates a local \u0026lsquo;apt\u0026rsquo; repository for them. Once my script has been executed you can then \u0026lsquo;apt-get\u0026rsquo; install/upgrade Java 6 from your local repository. Packages are compatible with \u0026ldquo;official\u0026rdquo; Ubuntu ones and pre-existing Java 6 packages will upgrade cleanly. You can find the script and full usage instructions on github.\nPlease read the README file for a more detailed explanation of how the script works and how to use it. If anyone has any problems, then please submit a ticket on my Issue Tracker.\n","permalink":"https://wimpysworld.com/posts/install-sun-java-6-jre-and-jdk-from-deb-packages/","tags":["Ubuntu","Debian","Java","JDK","JRE","Bash"],"title":"Install Sun Java 6 JRE and JDK from .deb packages"},{"categories":["Linux","Open Source","Development"],"contents":"Update Friday 13th January 2012 My Java PPA has been disabled by Canonical, possibly because they violate the Ubuntu CoC and PPA terms of use, as Jef Spaleta noted in the comments below, although I\u0026rsquo;ve had no communication from Canonical at this time. I\u0026rsquo;m preparing an alternative solution, for those of you who need Sun Java 6, that doesn\u0026rsquo;t violate and copyrights, CoCs or terms of use. A new blog post will be made when that alternate solution is available.\nUpdate Monday 16th January 2012 I\u0026rsquo;ve developed another solution for installing Java 6u30 on Ubuntu which doesn\u0026rsquo;t infringe any copyrights, licenses, terms of use or CoC\u0026rsquo;s.\nInstall Sun Java 6 JRE and JDK from .deb packages Sun Java 6 packages are being removed from Ubuntu in the near future for the following reasons:\nAs of August 24th 2011, Canonical no longer have permission to redistribute new Java packages as Oracle has retired the \u0026ldquo;Operating System Distributor License for Java\u0026rdquo;. Oracle has published an advisory about security issues in the version of Java currently in the partner archive. Some of these issues are currently being exploited in the wild. Due to the severity of the security risk, Canonical released a security update for the Sun JDK browser plugin which disables the plugin on all machines. In the near future, Canonical will remove all Sun JDK packages from the Partner archive. This will be accomplished by pushing empty packages to the archive, so that the Sun JDK will be removed from all users machines when they do a software update. Users of these packages who have not migrated to an alternative solution will experience failures after the package updates have removed Oracle Java from the system. See the full Canonical notice below.\nhttps://lists.ubuntu.com/archives/ubuntu-security-announce/2011-December/001528.html My personal motivations for creating this PPA are as follows:\nI require Sun Java 6 for two enterprise applications we use at work. OpenJDK is not fully compatible.\nI require Sun Java 6 for two desktop applications at home (so does my father-in-law). OpenJDK not compatible in one instance and not fully compatible in the other.\nI require Sun Java 6 browser plugin for a web applications I use at home. OpenJDK is not compatible.\nA friend of mine requires Sun Java 6 for building AOSP from source. OpenJDK is not compatible.\nSome friends of mine play Minecraft, apparently this will help ;-)\nJanusz Dziemidowicz made it easy for me - https://github.com/rraptorr/sun-java6 The PPA currently publishes Sun Java 6 1.6.0.30 for:\nLucid i386/amd64\nMaverick i386/amd64\nNatty i386/amd64\nOneiric i386/amd64\nPrecise i386. However, amd64 is failing to build on Precise. I will try and fix this in due course.\nTo Sun Java 6 , previously installed via packages, do the following.\nsudo apt-add-repository ppa:flexiondotorg/java sudo apt-get update sudo apt-get dist-upgrade To install Sun Java 6 JRE do the following:\nsudo apt-add-repository ppa:flexiondotorg/java sudo apt-get update sudo apt-get install sun-java6-jre To install Sun Java 6 browser plugin do the following:\nsudo apt-add-repository ppa:flexiondotorg/java sudo apt-get update sudo apt-get install sun-java6-plugin To install Sun Java 6 JDK do the following:\nsudo apt-add-repository ppa:flexiondotorg/java sudo apt-get update sudo apt-get install sun-java6-jdk You can take a look a round my PPA from the URL below:\nhttps://launchpad.net/~flexiondotorg/+archive/java ","permalink":"https://wimpysworld.com/posts/sun-java-1.6.0.30-packages-for-ubuntu/","tags":["Ubuntu","Debian","Java","JDK","JRE","PPA"],"title":"Sun Java 1.6.0.30 packages for Ubuntu"},{"categories":["Linux","Open Source","Tutorial"],"contents":"I tried Unity in Ubuntu Natty 11.04 and Ubuntu Oneiric 11.10. We\u0026rsquo;ve agreed to hate each other. A few weeks ago I started using GNOME 3 and it only took me a couple of hours to adapt to it\u0026rsquo;s workflow. GNOME 3 is now my desktop environment at home and and work. I love it! If you\u0026rsquo;d like to give GNOME 3 a whirl then you could try installing Jan Hoffman\u0026rsquo;s Ubuntu GNOME Shell Remix from either the 32-bit or 64-bit ISOs he has prepared. This will give a \u0026ldquo;pure\u0026rdquo; GNOME 3 experience.\nhttp://ubuntu-gs-remix.sourceforge.net/p/home/ If you already have Ubuntu 11.10 installed then you can install GNOME 3 alongside Unity. Here are the incantations you\u0026rsquo;ll need to utter in a shell.\nsudo apt-add-repository ppa:jan-hoffmann/gnome-shell sudo apt-add-repository ppa:aegirxx-googlemail/gnome-shell-extensions sudo apt-add-repository ppa:gnome3-team/gnome3 sudo apt-add-repository ppa:webupd8team/gnome3 sudo apt-get update sudo apt-get install libglib2.0-bin gnome-core gnome-documents gnome-shell gnome-sushi gnome-tweak-tool gnomeshell-default-settings gtk3-engines-unico The repositories added above will give you access to Jan\u0026rsquo;s GNOME 3 meta packages, updated GNOME 3 packages and some extra GNOME 3 extensions. GNOME 3 extensions add all manner of additional tweaks and functionality. Some extensions can even provide a user experience more akin to that of GNOME 2.\nhttp://intgat.tigress.co.uk/rmy/extensions/index.html In order to get acquainted with GNOME 3 I suggest you read the Discover GNOME 3 (watch the videos too) and GNOME 3 Cheat Sheet pages. Having read those you\u0026rsquo;ll soon master GNOME 3. After you\u0026rsquo;ve used GNOME 3 for a while you may conclude it is a more usable desktop environment than Unity, which isn\u0026rsquo;t a surprising conclusion to arrive at given Unity sucks the big one right now. If you want a \u0026ldquo;pure\u0026rdquo; GNOME 3 experience then the following commands will purge Unity and other bits and bobs that GNOME 3 simply doesn\u0026rsquo;t require.\nRemove Unity sudo apt-purge unity unity-2d unity-2d-launcher unity-asset-pool unity-common \\ unity-greeter unity-lens-applications unity-lens-music libunity-misc4 Remove Overlay Scrollbars These just don\u0026rsquo;t work on my netbook since they regularly obscure portions of the window I actually want to click on. The can safely be removed even if you intend to continue using Unity.\nsudo apt-get purge overlay-scrollbar liboverlay-scrollbar-0.2-0 liboverlay-scrollbar3-0.2-0 Remove Indicators If you never going back to Unity, Indicators can be safely removed.\nsudo apt-get purge xchat-gnome-indicator indicator-appmenu indicator-power \\ indicator-session indicator-sound indicator-status-provider-mc5 \\ libindicator-messages-status-provider1 Remove Global Menu Again, Global Menu is not used by GNOME 3. So if you not going back to Unity these can be safely removed.\nsudo apt-get purge appmenu-gtk3 appmenu-gtk appmenu-qt firefox-globalmenu \\ thunderbird-globalmenu Finally, a word or warning: Distribution upgrades are not possible! You can\u0026rsquo;t upgrade to a newer version of Ubuntu when using Jan Hoffman\u0026rsquo;s Ubuntu GNOME Shell Remix or if you modify an existing Ubuntu 11.10 using my method above. You will have to do a full install once the next Ubuntu release is available. This can\u0026rsquo;t be fixed as long as Jan\u0026rsquo;s meta packages are unofficial, because the distribution upgrade process requires having installed one of the desktop meta packages from the official Ubuntu repositories.\n","permalink":"https://wimpysworld.com/posts/installing-gnome-3-on-ubuntu-11.10/","tags":["GNOME","Ubuntu","Unity"],"title":"Installing GNOME 3 on Ubuntu 11.10"},{"categories":["Linux","Open Source","Development"],"contents":"Like many others I wanted Shotwell 0.11 for Lucid and Maverick so I\u0026rsquo;ve created a PPA for it.\nhttps://launchpad.net/~flexiondotorg/+archive/shotwell My PPA contains Shotwell 0.11 built for Ubuntu Lucid 10.04 LTS and Ubuntu Maverick 10.10. I created this PPA because I run Lucid at home and wanted the new version of Shotwell. Sadly, Yorba aren\u0026rsquo;t going to provide new Shotwell packages for Lucid due to the reasons discussed in the following ticket: -\nhttp://trac.yorba.org/ticket/3015 As mentioned in the ticket above, there are newer versions of Shotwell available for Lucid in other PPAs. However, those PPAs contain hundreds of packages. If you\u0026rsquo;re not that brave, like me, then hopefully my PPA provides what you need. I have built Shotwell with minimal changes from the original Yorba source packages and not polluted my PPA with any unnecessary packages. Since Shotwell 0.11 you must enable the GStreamer PPA, see the ticket below for the reasons for this requirement:\nhttp://redmine.yorba.org/issues/3716 To install Shotwell on Lucid and Maverick do the following:\nsudo apt-add-repository ppa:flexiondotorg/shotwell sudo apt-add-repository ppa:gstreamer-developers/ppa sudo apt-get update sudo apt-get dist-upgrade sudo apt-get install shotwell Enjoy!\n","permalink":"https://wimpysworld.com/posts/shotwell-0.11-ppa-available-for-ubuntu-lucid-and-maverick/","tags":["Ubuntu","Shotwell","GNOME","PPA"],"title":"Shotwell 0.11 PPA available for Ubuntu Lucid and Maverick"},{"categories":["Linux","Open Source","Development"],"contents":"Like many others I wanted Shotwell for Lucid so I\u0026rsquo;ve created a PPA for it.\n\u0026lt;https://launchpad.net/~flexiondotorg/+archive/shotwell. My PPA contains Shotwell 0.8.1 built for Ubuntu Lucid 10.04 LTS. I created the PPA because I run Lucid at home and wanted the new version of Shotwell. Sadly, Yorba aren\u0026rsquo;t going to provide a Lucid build of Shotwell 0.8.1 due to the reasons discussed in the following ticket:\nhttp://trac.yorba.org/ticket/3015 As mentioned in the ticket above, there are versions of Shotwell 0.8.1 available for Lucid in other PPAs. However, those PPAs contain hundreds of packages. If you\u0026rsquo;re not that brave, like me, then hopefully my PPA provides what you need. I have built Shotwell 0.8.1 with minimal changes from the original Yorba source packages and not polluted my PPA with any unnecessary packages NOTE! My PPA has dependencies that are satisfied by the Yorba PPA, so you must also enable the Yorba PPA too.\nhttps://launchpad.net/~yorba/+archive/ppa To install Shotwell 0.8.1 on Lucid do the following:\nsudo apt-add-repository ppa:yorba/ppa sudo apt-add-repository ppa:flexiondotorg/shotwell sudo apt-get update sudo apt-get install shotwell ","permalink":"https://wimpysworld.com/posts/shotwell-0.8.1-ppa-available-for-ubuntu-lucid/","tags":["Ubuntu","GNOME","Shotwell","PPA"],"title":"Shotwell 0.8.1 PPA available for Ubuntu Lucid"},{"categories":["Linux","Open Source","Development"],"contents":"I\u0026rsquo;m working a script to automatically backport Debian packages to Ubuntu. I needed a way to get a list of currently supported/active Ubuntu releases by codename or version. Here is how I do it.\nGet a list of Ubuntu codenames wget -q http://cdimage.ubuntu.com/releases/ -O - | sed -e :a -e \u0026#39;s/\u0026lt;[^\u0026gt;]*\u0026gt;//g;/\u0026lt;/N;//ba\u0026#39; | grep \u0026#39;^[[:space:]][a-z]\u0026#39; | sed \u0026#39;s/\\///g\u0026#39; Get a list of Ubuntu versions wget -q http://cdimage.ubuntu.com/releases/ -O - | sed -e :a -e \u0026#39;s/\u0026lt;[^\u0026gt;]*\u0026gt;//g;/\u0026lt;/N;//ba\u0026#39; | grep \u0026#39;^[[:space:]][1-9]\u0026#39; | sed \u0026#39;s/\\///g\u0026#39; ","permalink":"https://wimpysworld.com/posts/bash-script-to-retrieve-ubuntu-codenames-and-versions/","tags":["Ubuntu","Bash","wget"],"title":"Bash script to retrieve Ubuntu codenames and versions"},{"categories":["Linux","Open Source","Development"],"contents":"I\u0026rsquo;ve finally found a photo organiser for Linux I can live with, Shotwell. Shotwell is a photo organiser for GNOME that I\u0026rsquo;ve been testing for a few months now but the recent 0.5 release which added tagging and printing, it means Shotwell is finally ready replace F-Spot on my workstation.\nShotwell is intuitive, well documented, extremely easy to use and reliable. It\u0026rsquo;s easy to dismiss Shotwell as an over simplified photo manager. But once you start using it, you\u0026rsquo;ll quickly appreciate its clean interface and easy-to-use tools. Don\u0026rsquo;t just take my word for it either, Shotwell is now the default photo manager in Fedora 13 alpha. Here is a quick run down of the features.\nImport photos from folders or from any digital camera supported by gPhoto. Shotwell automatically groups photos taken at the same time. You can also use tags to organize your photo collection. You can rotate, crop, reduce red-eye, and adjust the exposure, saturation, tint, and temperature of each photo. Publish photos to Facebook, Flickr and Picasa Web Albums. Shotwell provides a non-destructive way to tweak your photos. Instead of modifying the original photos, Shotwell stores all edits in a database and applies them on-the-fly as necessary. This means that you can easily undo all edits. Shotwell comes equipped with all the usual photo enhancing tools and slideshow. You can download a source tarball from the Shotwell home page at http://www.yorba.org/shotwell/ or grab a binary for Ubuntu Karmic or Lucid via Yorba\u0026rsquo;s Launchpad PPA.\nhttps://launchpad.net/~yorba/+archive/ppa ","permalink":"https://wimpysworld.com/posts/goodbye-f-spot-hello-shotwell/","tags":["GNOME","Shotwell","F-Spot","Ubuntu","Photo Organiser"],"title":"Goodbye F-Spot. Hello Shotwell"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"After tinkering with Ext4 I did some research and tested other file systems on my new disk arrays. I\u0026rsquo;ve concluded that XFS, once tuned, is the best file system for my needs and it could well be the best file system for your needs too.\nThe remainder of this page explains how I arrived at that decision and how I tune XFS to get optimal, yet safe, performance that can rival Ext4 and JFS.\nBenchmarks Here are some benchmarks.\nhttp://izanbardprince.wordpress.com/2009/03/28/comparing-boot-performance-of-ext3-ext4-and-xfs-on-ubuntu-jaunty/ http://linuxgazette.net/122/piszcz.html Reiser4 Benchmarked On Linux 3.5 Against EXT4, Btrfs, XFS, ReiserFS Why I chose XFS I have not chosen XFS for performance alone, indeed some benchmarks show that XFS it outperformed for some file operations.\nMy workstation at home has two 6TB disk arrays and a 1TB root file system. The disk arrays contain photo, music and video libraries which are streamed via UPnP/DLNA and DAAP. The video files can be 2GB to 30GB in size. I also do a good deal of HD video encoding, processing and editing. My root partition contains many virtual machine images of which several are running at any given time.\nMy work laptop has a 250GB root file system and also contains many virtual machine images of which one is usually running.\nXFS is designed with large file systems and large file handling in mind. It seems a sensible choice for those reasons alone, but I also liked the following features:\nXFS has on-line defragmentation tools, while (at the original time of writing in early 2010) Ext3/4 and JFS do not. XFS dramatically reduces start-up time by avoiding fsck delay. Ext3/4 can be very slow to fsck large volumes. XFS has very fast (a few seconds or less) file system creation. JFS is faster than XFS but Ext4 takes many, many minutes. XFS formatted disk capacity is greater than Ext3/4 even after removing the reserved blocks from the Ext3/4 file system. JFS formatted capacity is similar to XFS. On that last point, XFS gains 400GB over Ext4 on a 6TB array but when the Ext4 reserved blocks are removed XFS gains 100GB over Ext4.\nTuning XFS Most of the performance tuning information I found (at the original time of writing in early 2010) is out of date and doesn\u0026rsquo;t reflect the XFS defaults in modern Linux kernels.\nThat said, the information on this page is quite old and I no longer feel the need to tweak XFS like I once did.\nCreating XFS XFS 3.1.0 and Kernel 2.6.32 or newer Ubuntu Lucid 10.04 comes with XFS 3.1.0. The defaults used when creating a XFS file system using Ubuntu 10.04 are optimal and do not require any tweaking.\nXFS 3.0.2 and Kernel 2.6.31 or older Ubuntu Karmic 9.10 comes with XFS 3.0.2. If you are running an earlier Ubuntu release and want to use a tuned XFS root file system you can\u0026rsquo;t simply use the graphical partitioning tool from the Ubuntu LiveCD installer. However, it is very easy manually create the tuned XFS file systems. Simply boot the Ubuntu Live CD, then start a new shell Application -\u0026gt; Accessories -\u0026gt; Terminal.\nNow run the following as root.\nmkfs.xfs -l lazy-count=1 -L VolumeName \u0026lt;dev\u0026gt; lasy-count=1 is a default since XFS 3.1.0 but was recommended by the XFS developers before that. lazy-count is a mkfs option because it changes the on-disk format slightly, and older kernels do not understand this new format. Hence mkfs sets a superblock feature bit to prevent the file system from being mounted on kernels that don\u0026rsquo;t understand the slightly different disk format. So you must specify lazy-count=0 if you want to disable this feature for older kernels which don\u0026rsquo;t support it.\nhttp://oss.sgi.com/archives/xfs/2007-12/msg00536.html Forcing a tuned XFS creation If you are not sure what XFS version you are running, and therefore what the defaults might be on your system, you can fully tune XFS using the following.\nFor \u0026lt; 1TB XFS file system mkfs.xfs -l lazy-count=1,version=2,size=128m -i attr=2 -d agcount=4 -L VolumeName \u0026lt;dev\u0026gt; For \u0026gt; 1TB XFS filesystem mkfs.xfs -l lazy-count=1,version=2,size=128m -i attr=2 -d agcount=16 -L VolumeName \u0026lt;dev\u0026gt; Once you have created all your tuned XFS file systems start the Ubuntu installer from the Live CD. When the disk partitioning section comes round choose: Specify Partitions Manually\nNow Change each XFS file system telling the partitioner where to mount each XFS file system. But ensure that you do not tick Format the Partition:, thereby preserving your tuned XFS file systems.\nWhen you see this message, just click Continue.\nThe file system on /dev/sda1 assigned to /boot has not been marked for formatting. Directories containing system files (/etc, /lib, /usr, /var, \u0026hellip;) that already exist under any defined mountpoint will be deleted during the install.\nPlease ensure that you have backed up any critical data before installing.\nMounting XFS Further performance optimisations can be gained but specifying some additional mount options for your XFS file systems.\nTo manually mount a XFS file system with, optimal mount options, use the following:\nmount -t xfs -o noatime,osyncisosync,logbsize=256k,logbufs=8 \u0026lt;dev\u0026gt; \u0026lt;mtpt\u0026gt; The /etc/fstab entries I use look something like this.\nUUID=xxxxxxxxxxx...x \u0026lt;mtpt\u0026gt; xfs noatime,osyncisosync,logbsize=256k,logbufs=8 0 2 The logsbsize' and logbufsoptions address the often sited limitation of XFS when handling lots of small files and large number of file deletions. The above assumes you don't requireatime. Not using atime` provides a significant performance benefit.\natime, relatime and noatime Every time a file is accessed (read or write) the default for most file systems is to append the metadata associated with that file with an updated access time. Thus, even read operations incur an overhead associated with a write to the file system. This can lead to a significant degradation in performance in some usage scenarios. Appending noatime to the fstab line for any file system stops this action from happening.\nOne may also specify a relatime option which updates the atime if the previous atime is older than the mtime or ctime. In terms of performance, this will not be as fast as the noatime mount option, but is useful if using applications that need to know when files were last read (like mutt).\nAs access time is of little importance in most scenarios, this alteration has been widely touted as a fast and easy way to get a performance boost. Even Linus Torvalds seems to be a proponent of this optimization\nhttp://kerneltrap.org/node/14148 Access time is not the same as the last-modified time. Disabling access time will still enable you to see when files were last modified by a write operation.\nasync and nobarrier If you really want to go for all out performance you can also provide async and nobarrier mount options. But you really need to understand and accept the potential issues with using these options.\nRead the following to understand what write barriers are and if you are prepared to disable them to gain performance.\nhttp://lwn.net/Articles/283161/ XFS userspace tools XFS is available as a kernel module in Ubuntu and also available from the Live CDs. Once Ubuntu is installed you can install the XFS userspace tools as follows.\nsudo apt-get install xfsdump xfsprogs De-fragmenting XFS There are two utilities that XFS has to manage this fragmentation.\nxfs_db XFS Debug Information. Used to examine an XFS file system for problems or gather information about the XFS file system. xfs_fsr File System Organiser. Improves the organisation of mounted file systems. The reorganisation algorithm operates on one file at a time, compacting or otherwise improving the layout of the file extents (contiguous blocks of file data). Defragment a file system To find the health of a XFS file system use the xfs_db command to gather some information. In the example below /dev/sda1 is mounted as /boot and /dev/sda3 is mounted as /root.\nsudo xfs_db -c frag -r /dev/sda1 actual 162, ideal 162, fragmentation factor 0.00% sudo xfs_db -c frag -r /dev/sda3 actual 2288833, ideal 254504, fragmentation factor 88.88% The closer the fragmentation factor is to 0% the better. Unsurprisingly /boot is not fragmented. However /root is very fragmented.\nDefragmenting XFS file systems can be done on a live running system, but it is a good idea to schedule this for a time where the partition will be used less.\nThe file system reorganizer for XFS is xfs_fsr. Typically, I instruct xfs_fsr to reorganise /dev/sda3 with a timeout (-t) of 6hrs (60 * 60 * 6 = 21600) which is specified in seconds. But for the purposes of this example I used a timeout of 15 mins.\nsudo xfs_fsr -t 300 /dev/sda3 -v The output will look something like this.\n/ start inode=0 ino=145565 extents before:2 after:1 DONE ino=145565 ino=145662 extents before:2 after:1 DONE ino=145662 ino=600148 extents before:2 after:1 DONE ino=600148 ino=1127295 extents before:82794 after:1 DONE ino=1127295 ino=1127243 extents before:2 after:1 DONE ino=1127243 ino=1382852 extents before:50869 after:1 DONE ino=1382852 ino=1422636 When the defrag is finished check how well the file system reorganising was.\nsudo xfs_db -c frag -r /dev/sda3 actual 2155648, ideal 254512, fragmentation factor 88.19% As you can see defragmenting for 15 mins doesn\u0026rsquo;t improve things greatly, which is why xfs_fsr needs to be run for several hours or more.\nManually defragmenting the file system is simple enough, but a better solution would be to schedule a cron job to run periodically.\nDefragment a file It is also possible to de-fragment a single file. To determine if a file is in need of defragmenting run the following\u0026hellip;\nxfs_bmap -v /srv/A320/PGQAR.DAT | wc -l This will output a number which showing the number of extents the file is using.\n95280 This number should be close to 1. So in the example above, I have a very fragmented file.\nsudo xfs_fsr -v /srv/A320/PGQAR.DAT This will output something like the following.\n/srv/A320/PGQAR.DAT extents before:95278 after:1 DONE /srv/A320/PGQAR.DAT The file is now defragmented. I use the method above to target defragmentation where I know files reside that are most likely to be fragmented, rather than defragmenting the whole file system.\nReferences XFS References http://www.xfs.org/index.php/Main_Page http://en.wikipedia.org/wiki/XFS http://oss.sgi.com/projects/xfs/papers/hellwig.pdf http://www.ibm.com/developerworks/linux/library/l-fs9.html http://www.ibm.com/developerworks/linux/library/l-fs10.html http://www.mythtv.org/wiki/XFS_Filesystem http://www.thushanfernando.com/index.php/2009/01/25/maintaining-your-xfs-with-xfs-fsr/ http://www.linux.com/archive/feature/141404 Performance Tuning XFS References http://everything2.com/index.pl?node_id=1479435 http://www.opensubscriber.com/message/xfs@oss.sgi.com/8198329.html http://ondrejcertik.blogspot.com/2008/02/xfs-is-20x-slower-than-ext3-with.html http://archives.free.net.ph/message/20090825.155236.abd842ef.en.html http://www.mythtv.org/wiki/Optimizing_Performance#XFS-Specific_Tips ","permalink":"https://wimpysworld.com/posts/give-xfs-a-chance-dont-believe-the-fud/","tags":["XFS","Ext3","Ext4","JFS"],"title":"Give XFS a chance. Don't believe the FUD."},{"categories":["Linux","Open Source","Self Hosting"],"contents":"The Ext4 file system, like Ext3, reserves 5% of the blocks on the file system for the root user. The reserved blocks are there for root\u0026rsquo;s use as a safe guard if the filesystem gets full, it provides some wiggle room to enable the really important programs to still function. But in some cases there\u0026rsquo;s not much point in having space reserved for root. I\u0026rsquo;ve recently upgrade my workstation with a 6TB internal RAID 0 array for data storage (music, videos, photos, etc) and an external 6TB RAID 0 array as a backup. My OS boot from a 1TB drive. For my 6TB arrays I want the maximum available storage and was interested to see what effect removing the reserved space would have. So, this is what I did. First I made the Ext4 file system, mounted it and queried how much space was available.\nsudo mkfs.ext4 /dev/sdh1 sudo mount /dev/sdh1 /mnt df -h Looks like I have 5.1TB of available space.\n/dev/sdh1¬†5.4T¬†186M¬†5.1T¬†1% /mnt Then I unmounted the file system, removed the reserved blocks, checked the consistency of the file system, mounted it and queried how much space was available.\nsudo umount /mnt sudo tune2fs -m 0 /dev/sdh1 sudo e2fsck /dev/sdh1 df -h Looks like I have 5.4TB available now, a saving of 300GB.\n/dev/sdh1¬†5.4T¬†186M¬†5.4T¬†1% /mnt Now, I could have simply created the files system without the reserved blocks in the first place, but I was interested to see the comparison.\nsudo mkfs.ext4 -m 0 /dev/sdh1 Before you start removing the reserved blocks from your ext3/ext4 file systems do a bit a research first.\nDisk capacity, free space, and Ext3 reserved blocks Ext3 Filesystem Tips ","permalink":"https://wimpysworld.com/posts/recovering-reserved-space-from-ext4/","tags":["Ext3","Ext4","Reserved space"],"title":"Recovering reserved space from ext4"},{"categories":["Linux","Computer Hardware","Self Hosting"],"contents":"*** UPDATE: The StarTech S354UER completely died after less than one year. Not recommended! ***\nI\u0026rsquo;ve ripped my entire CD collection to MP3 and I\u0026rsquo;m in the process of ripping my entire DVD, Blu-Ray and HD-DVD collection to MPEG-2 TS files so that I can stream everything to my PS3 using MiniDLNA. I currently have this data stored on an internal 2TB volume and backed up to an external 2TB volume. I currently have just 360GB remaining capacity and I\u0026rsquo;ve only imported half my DVD collection and one Blu-Ray. I need more storage.\nI wanted to keep the same backup method, large internal volume backed up to a large external volume of the same size. I opted for Samsung Spinpoint F2 EcoGreen (HD154UI) drives because they are relatively inexpensive, low power (therefore lower heat) and quiet.\nSamsung Spinpoint F2 EcoGreen (HD154UI) Samsung Spinpoint F2 EcoGreen (HD154UI) Review I decided to get 4x 1.5TB drives for the internal volume and stripe them to give 6TB of storage and I went looking for an external box in which I could install 4x 1.5TB drives and also stripe or span them. That meant a multi disk external enclosure, with some kind of RAID, supported by Linux and that isn\u0026rsquo;t too expensive. A tall order as it turns out.\nAfter lots of research I finally found the StarTech S354UER which on paper appears to do what I required and a good deal more.\nCompatible with Windows, Mac, and Linux operating systems Fan control button to enable manual control of the fan and switch between the three fan speeds Internal three speed 80mm fan with automatic or manual controls Multiple LED indicators to provide RAID information, hard drive activity, HDD Status, RAID rebuild status, fan settings, and interface in use No software required Package includes 1x USB, 1x eSATA, 1x FireWire 400, 1x FireWrie 800 cable, Power adapter and cord, and the manual Plug-and-Play and Hot swap supported with USB 2.0, eSATA, and FireWire Push button raid configuration eliminated the need to disassemble the enclosure to upgrade your raid configurations Removable front cover for easy access to hard drive Rugged aluminum chassis Supported File Systems:NTFS, FAT, FAT32, and ext3 Supports four 3.5in hard drives up-to 2.0 TB each in size Supports RAID 0, RAID 1, RAID 3, RAID 5, RAID 10 (RAID 1+0), and Spanning Normally, I will read reviews of different products and select something with a proven track record particularly when Linux support is required. I couldn\u0026rsquo;t find much in the way of reviews for the StarTech S354UER so I took a gamble and decided to buy one. Eeek!\nIn short it works and it is quiet. It is currently sitting no more than 50cm from me initialising a stripped array of 4x1.5Tb disks as Ext4. I can\u0026rsquo;t hear it but I have manually set the fan speed to low using the fan control buttons on the front on the chassis.\nThe build quality is not great, but not awful either, but once the drives are installed and clamped in place they are very secure. It is impossible to tell if you\u0026rsquo;ve pushed the power button you have to wait and see if the device powers up/down to be sure. The fan speed controls work, but are inverted from what is documented in manual. Fan1 is documented as LOW in the manual but is actually HIGH.\nSetting up the device was not quiet plug and play either but the issues I ran into may not be entirely the fault of the StarTech S354UER. My plan was to connect the enclosure via Firewire and as yet I\u0026rsquo;ve not been able to get the enclosure to be recognised via Firewire using Ubuntu Jaunty 9.04. However, I am a Firewire newbie so maybe more research required. I don\u0026rsquo;t have eSATA (yet) so I have the device connected via USB 2.0. Which does work.\nOne of my new hard disks turned out to be DOA. It took me a while to figure out what was wrong here. The StarTech drive failure light on the front of the chassis was illuminated, but I didn\u0026rsquo;t know how to tell which drive had actually failed. After some trial and error I found that there are four internal LEDs, one for each disk. Starting the StarTech with the chassis door open you can see the internal LEDs blinking as each disk is spun up and tested. If the drive failure LED on the front of chassis is illuminated look at the internal LEDs, the drive LED which is off denotes the failed drive. This information is not in the user manual!\nI replaced the drive and was able to select my RAID level. Selecting the RAID level is done though a combination of DIP switches under a panel at the back of the unit and buttons on the front. It is a slightly fiddly process, but it does have the advantage that you can\u0026rsquo;t accidentally change your RAID levels and re-initialise the array.\nIn order to create a partition greater than 2TB you have to use GPT. I\u0026rsquo;d not encountered GPT before, but I found everything I needed to know on the page below.\nMake the most of large drives with GPT and Linux I used gparted to create my partition and format with Ext4 with the enclosure connected via USB 2.0. The whole process took ~1 hour. As you will see from the link the quoted price makes this enclosure pretty expensive. Search around though, because I got mine of 50% less than the price quoted on the StarTech.com website. You do get a healthy selection of RAID levels, all the cables, screws, screwdriver and drive handles you require.\nWould I recommend the StarTech S354UER? Time will tell, but it does work with Linux via USB 2.0 and I will continue investigate FireWire and I may add eSATA in the future to see what the performance benefits are. But for what I bought it for, secondary storage for backups, it is a pretty cheap way to add a multi terrabyte array to your system.\n","permalink":"https://wimpysworld.com/posts/startech-s354uer-review/","tags":["StarTech S354UER","RAID","Ext4"],"title":"StarTech S354UER Review"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"I\u0026rsquo;ve been using Mediatomb for nearly two years now but decided to give MiniDLNA a whirl since it is a fully fledged DLNA server whereas Mediatomb is UPnP only. I\u0026rsquo;m currently running both Mediatomb SVN and MiniDLNA CVS. So, how does MiniDLNA compare to Mediatomb?\nMiniDLNA is easier to compile, configure, uses less RAM and has less software dependencies than Mediatomb. MiniDLNA doesn\u0026rsquo;t currently support music play lists or Last.fm scrobbling. Mediatomb supports .m3u and .pls playlists but requires a 3rd party patch to add Last.fm scrobbling. MiniDLNA doesn\u0026rsquo;t support dynamic video thumbnail creation, which would be nice to have but is not essential, cover images are supported. Mediatomb supports video thumbnails via ffmpegthumbnailer. MiniDLNA doesn\u0026rsquo;t currently have any transcoding support. This is of little consequence for me since I import video content into my library in a format natively supported by the PS3, either MP3, MPEG-2 TS or MPEG-4. Mediatomb does support transcoding but it is somewhat fiddly to setup and you can\u0026rsquo;t pause transcoded content. MiniDLNA works \u0026ldquo;out of the box\u0026rdquo; with the PS3 (and other DLNA clients) while Mediatomb requires some tweaking. Mediatomb\u0026rsquo;s default video import script doesn\u0026rsquo;t suit how I organise my video library, but MiniDLNA suits my video library perfectly. So, as of today I am running both Mediatomb and MiniDLNA. Mediatomb is exclusively handling audio since playlist and Last.fm support are essential for me. MiniDLNA is now handling video exclusively. I\u0026rsquo;m very happy with the results but should MiniDLNA add .m3u/.pls play lists and Last.fm support I will switch everything to MiniDLNA.\n2 years later\u0026hellip; Since writing this post MiniDLNA added support for playlists. It still doesn\u0026rsquo;t support Last.fm scrobbling though. Despite that I switched to MiniDLNA and it has been streaming audio and video around the house for that last couple of years.\n","permalink":"https://wimpysworld.com/posts/mediatomb-vs-minidlna/","tags":["DLNA","UPnP","Mediatomb","MiniDLNA","PlayStation 3"],"title":"Mediatomb vs. MiniDLNA"},{"categories":["Linux","Entertainment"],"contents":"I\u0026rsquo;ve no idea when Amazon.co.uk launched their MP3 store and I\u0026rsquo;ve no idea when they released their Linux client for downloading the MP3s you purchased. I don\u0026rsquo;t care, I just want to say I\u0026rsquo;m really impressed Amazon have considered us Linux users. Well done Amazon!\nNot only that but the MP3s are DRM free, encoded using variable bit rates aiming at an average of 256 kilobits per second (kbps), album cover art is included with each song and the tracks are typically cheaper than iTunes. Well done again.\nDoubtless some would want an Open Source client and unencumbered formats such as Ogg and FLAC, but I\u0026rsquo;m pretty happy with what Amazon have on offer so long as it works. Which it does.\nHowever, the Linux MP3 downloader client is 32-bit only. Not so good, but it can be successfully installed in 64-bit Ubuntu. Here\u0026rsquo;s how I did in on Ubuntu Jaunty 9.04 64-bit.\nwget -c http://frozenfox.freehostia.com/cappy/getlibs-all.deb dpkg -i getlibs-all.deb¬†wget \u0026#34;http://www.amazon.co.uk/gp/dmusic/help/amd-installer-redirect.html/ref=dm_amd_linux_ubuntu?ie=UTF8\u0026amp;forceos=LINUX\u0026amp;callingPage=%2Fgp%2Fdmusic%2Fhelp%2Famd.html\u0026amp;linux_Ubuntu.x=1\u0026#34; -O amazonmp3.deb dpkg -i --force-architecture amazonmp3.deb getlibs /usr/bin/amazonmp3 ","permalink":"https://wimpysworld.com/posts/amazon-loves-linux-music-lovers/","tags":["Amazon","MP3","Ubuntu"],"title":"Amazon Loves Linux Music Lovers"},{"categories":["Linux","Open Source","Home Cinema","Self Hosting","Gadgets"],"contents":"A while back I released a script that rips a DVD to MPEG-2 PS allowing the user to select one audio stream and one subtitle stream. Optionally the video can be requantised, using M2VRequantiser and an ISO image created. If creating an ISO image the chapters are also preserved from the original DVD. You can see the original post below.\nDVD to MPEG-2 PS Ripper for Linux I\u0026rsquo;ve just released an update to that original script which fixes subtitles in the original MPEG-2 PS mode but now adds the capability to rip MPEG-2 TS. The video stream can still be shrunk and in MPEG-2 PS mode the video is still requantised but in MPEG-2 TS mode the video is re-encoded as H.264.\nRequantising is faster but can introduce artifacting. H.264 encoding is slower, but produces very good quality. I am currently re-importing my entire DVD collection, using this script, to my DLNA server using MPEG-2 TS and re-encoding the video to H.264. This gives me high quality rips at relatively small size (~3Gb) whilst preserving Dolby Digital 5.1 audio. Perfect for playback via DLNA on the PS3. Some things to be aware of:\nSubtitles are only supported in MPEG-2 PS mode. MPEG-2 PS files created by this script are DVD compliant. ISO files created by this script will preserve the chapters from the original DVD. The PS3 can only play DTS audio in MPEG-2 PS streams when they have been authored to DVD. The PS3 can only play subtitles in MPEG-2 PS streams when they have been authored to DVD. The PS3 can\u0026rsquo;t play DTS audio in MPEG-2 TS streams therefore this script will transcode DTS to AC3 when in MPEG-2 TS mode. To download the script and find out how to make full use of it visit the release page below.\nDVD-to-MPG ","permalink":"https://wimpysworld.com/posts/dvd-to-mpeg2-ts-ripper-for-linux/","tags":["MPEG2-PS","MPEG2-TS","DVD","H.264","Ripper","M2VRequantiser","Bash","PlayStation 3","C","DLNA"],"title":"DVD to MPEG2-TS Ripper for Linux"},{"categories":["Linux","Open Source","Development"],"contents":"We use hex editors daily at work, we are regularly cutting up data from flight data recorders for analysis or recovery. So when I find a new hex editor for Linux I usually give it a try. I happened across a blog listing five GUI hex editors for Ubuntu today. Find out more below.\nFive gui hex editors for ubuntu ","permalink":"https://wimpysworld.com/posts/linux-hex-editors/","tags":["Hex Editor","Ubuntu"],"title":"Linux Hex Editors"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"I created JetDirect compatible server on my NSLU2 running Ubuntu Jaunty 9.04 using p910nd, which is a small printer daemon that does not spool to disk but passes the job directly to the printer. It is particularly useful for disk less Linux workstations and embedded devices that have a printer hanging off them.\n","permalink":"https://wimpysworld.com/posts/creating-a-jetdirect-server-with-linux/","tags":["Ubuntu","NSLU2","JetDirect","Printing"],"title":"Creating a JetDirect Server with Linux"},{"categories":["Linux","Open Source","Home Cinema","Self Hosting","Gadgets"],"contents":"PlayStation 3 firmware 3.00 added a new feature I was very excited about, multi-av output. Today I finally got round to re-wiring the home cinema system to make use of this new feature. I now have the PS3 streaming music from MediaTomb with my A/V receiver sending audio to Zone 1 via digital inter connects and also sending audio to Zone 2 via analog stereo interconnects.\nZone 1 is a 5.1 speaker setup and Zone 2 is a 2.0 all weather wireless speaker system which are often in the kitchen but also moved outside for parties. If Sony could just add Skype to the PS3 and allow the PSP Remote Play to output audio to both the PS3 and PSP (rather than just one of them) I would be very happy indeed.\n","permalink":"https://wimpysworld.com/posts/ps3-mediatomb-multi-zone-music-streaming/","tags":["Mediatomb","PlayStation 3","UPnP"],"title":"PS3, Mediatomb, Multi Zone Music streaming"},{"categories":["Linux","Open Source","Home Cinema","Self Hosting","Gadgets"],"contents":"UPDATE! I no longer use or maintain the script below. I suggest the vastly superior Sheet Maker for Linux.\nBack in April I released a script to create a MPEG video summarising a movie using data from IMDB, you can find the original post in the URL below to learn why I created such a script in the first place.\nIMDB Film Summary as a MPEG-2 video Today I\u0026rsquo;ve released v2.0 of that script, which is almost a complete re-write mostly thanks to Eric at yPass.net who contributed significantly. Thanks to Eric the script is much improved since version 1.0, here is a run down of what\u0026rsquo;s new.\nv2.0 2009, 19th September. Merged yet more contributions from Eric, http://www.ypass.net. Thanks Eric! Added usage instructions. Added categorisation by Certificate. Added dynamic computation of video bitrate. Added silent audio generation. Added a shell script to reprocess an entire film store. Re-added MPEG-2 video encoding. Improved video encoding speed by removing pre-processing with jpeg2yuv. Fixed spiffy animations when cover art is not available. Fixed spiffy animations on platforms that may have incomplete GD. Modified filename input so that an input filename is optional rather than mandatory. v1.2 2009, 17th July. Merged extensive contributions from Eric, http://www.ypass.net. Thanks Eric! Updated the README to reflect Eric\u0026rsquo;s changes. MPEG-4 video encoding replaced MPEG-2 video encoding. Never released to the public. To download the script and find out how to make full use of it visit the release page below.\nIMDB-to-MPEG As it stands the IMDB-to-MPEG script does what I require, so I will maintain it in it\u0026rsquo;s current form. However, Eric has been working on a new direction by adding support for NetFlix, creating a GUI with php-gtk and some other cool stuff. While Eric has shared the details with me, I simply don\u0026rsquo;t have the time to add all that good stuff to IMDB-to-MPEG, so if you like the sound of what Eric has been up to hop over to his site to find out more.\nNetflix Has a Developer API ","permalink":"https://wimpysworld.com/posts/imdb-film-summary-as-a-mpeg-2-video-part-2/","tags":["IMDB","MPEG-2","PHP"],"title":"IMDB Film Summary as a MPEG-2 video, Part 2"},{"categories":["Linux","Open Source","Home Cinema","Self Hosting","Gadgets"],"contents":"The PlayStation 3 can\u0026rsquo;t play MKV files. Therefore I\u0026rsquo;ve written a script that creates a PlayStation 3 or Xbox 360 compatible MPEG-4 from Matroska providing the video is H.264 and audio is AC3 or DTS.\nXbox 360 compatibility requires that audio is forcibly downmixed to stereo with --stereo. AAC 5.1 audio will have the correct channel assignments when transcoding from AC3 5.1 and DTS 5.1. If neroAacEnc is installed then it is used in preference to faac for encoding the AAC audio, as it produces better quality output. neroAacEnc is optional.\nThe script does as little re-encoding as possible, only the audio and subtitles are re-encoded or converted. The script can detect profile 5.1 H.264 and patch it to 4.1 in under a second. Any subtitles in the Matroska are preserved. If mp4creator is used the subtitles are extracted stored in a seperate file. If MP4Box is used (default) the subtitles are converted to GPAC Timed Text and muxed into the resulting MPEG-4. The PlayStation 3 can\u0026rsquo;t display these subtitles but some software players can.\nThe script can optionally split the Matroska if it is greater than 4GB to ensure PlayStation 3, Xbox 360 and FAT32 compatibility. This script works on Ubuntu and should work on any other Linux/Unix flavour and possibly Mac OS X providing you have the required tools installed.\nMKV-to-MP4 ","permalink":"https://wimpysworld.com/posts/mkv-to-mpeg-4-conversion-script/","tags":["Matroska","H.264","Bash","AAC 5.1","AC3","DTS","PlayStation 3","Xbox 360","faac","neroAacEnc","MP4Box"],"title":"MKV to MPEG-4 conversion script"},{"categories":["Linux","Open Source","Home Cinema","Self Hosting","Gadgets"],"contents":"Work has been crazy. We\u0026rsquo;re moving house. Hence, not much time for geeky stuff recently. I\u0026rsquo;ve been putting this off for ages, I need to \u0026ldquo;normalise\u0026rdquo; the volume of my MP3 music music library. Not all CDs sound equally loud. Whilst different musical moods require that some tracks should sound louder than others, the loudness of a given CD has more to do with the year of issue or the whim of the producer than the intended emotional effect. This difference carries over when you rip the CD to MP3 and random play through my music collection requires constant manual volume adjustment. This has been bugging me for a while now, but when it started to bug my wife I knew it was time to find a solution. My main concerns with applying some sort of audio normalisation were\u0026hellip;.\nMy MP3s should not be irretrievably changed into something I end up hating. The method used should be free of the application used for music playback, given that I play my music on iPod Nano, iPod Shuffle, PSP, PS3, Linux desktops, TomTom 720T FM streaming and in car MP3 player. After some research mp3gain seems to be the tool for the job which provides an implementation of ReplayGain. However, as of today my entire CD collection is ripped, which is very large, so I needed a way to process my whole music collection in an automated fashion. I found some examples of how to script this, but there are caveats with the solutions I found. Therefore I have created my own script, MP3Gainer, to apply ReplayGain using mp3gain which overcomes these common limitations. MP3Gainer recursively applies ReplayGain to a MP3 music collection of any size and directory depth. ReplayGain can be applied in \u0026rsquo;track\u0026rsquo; or \u0026lsquo;album\u0026rsquo; mode and if ReplayGain has previously been applied it can also be undone. It is important to understand that MP3Gainer \u0026lsquo;album\u0026rsquo; mode really is per album, which is what you want. Trust me! This script works on Ubuntu, should work on any other Linux/Unix flavour and possibly Mac OS X providing you have the required tools installed.\nMP3Gainer ","permalink":"https://wimpysworld.com/posts/mp3gainer-apply-replaygain-to-your-entire-music-library/","tags":["MP3","ReplayGain","Bash","Ubuntu"],"title":"MP3Gainer - Apply ReplayGain to your entire music library"},{"categories":["Linux","Open Source","Home Cinema","Gadgets","Entertainment"],"contents":"Some of my mobile phones have been able to record video clips in MPEG-4 format. Sadly some of these clips don\u0026rsquo;t play on the PlayStation 3 and those that do stutter terribly. I use iplayer-dl to download content from BBC iPlayer. Sadly the files are in a Quicktime container and are not playable on the PlayStation 3.\nIn order to address both these issues I created a script which extracts the audio and video from an existing MPEG-4 or ISO Media Apple QuickTime container and repacks them in a new MPEG-4 container with optional splitting of the resulting MPEG-4 to maintain FAT32 compatibility. The new MPEG-4 files play just fine on my PlayStation 3. This script works on Ubuntu, should work on any other Linux/Unix flavour and possibly Mac OS X providing you have the required tools installed.\nMP4-Repacker ","permalink":"https://wimpysworld.com/posts/playstation-3-compatible-mpeg-4-container-repacker/","tags":["MPEG-4","iPlayer","PlayStation 3","Bash","BBC"],"title":"PlayStation 3 compatible MPEG-4 container repacker"},{"categories":["Linux","Open Source","Home Cinema","Gadgets"],"contents":"The PlayStation 3 can\u0026rsquo;t play MKV files. Therefore I\u0026rsquo;ve written a script that creates a PlayStation 3 compatible M2TS from a MKV, assuming video is H.264 and audio is AC3 or DTS with as little re-encoding as possible. Any subtitles in the MKV are preserved in the M2TS although the PlayStation 3 can\u0026rsquo;t display subtitles in M2TS containers. Optionally splits the M2TS, if it is greater than 4GB, to maintain FAT32 compatibility. Unlike other MKV to M2TS solutions, this script doesn\u0026rsquo;t create any intermediate files during the conversion.\nThe PlayStation 3 can\u0026rsquo;t play DTS audio streams in M2TS containers, therefore DTS audio is transcoded to AC3.\nThis script works on Ubuntu, should work on any other Linux/Unix flavour and possibly Mac OS X providing you have the required tools installed.\nMKV-to-M2TS ","permalink":"https://wimpysworld.com/posts/mkv-to-m2ts-conversion-script/","tags":["Matroska","M2TS","Bash","AC3","DTS","PlayStation 3"],"title":"MKV to M2TS conversion script"},{"categories":["Linux","Open Source","Home Cinema","Self Hosting","Gadgets"],"contents":"Every so often I find myself in looking through the ex-rental DVD \u0026ldquo;bargain bin\u0026rdquo;. Quite often I find something I consider a bargain. However, the experience of watching an ex-rental DVD is typically ruined by the various trailers and marketing guff at the start which you can\u0026rsquo;t skip. My wife hates that stuff, and I love my wife, so I routinely rip the main feature of newly acquired ex-rental DVD movies so we can avoid that crap.\nI run a Mediatomb DLNA server and I want to load it with all my DVDs. Ripping them helps reduce the amount of storage I require. MPEG2-PS files are compatible with my PlayStation 3 which is the client to my Mediatomb DLNA server. As a solution to the above I created a script, which can extract the main feature from a DVD video, allowing the user to select one audio stream and one subtitle stream. Optionally the video can be requantised, using M2VRequantiser, and an ISO image created. If creating an ISO image the chapters are also preserved from the original DVD. I\u0026rsquo;ve lobbed my code into GitHub.\nDVD-to-MPG ","permalink":"https://wimpysworld.com/posts/dvd-to-mpeg2-ps-ripper-for-linux/","tags":["MPEG2-PS","DVD","Ripper","M2VRequantiser","Bash","DLNA","PlayStation 3"],"title":"DVD to MPEG2-PS Ripper for Linux"},{"categories":["Linux","Open Source","Home Cinema","Development"],"contents":"I recently discovered that tcrequant (part of the transcode suite of tools) has been deprecated. Worst still I found that when I ran tcrequant on my 64-bit Linux workstation is was corrupting the video. See the links below for details.\ntranscode 1.1.0 Final Release [transcode-users] tcrequant status Therefore I decided to get the M2VRequantiser code from Metakine working on both 32-bit and 64-bit Linux as a replacement for tcrequant. M2VRequantiser accepts the raw MPEG2 video data (not VOB) from the standard input and writes the recompressed frames to the standard output. M2VRequantiser takes two arguments. The first one is a floating point value specifying the ratio of compression. The second is the size of the M2V, since the data is streamed to M2VRequantiser it cannot know the M2V size. The following command would recompress \u0026lsquo;original.m2v\u0026rsquo;, whose size is 1024000 bytes, by a factor of 1.25.\nM2VRequantiser 1.25 1024000 \u0026lt; original.m2v \u0026gt; requantised.m2v I\u0026rsquo;ve only tested on 32-bit and 64-bit Linux, specifically Ubuntu 8.10. It works for me but I\u0026rsquo;d be interested to get your feedback.\nM2VRequantiser ","permalink":"https://wimpysworld.com/posts/m2vrequantiser-for-32-bit-and-64-bit-linux/","tags":["M2VRequantiser","tcrequant","MPEG-2","C"],"title":"M2VRequantiser for 32-bit and 64-bit Linux"},{"categories":["Linux","Open Source","Home Cinema","Self Hosting","Gadgets"],"contents":"UPDATE! I no longer use or maintain the script below. I suggest the vastly superior Sheet Maker for Linux.\nIf you\u0026rsquo;ve read my blog before you\u0026rsquo;ll know I run Mediatomb DLNA server with my PlayStation 3 as the client, You\u0026rsquo;ll also know I am working towards importing my entire DVD collection into my Mediatomb server. However, my wife wants to know something about each film in the library without having to dig out the DVD case from storage. My solution is to include a MPEG-2 video displaying the film summary in the Mediatomb library for each DVD I have imported so it can be easily viewed from the PS3.\nMy script is called IMDB-to-MPEG and I\u0026rsquo;ve finally got round to uploading it.\nIMDB-to-MPEG The scripts takes one parameter as input, a film title. The plotline, year of release, genres, cast list and running time for that film are gathered from IMDB and formatted as text. Here is an example.\nThe Usual Suspects (1995) A boat has been destroyed, criminals are dead, and the key to this mystery lies with the only survivor and his twisted, convoluted story beginning with five career crooks in a seemingly random police lineup. (106 mins) Starring Stephen Baldwin as Michael McManus, Gabriel Byrne as Dean Keaton, Benicio Del Toro as Fred Fenster, Kevin Pollak as Todd Hockney, and Kevin Spacey as Roger \u0026#39;Verbal\u0026#39; Kint. Genres: Crime, Mystery, Thriller. Rated 8.7 out of 10 from 227,964 votes. The text is converted into an image and then encoded into a MPEG-2 video using the lowest possible bitrate/resolution that is acceptable to read when viewing on a 42\u0026quot; plasma from my sofa.\nDirectories for each matching genre are created and also one for the IMDB rating (rounded down). The MPEG-2 is stored in the \u0026lsquo;All\u0026rsquo; folder and then symlinked to the genres and rating for that film. I then copy my video into the appropriate directory in \u0026lsquo;All\u0026rsquo;. For example.\n. |-- All |¬†`-- The_Usual_Suspects |¬†`-- About_The_Usual_Suspects.mpg |-- Genres |¬†|-- Crime |¬†|¬†`-- The_Usual_Suspects -\u0026gt; ../../All/The_Usual_Suspects |¬†|-- Mystery |¬†|¬†`-- The_Usual_Suspects -\u0026gt; ../../All/The_Usual_Suspects |¬†`-- Thriller |¬†`-- The_Usual_Suspects -\u0026gt; ../../All/The_Usual_Suspects |-- Ratings `-- 8 `-- The_Usual_Suspects -\u0026gt; ../../All/The_Usual_Suspects This code was lashed up in a few hours, it ain\u0026rsquo;t pretty but it works for me on my Ubuntu systems, maybe it\u0026rsquo;ll work for you too.\n","permalink":"https://wimpysworld.com/posts/imdb-film-summary-as-a-mpeg-2-video/","tags":["IMDB","MPEG","PHP","PlayStation 3"],"title":"IMDB Film Summary as a MPEG-2 video"},{"categories":["Linux","Open Source","Home Cinema","Self Hosting","Gadgets","Development"],"contents":"It has been a while since I last posted, mainly due to not having Internet access at home for a month. Anyway, I\u0026rsquo;m online again and I have been tinkering with various projects the most recent of which is Matroska conversion (again).\nMatroska to MP4 For sometime I have been converting Martoska files to MPEG-4 with AAC 5.1 audio so I can stream them via Mediatomb to my PlayStation 3. The conversion process works well although there is some overhead in transcoding the audio and the AAC 5.1 audio is not as good quality as the original AC3 or DTS.\nIf you are interested I\u0026rsquo;ve put my code in GitHub, the script automates the whole process.\nMPV-to-MP4 Matroska to M2TS A little while back I read it was possible to convert those same Matroska file to M2TS files which, so long as the audio is AC3, so takes much less time to convert. As the PlayStation 3 can\u0026rsquo;t play DTS audio streams inside a M2TS container there is still a requirement to transcode DTS to AC3. That said the conversion to M2TS requires less file I/O than converting to MPEG-4 and is therefore it is generally a quicker conversion method, typically just 2 or 3 minutes on my workstation at home.\nPlus the audio quality of the AC3 or transcoded DTS is better than that of transcoded AAC 5.1. I\u0026rsquo;ve created my own script to fully automate the conversion process. The script has been tested on Ubuntu 8.10 64-bit but there is an outside chance it will work on Mac OS X if you can get the required tools installed. Again, you can find my script on GitHub.\nMPV-to-M2TS ","permalink":"https://wimpysworld.com/posts/converting-matroska-to-m2ts-for-ps3-and-mediatomb/","tags":["Matroska","MP4","M2TS","PlayStation 3","DLNA","UPnP","Bash"],"title":"Converting Matroska to M2TS for PS3 and Mediatomb"},{"categories":["Linux","Open Source","Home Cinema","Self Hosting","Gadgets"],"contents":"Mediatomb is an open source (GPL) UPnP MediaServer with a nice web user interface, it allows you to stream your digital media through your home network and listen to/watch it on a variety of UPnP compatible devices, such as the PlayStation in my case.\nMediatomb 0.12 is not yet released as final yet but it is certainly stable enough for general use, so I spent the last week migrating from Mediatomb 0.11 to Mediatomb 0.12.\nI\u0026rsquo;ve recently finished ripping my entire CD collection (344 CDs) to MP3 and I am currently ripping my DVD collection (85 done so far) to MP4 with AAC 5.1 audio. The \u0026lsquo;Music\u0026rsquo; and \u0026lsquo;Video\u0026rsquo; folders in our home directories are mounted via NFS. The Mediatomb server uses the same data sources so any playlists or new music/videos we might import are immediately reflected in Mediatomb.\nOur entire CD library is now available at the click of a button, automatically organised by genre, artist and date. We have also created some playlists in .m3u or .pls format.\nNew to Mediatomb 0.12 is the ability to scrobble your music to Last.fm, this a killer feature for me and why I chose to migrate to 0.12 before it goes final.\nI ripped the CDs using SoundJuicer, since I can configure it to use LAME presets. I then used the Music Brainz Picard Tagger to add additional tagging and embed cover art and then applied ReplayGain.\nFinally my wife and I use Banshee to manage the music library on our computers, including the creation of playlists and syncing to our iPods.\nI am using Handbrake to rip the DVDs to MP4. I\u0026rsquo;ve created a new PS3 compatible profile which is focused on quality, I\u0026rsquo;ll post details about that in the future. Mediatomb 0.12 has some experimental features to stream video content from .ISO images of DVDs. I\u0026rsquo;ve yet to play with that but it sounds very cool. I\u0026rsquo;ve also created a script which queries IMDB to categorise our film library by genre and create summary information about each film in the library. I\u0026rsquo;ll be posting more about that soon. I haven\u0026rsquo;t finalised how we will integrate Photo management with Mediatomb yet, but that is that final piece in the puzzle.\n","permalink":"https://wimpysworld.com/posts/mediatomb-0.12-streaming-audio-and-video-around-the-house/","tags":["Mediatomb","MP3","MP4","DLNA","UPnP"],"title":"Mediatomb 0.12 - Streaming audio and video around the house"},{"categories":["Development"],"contents":"Last November we switched to Python as the principal language for all new software development projects at work, ditching Microsoft Visual C++ and PHP in the process. Last Friday we released our first Python application to our customers for both Windows and Linux users.\nAlthough we make good use of Open Source software development tools and methodologies the application we have just written is propritary and the source can not be released publicly. We needed to compile, or freeze, the Python script in order to create a standalone executable. Tools that do this have been around for sometime, however our application makes use of Win32 Extensions for Python and WMI on Windows, DBUS/HAL on Linux, wxPython on both, and a number of other modules. This is quite a big ask for the Python script compilers and initially the only tool which could build this lot successfully was py2exe. Sadly that only solves part of the problem since it is a Windows only tool.\nThen we found bbfreeze, which supports both Windows and Linux with Mac OS X support being actively developed. bbfreeze has a simple build API and we were soon using it to build stand alone executables for both Windows and Linux. Everything is peachy, all we needed was as means to install our application.\nWe only need a tarball for Linux since we manage all kiosk installations, but our customer can install the Windows version. Enter InnoSetup. InnoSetup is a free installer for Windows programs and installer can even be created from the command line, perfect for integration with our Jenkins build servers.\n","permalink":"https://wimpysworld.com/posts/distributing-closed-source-python-applications/","tags":["Python","Freeze","Windows","py2exe","bbfreeze","InnoSetup"],"title":"Distributing closed source Python applications"},{"categories":["Open Source","Content Creation"],"contents":"I manage several websites at work and have therefore learned something about search engine optimisation (SEO). Our main site at work uses Wordpress as the content manager, which has good SEO features by default. Last week we launched a new website and I also refreshed the other sites, in so doing I found a great article discussing how to fully SEO your Wordpress site. It is a good read even if you don\u0026rsquo;t use Wordpress, but for those of you that do, it recommends a suite of plugins that do all the hard work for you.\nWordpress SEO - The definitive guide to high rankings for your Blog ","permalink":"https://wimpysworld.com/posts/wordpress-search-engine-optimisation/","tags":["Content Management","SEO","Wordpress"],"title":"Wordpress Search Engine Optimisation"},{"categories":["Linux","Open Source","Development"],"contents":"I have quickly forked WordTwit into WordDent. WordDent is a Wordpress plugin that utilizes the Twitter API to automatically push a published post to your Identi.ca account as a dent. It allows all your Identi.ca contacts to keep up to date with your blog postings. I\u0026rsquo;m still just testing that WordDent works correctly. I\u0026rsquo;ll find out if the nice people over at Brave New Code will agree to me releasing WordDent since I can\u0026rsquo;t fine any license details for WordTwit.\n","permalink":"https://wimpysworld.com/posts/hacking-wordtwit-into-worddent/","tags":["Content Management","Wordpress","identi.ca","PHP"],"title":"Hacking WordTwit into WordDent"},{"categories":["Linux","Open Source","Home Cinema","Entertainment","Gadgets"],"contents":"I am just about to clean up and convert another batch of programmes I have recorded from Freeview (DVB-T in the UK) so that I can add them to my DLNA Server. I thought I\u0026rsquo;d share the method I use on Ubuntu.\nBy clean up, I mean edit out any adverts and trim crap from the start and the end of the recordings. It just so happens that the result of this process is a DVD compliant MPEG-2 which is suitable for DVD authoring, or in my case, streaming around the house. This method of conversion should work for any DVB PVR which allows you to export recordings via USB and, of course, MythTV or similar.\nDVB Ripping I have a PlayTV add-on for the PlayStation 3 which enables me to record Freeview (DVB-T) broadcasts to the PS3 internal hard disk. I mostly use PlayTV to record films. To prevent the PlayStation 3 hard disk filling up with films I wanted to export, edit out any adverts and then serve the edited file from my DLNA server or author it to DVD.\nThis process does not re-encode the audio or video therefore it is fairly quick and the output is the same quality as the input.\nAlthough I am using a PlayStation 3 as PVR and MPEG-2 TS (Transport Stream) file can be converted to a MPEG-2 PS (Program Stream) file using this process.\nExport from PlayStation 3 PlayTV to Home Menu First we need to move the recording from the PlayTV Library to the PS3 Home Menu. Start PlayTV, open the Library, select the recording and choose the Move to Home Menu option.\nCopy from Home Menu to External USB Quit PlayTV Plug in an external (FAT32 formatted) USB drive to the PS3. Go to Video on the PS3 Home Menu and select the recording you moved there earlier. Select Copy from the Options screen and choose the external USB drive as the target. Clean MPEG-2 TS and convert to MPEG-2 PS Plug the USB drive into your Ubuntu workstation and copy the .m2ts file to your hard disk.\nYou will need to Project X to clean the MPEG-2 TS and convert it to MPEG-2 PS.\napt-get install project-x Edit out the adverts Start the Project X GUI and load your .m2ts file.\nFile -\u0026gt; Add and select your .m2ts file. Now use Project X to add cut points to edit out any adverts.\nDe-multiplex the audio and video When you have completed your edits you need to \u0026lsquo;demux\u0026rsquo; the .m2ts file into two streams, one holding the audio (.mp2) and one holding the video (.m2v).\nClick the Prepare \u0026gt;\u0026gt; button. From the Process Window select the Action type to M2P Click the start button and wait for the processing to finish. Clock the \u0026lsquo;\u0026lsquo;Process Windows\u0026rsquo;\u0026rsquo; and quit Project X. Re-multiplex the audio and video The reason for the de-mux and then re-musing it to ensure the timecodes are correct, other the video will not playback correctly.\nInstall MJPEG tools.\napt-get install mjpegtools Now we need to re-multiplex the audio and video to create a DVD compliant MPEG-2 PS file.\nmplex -f 8 -o muxed-%d.mpg audio.mp2 video.m2v The -f 8 option specifies a dvd-compliant stream that is compatible with dvdauthor. The -o option specifies the outfile, you can substitute muxed-%d.mpg with a more descriptive name if you like. %d is expanded to a number if mplex decides to split the output to several files, this usually happens when the recording contains commercials and is nothing to worry about.\nAuthor DVD The MPEG-2 PS file that has been created should be suitable for DVD authoring using DeVeDe. When adding MPEG-2 PS files created using the method above open the DeVeDe Advanced options and select This file is already a DVD/xCD-suitable MPEG-PS file in the Misc menu.\nReferences http://project-x.sourceforge.net/ http://ttcut.tritime.de/index.2.html http://gopchop.org/index.php http://gopchop.sourceforge.net/ http://www.rastersoft.com/programas/devede.html ","permalink":"https://wimpysworld.com/posts/converting-dvb-t-to-dvd-compliant-mpeg-2/","tags":["DVB-T","PVR","MPEG-2","Project-X","DVD","Freeview","PlayStation 3","PlayTV","MythTV"],"title":"Converting DVB-T to DVD Compliant MPEG-2"},{"categories":["Linux","Open Source","Gadgets","Tutorial"],"contents":"We use Zimbra at work for email, contacts, calendaring, etc. I have Zimbra syncing with Thunderbird and my phone, I love it.\nAt the weekend I was updating the music library on my iPod Nano (2nd Gen) and noticed I had hidden the Contact and Calendar menu entries. I decided to see if I could get my iPod Contacts and Calendar synced with Zimbra, it turned out to be very simple. In the examples below replace username and password with your Zimbra user credentials. Obviously use the URL to your Zimbra server and replace /media/IPOD with where your Linux distribution has mounted your iPod.\nwget https://username:password@your.zimbraserver.tld/zimbra/home/username/contacts.vcf -O /media/IPOD/Contacts/contacts.vcf wget https://username:password@your.zimbraserver.tld/home/username/Calendar -O /media/IPOD/Calendars/calendar.ics wget https://username:password@your.zimbraserver.tld/home/username/Tasks -O /media/IPOD/Calendars/tasks.ics ","permalink":"https://wimpysworld.com/posts/sync-zimbra-contacts-calendar-and-tasks-to-your-ipod/","tags":["Zimbra","iPod","Linux"],"title":"Sync Zimbra Contacts, Calendar and Tasks to your iPod"},{"categories":["Linux","Open Source"],"contents":"Last week I switched from VMware to VirtualBox at home. Why? Well, hack value mostly and I also wanted to learn more about VirtualBox having never used it before.\nBottom line, for home use it suits me very nicely and is far easier to get installed and running when compared to VMware Server which almost always required patching. The VirtualBox and Guest Additions (think VMWare Tools) installers both worked without a hitch. I even migrated my existing VMware Linux guests to VirtualBox, again everything went smoothly and my existing .vmdk disks worked just fine.\n","permalink":"https://wimpysworld.com/posts/vmware-to-virtualbox-migration/","tags":["VirtualBox","VMware","Virtualisation"],"title":"VMWare to VirtualBox Migration"},{"categories":["Content Creation"],"contents":"I finally got around to verifying my websites with the Google, Yahoo! and MSN Live search engines. I\u0026rsquo;ve also setup sitemaps for my websites too. I\u0026rsquo;ve done this for the websites at work but couldn\u0026rsquo;t be arsed to do it for my own sites until today.\nTo find out why you want sitemap enable your sites read the Sitemap page at Wikipedia. In order to register your sitemaps with the major search engines you\u0026rsquo;ll need to setup accounts for Google Webmaster Tools, MSN Live Webmaster Tools and Yahoo! Site Explorer.\nYou\u0026rsquo;ll then need to verify your site(s) with each of the search engines, they provide details about how to do this but it typically requires that you put a meta tag in your page header. Once you\u0026rsquo;ve verified your site(s) it\u0026rsquo;s time to create a sitemap.xml.\nIf you have a Wordpress blog adding sitemap support is easy, just use the Google XML Sitemaps plugin. This re-builds sitemap.xml when you update posts, pages, comments etc. It also notifies all the relevant search engines that content has changed on your site. Very useful indeed. If you need to create your sitemap by hand, or better yet script its creation, then read sitemaps.org for the protocol spec.\n","permalink":"https://wimpysworld.com/posts/search-engine-verification-and-sitemaps/","tags":["Content Management","SEO","Sitemap","Wordpress"],"title":"Search engine verification and sitemaps"},{"categories":["Linux","Open Source","Content Creation"],"contents":"I\u0026rsquo;ve just installed WordTwit on my blog. WordTwit keeps track of when you publish new posts, and automatically informs all of your followers by pushing out a Twitter tweet. All links are automatically converted to tiny URLs.\n","permalink":"https://wimpysworld.com/posts/blog-post-notifications-to-twitter/","tags":["Content Management","Wordpress","Twitter","PHP"],"title":"Blog post notifications to Twitter"},{"categories":["Linux","Open Source","Security"],"contents":"We have a reasonable number of Debian servers at work and as a result I ssh into servers about as many times as I visit Google. I have been using Profiles in gnome-terminal to manage my ssh connections, which is fine but requires I already have a terminal open to initiate a new server connection. Enter SSHMenu, a GNOME panel applet that keeps all your regular SSH connections within a single mouse click.\nI couldn\u0026rsquo;t be arsed adding up a new repo for one application, so here are my quick and dirty install steps.\nwget http://sshmenu.sourceforge.net/debian/dists/stable/contrib/binary-all/sshmenu_3.15-1_all.deb wget http://sshmenu.sourceforge.net/debian/dists/stable/contrib/binary-all/sshmenu-gnome_3.15-1_all.deb sudo gdebi -n sshmenu_3.15-1_all.deb sudo gdebi -n sshmenu-gnome_3.15-1_all.deb I have taken to using gdebi to install local deb packages as it resolves and installs dependencies. Now add SSHMenu to a GNOME panel and configure your ssh connections. If SSHMenu isn\u0026rsquo;t listed in the GNOME panel applets yet, then you can force a refresh with the rather heavy handed\u0026hellip;\nkillall gnome-panel ","permalink":"https://wimpysworld.com/posts/sshmenu-ssh-connection-management/","tags":["GNOME","Ubuntu","OpenSSH","SSHMenu"],"title":"SSHMenu - SSH Connection Management"},{"categories":["Linux"],"contents":"AIR (Automated Image and Restore) is a GUI front-end to dd and dcfldd designed for easily creating forensic bit images. Or, a nice way to let the guys at work who like GUIs make Debian boot install floppies (don\u0026rsquo;t ask) easily. Ubuntu 7.10 doesn\u0026rsquo;t have a package for AIR, but AIR does have an installer.\nsudo aptitude install perl-tk sharutils dcfldd netcat cryptcat wget http://prdownloads.sourceforge.net/air-imager/air-1.2.8.tar.gz?download tar zxvf air-1.2.8.tar.gz cd air-1.2.8/ sudo ./install-air-1.2.8 At this point the installer thingy will kick off, follow the prompts. I have found that air needs to run as root, but won\u0026rsquo;t run if the executable is setuid. So run it via sudo like so:\nsudo air ","permalink":"https://wimpysworld.com/posts/get-some-air/","tags":["dd","dcfldd","Ubuntu"],"title":"Get some AIR"},{"categories":["Linux","Open Source"],"contents":"gLabels, as packaged in the Ubuntu repositories, has not worked properly for some time. The accuracy of printing was way out making gLabels a non-starter unless you went to the hassle of manually re-aligning every label on a page to account for the inaccuracies.\nHowever, I have been patiently waiting for a new version of gLables to be released. The new development branch completely replaces libgnomeprint with the new GtkPrintOperation and Cairo. The upshot of that is that the printing accuracy issues are resolved.\nGetDeb have released .debs for gLabels 2.2.1 that work with Ubuntu Gutsy 7.10. You can either download the .debs from the gLabels page at GetDeb and let gdebi do its thing or do the following from the shell\u0026hellip;\nwget -c ftp://cesium.di.uminho.pt/pub/getdeb/gl/glabels_2.2.1-1~getdeb1_i386.deb wget -c ftp://cesium.di.uminho.pt/pub/getdeb/gl/glabels-data_2.2.1-1~getdeb1_all.deb sudo dpkg -i glabels*.deb We print a lot of labels at work to identify media for flight recorders, that job just got a whole lot easier. More importantly, I now have a viable address label printing solution for my wife.\n","permalink":"https://wimpysworld.com/posts/glabels-2.2.1/","tags":["GNOME","Ubuntu","Label Printing","Printing"],"title":"gLabels 2.2.1"},{"categories":["Linux","Open Source","Content Creation","Tutorial"],"contents":"I have been meaning to setup a weblog client for a while now. I have tested a couple of blog clients and have settled on BloGTK.\nIt has a simple user interface but comprehensive features, although I did need to define a few Custom Tags before the editor supported all the formatting options I wanted. Setting up BloGTK is very simple for Ubuntu and Debain users requiring an aptitude install blogtk to get it installed and the following settings will connect to a Wordpress blog.\nServer URL: http://blog.example.org/xmlrpc.php Account: Your Username Password: Your Password Blogging System: Moveable Type Now I can blog directly from my desktop, I am hoping it will encourage me to post more often.\n","permalink":"https://wimpysworld.com/posts/blogtk-a-weblog-client-for-linux/","tags":["Content Management","Wordpress","GNOME","xmlrpc","BloGTK","Debian","Ubuntu"],"title":"BloGTK, a weblog client for Linux"},{"categories":["Linux","Open Source"],"contents":"When I setup the mail server at work I picked Zimbra. It\u0026rsquo;s great.\nToday Zimbra just got a bit better when I found Zindus. Zindus is open source software and runs on all Thunderbird platforms including Windows, Mac OSX and Linux. Zindus can sync your contacts between Zimbra and Thunderbird. It syncs everything from Address Books to your GAL (Global Address List).\nIt currently supports ZCS 3.x to 5.x. Adding the Lightning and Zindus add-ons to Thunderbird create a very complete desktop client to Zimbra for any platform. Can\u0026rsquo;t wait to share to good news with my Outlook users.\n","permalink":"https://wimpysworld.com/posts/zindus-contact-sync-for-thunderbird-and-zimbra/","tags":["Zimbra","Zindus","Thunderbird","Lightning","Messaging"],"title":"Zindus contact sync for Thunderbird and Zimbra"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"For the longest time I have been meaning to setup a shared calendar for my wife I and to use. You see, like most men I have no idea when and where I am supposed to be. This is because my wife keeps all this information in her filofax and that lives in her handbag, somewhere I never venture. So I have spent this evening setting up PHP iCalendar on Lighttpd, and I am very happy with the results.\nI have opted to use the publish.php add-on provided with PHP iCalendar, rather than add the WebDAV module to Lighty. For our modest requirements it works very well. We now have full read/write access to our calendar by using the Lightning extension for Thunderbird and read only access via the PHP iCalendar web interface. Viewing the calendar via the web interface requires a login first and the calendar publishing is protected by Lighty authentication using htdigest.\nLastly, because our calendar is a nice open standard I have options as to how I might sync it with my mobile phone. More on that when I figure it out.\n","permalink":"https://wimpysworld.com/posts/simple-ical-server/","tags":["iCal","Lighttpd","Thunderbird","PHP","Calendar"],"title":"Simple iCal Server"},{"categories":["OPen Source","Content Creation"],"contents":"I have finally got around to re-activating this website after many months of neglect. The first thing to do was move away from Jaws. Sadly, my Jaws installation is broken in a way that newer Jaws releases refuse to upgrade it.\nI did some research and decided to migrate to Wordpress since it caters for all the essentials I require either in the core functionality or via plugins. Plus I can integrate with some other stuff I want to use.\nThe migration to Wordpress was made all the easier thanks to the excellent Jaws import plugin I found on the Wordpress trac. However, I decided not to use the Textile plugin to preserve the Jaws formatted text. Instead I chose to manually clean up some of the old entries so I could stick with the TinyMCE editor long term.\nI am happy with Wordpress thus far and look forward to getting some plugins going and picking up a new theme over the coming days and weeks.\n","permalink":"https://wimpysworld.com/posts/flexion.org-is-re-activated/","tags":["Wordpress","Jaws","Content Management","PHP"],"title":"Flexion.Org is re-activated!"},{"categories":["Linux","Development","Open Source"],"contents":"Led the design, development and operation of the POLARIS project at Flight Data Services. An Open Source analysis engine developed using Python that can scale to analyse and report on millions of commercial aviation flights to comply with global aviation safety regulations. Now known as Flight Data Connect and owned by L3HARRIS and apparently no longer available as Open Source.\nOrganisation: Flight Data Services Date: May 2007 - September 2015 Role: Manager of IT Operations \u0026amp; Software Engineering ","permalink":"https://wimpysworld.com/projects/polaris/","tags":["Python","Django","Numpy","Scipy","Postgres","FDM","FOQA","Flight Data","OpenVZ","Containers","Analysis","Flight Recorder","Blackbox"],"title":"POLARIS"},{"categories":["Open Source","Development"],"contents":"R3-born 0.1.1 is released :-)\nR3-born Core Change Log Here are the main changes for this release. v0.1.1 : 9th March 2007\nAdded Akismet anti-spam API Added a version checker for the Core and also for Blocks and Modules. Added search bot (Google, MSN, Yahoo!, etc) detection. Added logging (in Combined Log Format) to the R3-born Intrusion Prevention System. Enhanced the Module API so it now supports safe updating and custom CSS for blocks and modules. Enhanced the Layout Manager Enhanced the Registration and Profile pages by separating them. Enhanced the Template engine by back porting some features from phpBB 3.0.x Optimised and fixed the Search API Optimised and simplified Coloured Groups. Improved the Groups Management ACP Improved the Styles Management ACP Fixed various bugs in the core. Significant feature enhancements, bug fixes and optimisations added to the Menu and Who Is Online blocks. Significant feature enhancements, bug fixes and optimisations added to the Comments, Downloads, Forum, Pages, Private Messages, Weblogs and View Online modules. New modules : bot_list, cookie, error, google, referrers and sql_backup New blocks : recent_blogs, recent_comments, recent_pages, recent_topics, search, socmarks and visit_counter. R3-born 0.1.1 has fulfilled its first major objective, which is to be functional enough to run a website.\n","permalink":"https://wimpysworld.com/posts/r3-born-0.1.1-is-released/","tags":["R3-born","Content Management","PHP"],"title":"R3-born 0.1.1 is released!"},{"categories":["Open Source","Development"],"contents":"Finally, R3-born 0.1.0 is released. R3-born is a content management system for modest websites which I hope will be ideal for individuals running their own sites or small community websites.\nDue to my accident I have not been able to address all of the bugs which have been reported recently and the downloads are only available as bzip2 tarballs right now. Please report any bugs you might encounter as 0.1.0 has really only been tested on Debian Sarge (stable) running PHP4 and MSQL 4. Feedback from other configurations will be useful and all reported bugs will be investigated.\n","permalink":"https://wimpysworld.com/posts/r3-born-0.1.0-is-released/","tags":["R3-born","Content Management","PHP"],"title":"R3-born 0.1.0 is released!"},{"categories":["Open Source","Development"],"contents":"I suppose it is a bit silly to announce this just before I go on holiday but what the heck. R3-born is intended to be a simple and modular content management system for modest websites. My hope is that it will be ideal for individuals running their own sites or for small community websites. R3-born is coded in PHP (4.2.0 or better required) and requires an SQL database, currently MySQL 3.x, 4.x and 5.x, Postgres 7.x or better and MS-SQL 7.x or better are supported.\nCurrent Status Right now, R3-born is considered pre-alpha and not suitable for a production website but is ready for testers to start feeding back on bugs, feature requests and in the near future code changes. Development has been fairly rapid so far. I started the project in April 2006 and I hope to release a beta version of R3-born later in 2006.\nhttp://www.sourceforge.net/projects/r3-born/ ","permalink":"https://wimpysworld.com/posts/announcing-r3-born/","tags":["R3-born","Content Management","PHP"],"title":"Announcing R3-born"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"I have reorganized and consolidated my Debian and Ubuntu HOW-TOs for RavenCore 0.2.3.\n","permalink":"https://wimpysworld.com/posts/conslidated-ravencore-how-tos/","tags":["Debian","RavenCore","Virtual Hosting","Ubuntu"],"title":"Conslidated RavenCore HOW-TOs"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"I have updated my HOW-TO for installing RavenCore on Debian (at the request of the RavenCore developer) and added a HOW-TO for installing RavenCore on Ubuntu. The are still some minor compatibility issues with Debian and Ubuntu and these HOW-TOs have been sent to the RavenCore developer to help document the outstanding incompatibilities.\n","permalink":"https://wimpysworld.com/posts/ravencore-0.2.3-on-debian-and-ubuntu/","tags":["Debian","RavenCore","Virtual Hosting","Ubuntu"],"title":"RavenCore 0.2.3 on Debian and Ubuntu"},{"categories":["Open Source","Development"],"contents":"First of all, I have disabled comments on my blog. Jaws has spam protection and captachs but both implementations suck. This site doesn\u0026rsquo;t generate much feedback so disabling comments altogether is not really a problem. I haven\u0026rsquo;t updated the site recently and here is why. The 0.6.x release of Jaws is buggy and I still haven\u0026rsquo;t found anything else which fully meets my needs for managing my own web content.\nTherefore for the last couple of months I have been working on an open source CMS of my own called R3-born. More details to follow about that soon, but you can find the project over at Sourceforge, don\u0026rsquo;t expect anything to work (although it does for the most part) it is pre-alpha and unreleased. SVN is the only way to snag the source.\nR3-born ","permalink":"https://wimpysworld.com/posts/comments-off-overdue-update-and-r3-born/","tags":["Content Management","Jaws","PHP","R3-born"],"title":"Comments off, Overdue update and R3-born"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"I have updated my HOW-TO for installing RavenCore 0.1.5 on Debian. I\u0026rsquo;m pleased to report that the RavenCore developer has been very responsive to my feedback and has significantly improved \u0026ldquo;out of the box\u0026rdquo; Debian compatibility in this release. The are still some minor compatibility issues and I\u0026rsquo;ve\u0026rsquo; sent feedback to the developer in the hope that things will continue to improve with RavenCore 0.1.6.\n","permalink":"https://wimpysworld.com/posts/ravencore-0.1.5-on-debian/","tags":["RavenCore","Debian","Virtual Hosting"],"title":"RavenCore 0.1.5 on Debian"},{"categories":["Open Source","Development"],"contents":"Despite a generous offer from a Minerva enthusiast a year or so ago to freely host the Project Minerva sites, all the Project Minerva hosting is coming back to where it started and rightly belongs. Yes, right here with me. It just goes to show you really don\u0026rsquo;t get anything for free. The developers have had several outages with the server which was provided by SpiderTech Hosting, so we are bringing it back here where we can look after our interests directly.\nMinerva users might be wondering if the fact I am fully hosting Project Minerva again means I am going to be developing for the project again. Well, we will just have to see but I did inform Chris of a little project I kicked off last week which may (or may not) lead to something.\n","permalink":"https://wimpysworld.com/posts/project-minerva-is-coming-home/","tags":["Minerva","PHP","Content Management"],"title":"Project Minerva is coming home"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"Here\u0026rsquo;s the blurb from the authors\u0026hellip; Munin surveys all your computers and remembers what it saw. It presents all the information in in graphs through a web interface. Its emphasis is on plug and play capabilities. After completing a installation a high number of monitoring plugins will be playing with no more effort. Using Munin you can easily monitor the performance of your computers, networks, SANs, and quite possibly applications as well. It makes it easy to determine \u0026ldquo;what\u0026rsquo;s different today\u0026rdquo; when a performance problem crops up. It makes it easy to see how you\u0026rsquo;re doing capacity wise on all limited resources.\n","permalink":"https://wimpysworld.com/posts/today-i-have-been-mostly-lovin-munin/","tags":["Server Monitoring","Munin"],"title":"Today I have been mostly lovin' Munin"},{"categories":["Open Source"],"contents":"Yah for me! I have won the RavenCore documentation contest.\n","permalink":"https://wimpysworld.com/posts/i-am-a-winner/","tags":["RavenCore","Virtual Hosting"],"title":"I am a winner!"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"Today Flexion.Org was successfully migrated to a new server. I\u0026rsquo;ve been using the same shared host for over 7 years but these days I really need much better control over my server, mostly for spam/virus protection of e-mail but also to ensure that periodic upgrades don\u0026rsquo;t screw up my website.\nSo this time I opted for a virtual dedicated server and I had a choice of all the popular Linux distros, which I can re-install via a web interface at will in a few seconds. I choose. If you are looking for a low cost virtual dedicated server then take a look at Quantact.\n","permalink":"https://wimpysworld.com/posts/flexion.org-server-migrated/","tags":["VPS","Debian"],"title":"Flexion.Org Server Migrated"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"I set up my new server to use RavenCore so that managing my domains and e-mail accounts for friends and family will be as easy as possible. RavenCore is designed for use on CentOS primarily and therefore RavenCore 0.1.4 requires some tweaking in order to get it fully working and compatible with Debian.\nI have been sharing my feedback with the RavenCore author and when RavenCore 0.1.5 is released \u0026ldquo;out of the box\u0026rdquo; Debian compatibility should be a reality.\n","permalink":"https://wimpysworld.com/posts/ravencore-0.1.4-on-debian/","tags":["Debian","RavenCore","Virtual Hosting","CentOS","Debian"],"title":"RavenCore 0.1.4 on Debian"},{"categories":["Development"],"contents":"I started a new job last week, I am contracting for the first time. I needed some applications installed on my desktop at work, but to do so would not be permitted as part of my clients standard build policies.\nSo I started making a USB disk with the tools I needed and in doing do I found the Portableapp and The Portable Freeware Collection websites which ease the process no end.\nA portable app is a computer program that you can carry around with you on a portable device and use on any Windows computer. When your USB thumb drive, portable hard drive, iPod or other portable device is plugged in, you have access to your software and personal data just as you would on your own PC. And when you unplug, none of your personal data is left behind.\n","permalink":"https://wimpysworld.com/posts/portable-app/","tags":["Windows"],"title":"Portable app"},{"categories":null,"contents":"A shocking truth is that despite my preference for Linux I do still have to use Microsoft Windows/ I have recently started a new job where I am now required to use Windows XP on my desktop at work and I also need a Windows computer at home in order to update firmware/software and configure most devices in my home cinema.\nSo I have decided to install Windows XP on my most aging of laptops so it is always available for my home cinema tweaking, this also means I can remove dual boot Windows partitions on my main computer. However, because my old laptop is a bit short on memory I need to tweak Windows XP a good deal. I have been a long time user of 98Lite and XPLite from LitePC.om and have been slim lining Windows for many years. I have recently found nLite which does much the same as XPLite except it rebuilds the Windows XP (or Windows 2000 and Windows 2003) installation CD so that the configuration changes you make, and Windows components you remove, are ingrained in a new ISO image.\nThe biggest benefit is that using nLite I can integrate Service Pack 2 and all the current hotfixes and patches into the new ISO meaning that after an install the new Windows system is better secured. I have also been able to integrate Firefox into my custom Windows XP install CD and completely remove Internet Explorer, and by using the WindizUpdate it is possible to do online Windows Updates using Firefox, Opera and K-Meleon.\nThere are also many other benefits to using nLite other than simply removing or adding software components, you can also pre-configure just about every aspect of the Windows environment and nLite will wrap all this into an unattended installation ISO image. My custom Windows XP install CD I made with nLite is just 145mb!\n","permalink":"https://wimpysworld.com/posts/slimlining-windows-xp-with-nlite-and-xplite/","tags":["Windows","nLite","XPLite","98Lite"],"title":"Slimlining Windows XP with nLite and XPLite"},{"categories":["Linux","Open Source"],"contents":"A week or so ago the NetworkManager package was changed so that nm-applet (the system tray application) was separated into it\u0026rsquo;s own package. After I updated and installed nm-applet, I noticed that it didn\u0026rsquo;t startup anymore. I didn\u0026rsquo;t have time to investigate until this morning and found the answer in the following forum posting\u0026hellip;\nNetworkManager broken after last update Here is the pearl of wisdom, from that forum discussion, that helped me make my system to be NetworkManager compatible again.\n\u0026ldquo;Network Manager has been installed on your system, however it will not immediately be able to manage your network interfaces. To avoid problems with important configuration being ignored, or strange behaviours, the Ubuntu version will not manage any network interface configured in the /etc/network/interfaces file.\nTo allow interfaces to be managed with Network Manager either edit the /etc/network/interfaces file and remove (or comment out) the \u0026ldquo;auto\u0026rdquo; and \u0026ldquo;iface\u0026rdquo; lines for those interfaces you wish it to manage, or use the \u0026ldquo;Networking\u0026rdquo; administration tool (found under the \u0026ldquo;System\u0026rdquo; menu) to disable the interfaces.\u0026rdquo;\n","permalink":"https://wimpysworld.com/posts/networkmanager-and-ubuntu-dapper-drake-6.04/","tags":["Ubuntu","NetworkManager"],"title":"NetworkManager and Ubuntu Dapper Drake 6.04"},{"categories":["Travel"],"contents":"We just got back from an enjoyable trip to Dublin, highlights for me were visits to the\u0026hellip;\nGuinness Storehouse for a history lesson and a drop of the black stuff. The Old Jameson Distillery for another history lesson and a drop of the hard stuff, I also certified as an Irish Whiskey taster during the visit. I have a certificate and everything :-) Gallagher\u0026rsquo;s Boxty House for some traditional Irish grub. Ryanair\u0026rsquo;s ticket prices, just 10p return each! This was our first visit to Ireland and I am looking forward to going back again soon and maybe incorporate some diving.\n","permalink":"https://wimpysworld.com/posts/long-weekend-in-dublin/","tags":["Dublin","Ireland"],"title":"Long weekend in Dublin"},{"categories":["Home Cinema","Entertainment"],"contents":"Today I finally got around to ordering some stuff from Amazon.co.uk using the vouchers I was given as present at Christmas. I have ordered The Matrix Trilogy and The Lord of the Rings Trilogy (Extended Edition Box Set) which I hope arrive before the weekend as my wife is away for a few days which should be enough time to get through both box sets üòÑ\n","permalink":"https://wimpysworld.com/posts/dvd-box-sets-extended-film-watching-session-is-coming/","tags":["DVD"],"title":"DVD Box Sets - Extended Film Watching Session is Coming"},{"categories":["Gadgets","Health \u0026 Fitness"],"contents":"I finally convinced my wife that I need (really wanted) a new mountain bike and today I took delivery of the Trek 4300 Disc 2006 model\nI managed to fall off it on the maiden voyage but I thought it best to get that out that way before I tackle to Bracknell Woods this coming Sunday.\n","permalink":"https://wimpysworld.com/posts/new-mountain-bike/","tags":["Trek 4300 Disc 2006","Mountain Bike"],"title":"New Mountain Bike"},{"categories":["Gadgets","Entertainment"],"contents":"My six year old MP3 player just isn\u0026rsquo;t up to the job anymore and I have been looking for an alternative, on and off, over that last few weeks. Ideally I would have liked a portable music player that supported Ogg Vorbis but as my home cinema isn\u0026rsquo;t Ogg Vorbis compatible I decided to standardize on MP3. No flames please!\nI have lots of MMC and SD memory cards that I have collected over the years so decided get a player which could make use of them. I only need a player for use in the gym and while cycling so it doesn\u0026rsquo;t need to be too fancy, with that in mind I decided to get the Sumvision XT105 MP3 Player which is super cheap and surprisingly good considering the price :-)\nInitial impressions are that the manual was obviously translated from Chinese to English using Google, the included headphones are not much cop. That said, once you plug-in a decent set of head phones the sound reproduction is very good and more than good enough for what I want it for and although playlists aren\u0026rsquo;t supported playback by folder is. That player is very light and very small, so ideal for use in the gym and battery life is around 10-12 hours from a single AAA battery. It is also Linux compatible, although I have been using a USB card reader to populate my memory cards with MP3s as the XT105 is only USB 1.1 and therefore a bit slow. I am off to the gym now with some banging tunes.\n","permalink":"https://wimpysworld.com/posts/cheap-and-cheerful-mp3-player/","tags":["MP3","Sumvision XT105"],"title":"Cheap and Cheerful MP3 Player"},{"categories":["Home Cinema"],"contents":"I\u0026rsquo;ve noticed that the contrast levels on my Panasonic TH42-PHD8 plasma will suddenly increase during dark scenes and then drop back down to normal a fraction of a second later. This can be most distracting but as it only happens once or twice a week it hasn\u0026rsquo;t really bothered me. But, I found a discussion at AVForums which describes how to enter the plasma service menu and fix this behaviour. I\u0026rsquo;m pleased to say it works perfectly. Here\u0026rsquo;s the solution:\nPanasonic Black Shift Problem/Solution ","permalink":"https://wimpysworld.com/posts/panasonic-plasma-black-level-fluctuation-fix/","tags":["Panasonic TH42-PHD8","Plasma TV"],"title":"Panasonic Plasma Black Level Fluctuation Fix"},{"categories":["Linux","Open Source"],"contents":"Despite my glowing comments about Fedora a couple of weeks back, the honeymoon period is well and truly over. My biggest gripe with Fedora is even with numerous compatible repositories enabled there isn\u0026rsquo;t a suitable selection of packages available and dependency breakage is all too frequent.\nAlthough I can build my own packages from source I just don\u0026rsquo;t have the time (or inclination) for that anymore. I do really like the Early Logon feature and the working NetworkManager in Fedora, but sadly these features are not enough to keep me away from Ubuntu. As a result I have just finished migrating all my computers to Ubuntu Dapper Drake 6.04 - Flight 3, which is shaping up to be another excellent release. Matt Galvin has been doing a great job of tracking the new features in each of the Dapper Flight pre-releases, see the Wiki entries below\u0026hellip;\nhttps://wiki.ubuntu.com/DapperFlight2 https://wiki.ubuntu.com/DapperFlight3 https://wiki.ubuntu.com/DapperFlight4 Having spent 6 weeks using Fedora I have decided that I have learnt enough about it to conclude it just isn\u0026rsquo;t for me and I will be seeing out the rest of 2006 using Ubuntu as my desktop OS. However, I will dabble with other distros periodically.\n","permalink":"https://wimpysworld.com/posts/the-honeymoon-is-over/","tags":["Fedora","Ubuntu"],"title":"The honeymoon is over"},{"categories":["Linux","Open Source"],"contents":"Having spent all of 2005 using Ubuntu I have learnt a lot about Debian and even started using Debian for my servers.\nDespite using Linux for over 10 years I had never previously used Debian and had even avoided using it. I was surprised by how much I liked using Ubuntu and Debian and decided that I give Fedora another try as I have never warmed to redhat in the same way I had never previously warmed to Debian. For the longest time I used Slackware and then switched to Crux.\nThis week I have installed Fedora Core 4 on my home computer and been hugely impressed, but this is mostly down to finding the nrpms.net repository. I was already using the RPMforge.net group of repositories and nrpms.net is striving for RPMforge compatibility, so far I haven\u0026rsquo;t experienced any package or dependency breakage so they must be doing something right. Thanks to nrpms.net I have effortlessly upgraded FC4 to GNOME 2.12.1, Firefox 1.5, mono 1.1.12 plus numerous other GNOME applications I regularly use which aren\u0026rsquo;t available elsewhere. The real bonus was to get NetworkManager 0.5.1 from nrpms.net which actually works, and works reliably!\nAs a result, this is a Linux distribution I can install on my wifes laptop without fear of reprisals. I have found that installing proprietary hardware drivers and software has been much simpler for Fedora than Ubuntu, most notable are VMWare Player, Linuxant HSF modem drivers, ATI drivers, Opera and Skype.\nI have been able to get my Smartphone and PocketPC working under Ubuntu the amount of tweaking and constant manual intervention is cumbersome. So I was staggered when after installing the SynCE packages on Fedora both devices just worked when connected via USB, the whole process was completely seamless.\nSo, after a few days tinkering I have everything I need installed, configured and working reliably. Fedora is not perfect thought, yum is still lagging behind apt and even that even after enabling a number of the excellent 3rd party repositories the number and variety of packages available to FC4 isn\u0026rsquo;t that great. Installing software is just so slow, what the bloody hell is yum doing? Using yumex is coma inducing and up2date just doesn\u0026rsquo;t work.\nThat said, there is some work being done in these areas for FC5 so maybe the gap will be closed on apt a little in the coming months. I do like the fact that the official Fedora repositories update packages past the final release date, something which Ubuntu doesn\u0026rsquo;t do. This means that on my first yum update OpenOffice was upgrade from 1.9.140 Beta to 2.0.1 final and many other essential applications were also upgraded. Just when I thought it couldn\u0026rsquo;t get any better I discovered the \u0026ldquo;Early Login\u0026rdquo; feature which is new to Fedora Core 4. It is simply brilliant and I can not get from power button to GNOME desktop in 20 seconds. I so wanted to not like Fedora but I have to say I think I might be converted. I will have to see how long this enthusiasm for Fedora will last, but I am already looking forward to FC5.\n","permalink":"https://wimpysworld.com/posts/leading-edge-fedora-core-4/","tags":["Debian","Fedora","Ubuntu","Slackware","Crux"],"title":"Leading edge Fedora Core 4"},{"categories":["Linux","Open Source","Tutorial"],"contents":"James bought a PowerBook G3 to the January 2006 HantsLUG meeting and wanted to have Ubuntu installed on it. I used to be familiar with Apple Mac computers in the mid to late 90\u0026rsquo;s because the company I worked for used Macs exclusively on the desktop, so I decided to give it a whirl.\nThe bottom line is that this old PowerBook G3 is now running Ubuntu Hoary 5.04 quite happily and I will soon be phone James to arrange for him to pick up his computer.\nThe article is largely based on the OldWorldsMac Ubuntu Wiki, I have included the specifics of James setup here so he has a record of how his computer was configured.\nI quickly realised that simply inserting the Ubuntu Hoary 5.04 PowerPC install CD and rebooting while holding down the \u0026lsquo;C\u0026rsquo; key wasn\u0026rsquo;t going to work. It seems that James computer is old enough to be a right pain in the arse to get working with Linux, but that just makes me want to get it working all the more :-)\nBy the end of the HantsLUG meeting Ubuntu Hoary 5.04 was just completing the final setup steps and would have been ready to use, but someone pulled the power block out of the mains and James battery is dead, so the computer shutdown :-( I took the PowerBook G3 home with me to fix/complete the installation but when I got home I decided to download Ubuntu Breezy and install that instead. Sadly, James PowerBook only has a 2GB hard disk (1.9GB available for Linux) and this wasn\u0026rsquo;t sufficient for the Breezy installation to complete so I reverted to Hoary.\nIdentifying the PowerBook G3 After some Googling I soon discovered that there are two classes of PowerBook G3, OldWorld and NewWorld, and that each of the classes have a number of slightly different models in the range. I took a guess that James was an OldWorld PowerBook based on the fact it had no USB ports. It turns out this was a good guess.\nMaking the assumption that James PowerBook was OldWorld meant that I should use BootX to boot into Linux from MacOS as opposed to using yaboot which is for NewWorld PowerPCs.\nPowerBook G3 Computers: How to Identify Different Models Doing the MacOS Installation The first job was to erase the hard disk and install MacOS in a small parition and leave the rest of the drive unallocated for installing Ubuntu later on.\nInsert MacOS 8.1 CD Reboot Hold down \u0026lsquo;C\u0026rsquo; as the computer boots to get it to boot from CD Erase the Hard Disk Use Drive Setup to make a 150MB HFS partition. Install MacOS, leaving off all the optional components. The only thing you need is Stuffit and a browser which are both part of the minimal MacOS8.1 install. After the install I delete some odds and ends I didn\u0026rsquo;t need and also used Extensions Manager to deselect a lot of components that were not required. Finally, I configured TCP/IP to use DHCP.\nTools Update James wanted to be able to use MacOS for basic web surfing, so that meant finding an more modern alternative to Netscape 3.0.3 which was installed be default. Sadly The only (relatively) upto date browser I could find which would install on MacOS 8.1 was Internet Explorer 5.1.7. I also needed an updated version of Stuffit Expander to extract BootX 1.2.2. I used Netscape 3.0.3 to download IE and Stuffit from the URL\u0026rsquo;s below\u0026hellip;\nInternet Explorer 5.1.7 for Mac OS 8.1 to 9.x Stuffit Expander 5.5 for MacOS Classic \u0026hellip;and installed them. Once they were working a deleted Netscpae 3.0.3 and the old version of Stuffit.\nBootX Older versions of Stuffit will only extract BootX 1.1.3 which I why I updated Stuffit Expander as explained earlier. Download BootX 1.2.2.\nBootX Open it with Stuffit and extract it the the Desktop then open the resulting BootX 1.2.2 folder on the desktop. Drag each of the following\u0026hellip;\nBootX BootX Extension Linux Kernels \u0026hellip;onto the \u0026ldquo;System Folder\u0026rdquo; one at a time to install BootX correctly. Insert the Ubuntu PPC install CD and navigate to the /install/powerpc folder.\nCopy vmlinux to (the Linux kernel) System Folder/Linux Kernels Copy initrd.gz (the init ramdisk image) to System Folder/ and rename it to ramdisk.image.gz BootX should appear on the apple menu and also run on every reboot during the boot process, meaning that you can choose to boot Linux without having to wait for the entire MacOS to load :-) When you run BootX it should show \u0026lsquo;vmlinux\u0026rsquo; as an available kernel, now add the following to \u0026ldquo;More kernel arguments\u0026rdquo; to make sure the correct video mode is used for Linux.\nvideo=atyfb:vmode:14,cmode:32,mclk:71 Now click the \u0026ldquo;Options\u0026rdquo; button, check \u0026ldquo;Use Specified RAM disk\u0026rdquo; and select System Folder/ramdisk.image.gz. Click on the \u0026ldquo;Save to prefs\u0026rdquo; button and then click on the \u0026ldquo;Linux\u0026rdquo; button and in a short while you should be looking at the regular Ubuntu install dialogs.\nOther Video Mode Suggestions I didn\u0026rsquo;t test these, but my understanding is the \u0026lsquo;cmode\u0026rsquo; choose the bit depth 8 for 8bit, 16, for 16bit and so one. \u0026lsquo;mclk\u0026rsquo; controls the graphics/monitor refresh rate I think, I was lucky that I the video mode suggested in the BootX README worked first go.\nvideo=atyfb:vmode:14,cmode:32,mclk:65 video=atyfb:vmode:14,cmode:8,mclk:63 Doing the Ubuntu Installation The installer will display an error message that \u0026ldquo;Configure a multiseat system\u0026rdquo; failed. You can ignore this\u0026hellip;\nSelect \u0026lsquo;Continue\u0026rsquo; Select \u0026lsquo;Detect Hardware\u0026rsquo; and press Enter \u0026hellip;and the install will continue normally.\nPartitioning When it gets to partitioning the drive Ubuntu will suggest using the entire disk for Linux. Don\u0026rsquo;t do that because you still need MacOS to run BootX to bootstrap Linux. Select the \u0026ldquo;Use Free Space\u0026rdquo; option or partition manually.\nCopying /boot to the HFS System Folder The rest of the install is fairly straight forward until you get to the part where Ubuntu tries to install a bootloader. GRUB and Lilo don\u0026rsquo;t work on OldWorld Macs, so Ubuntu will warn you that no bootloader can be installed. Switch to a second console at this point (Option-F2) and use df to see where things are currently mounted. In my case the newly installed ubuntu was on /dev/hda8 mounted as /target and the HFS filesystem was /dev/hda7. Make a mountpoint and mount the HFS filesystem.\ncd /target mkdir hfs mount /dev/hda7 hfs -t hfs You might also want to add an entry to /etc/fstab so it will be mounted when you reboot. This makes updating kernels easier in the future.\necho \u0026#39;/dev/hda7 /hfs hfs defaults\u0026#39; \u0026gt;\u0026gt; etc/fstab Now copy the kernel and boot image over;\ncp boot/vmlinux hfs/System\\ Folder/Linux\\ Kernels/vmlinux cp boot/initrd.img hfs/System\\ Folder/ramdisk.image.gz Option-F1 to get back to the installer, and tell it to go ahead and reboot.\nWhen the machine reboots the BootX dialog should come up straight away, just click \u0026ldquo;Linux\u0026rdquo; and Ubuntu should proceed through the rest of the install as usual.\nReferences http://ubuntuforums.org/showthread.php?t=73689 http://ubuntuforums.org/showthread.php?t=36431 https://wiki.ubuntu.com/Installation/OldWorldMacs http://penguinppc.org/ http://gonz.wordpress.com/2006/03/22/installing-ubuntu-510-breezy-badger-on-an-old-world-powerbook-g3-wallstreet/ ","permalink":"https://wimpysworld.com/posts/powerbook-g3-old-world-ubuntu-install/","tags":["Ubuntu","PowerBook G3","Mac"],"title":"Powerbook G3 (Old World) Ubuntu Install"},{"categories":["Linux","Open Source","Self Hosting"],"contents":"I have been testing a few virtual hosting control panels the last couple of days and I am deeply impressed with RavenCore, so much so I will most likely use it for a project I am planning. However, Debian is my server distro of choice and RavenCore needs a little tweaking in order to work seamlessly with Debian. I have been keeping some notes that explain how to get RavenCore to play nicely with Debian.\nI have submitted my notes in the RavenCore Forums and agreed to assist the author with any future testing to work toward better \u0026ldquo;out of the box\u0026rdquo; Debian integration.\n","permalink":"https://wimpysworld.com/posts/ravencore-0.0.6-on-debian/","tags":["Debian","RavenCore","Virtual Hosting"],"title":"RavenCore 0.0.6 on Debian"},{"categories":["Linux","Development","Open Source"],"contents":"Ubuntu comes with everything you need to run your organisation, school, home or enterprise. All the essential applications, like an office suite, browsers, email and media apps come pre-installed.\nCommunity contributor since 2006, worked for Canonical from 2016 to 2021 progressing from software engineer to director of engineering. I remain active in the Ubuntu community.\nOrganisation: Ubuntu Project \u0026amp; Canonical Date: January 2006 - date Role: Community contributor ","permalink":"https://wimpysworld.com/projects/ubuntu/","tags":["Ubuntu","Debian","GNOME","C","GTK","Python","Snapcraft","systemd","Raspberry Pi","Community","Robotics","IoT"],"title":"Ubuntu"},{"categories":["Linux","Open Source"],"contents":"I decided to install Ubuntu Dapper Flight-2 on a spare computer I had available. There are not any obvious differences between Dapper and Breezy at this early stage but one thing which does stand out is the performance improvements. My test Dapper and stable Breezy computers are exactly the same specification and the boot times for Dapper are vastly improved, currently 37 seconds (average) faster from power on to GNOME desktop than with Breezy. The graphical boot menu when booting from the install CD in a nice touch, I look forward to seeing how Dapper improves over the coming months. But right now there isn\u0026rsquo;t anything especially new, different or unusual to test.\n","permalink":"https://wimpysworld.com/posts/ubuntu-dapper-flight-2/","tags":["Ubuntu"],"title":"Ubuntu Dapper Flight-2"},{"categories":["Open Source","Linux"],"contents":"I haven\u0026rsquo;t been focusing on Linux during that last couple of months, I was a bit distracted completing my home cinema installation and ever since I have been watching a lot of films.\nHowever, I needed to get one of my laptops up to date for the Christmas holidays and in doing so needed some packages from the Ubuntu Backports repository, which led me to find the Ubuntu Penguin Liberation Front.\nThe Ubuntu PLF is a team that builds packages that are patent encumbered or proprietary. The PLF has been providing litigious packages for Mandriva for many years and now they are doing the same thing for Ubuntu. Having added the Breezy Backports and PLF repositories (just about) everything I consider essential for my desktop needs is now apt-getable, yah!\n","permalink":"https://wimpysworld.com/posts/ubuntu-backports-and-plf-repositories/","tags":["Ubuntu"],"title":"Ubuntu Backports and PLF Repositories"},{"categories":["Home Cinema","Entertainment"],"contents":"I had previously read on Yahoo Groups that a project was under way to retro fit a USB interface to the PaceTwin PVR allowing for easy archiving of recorded programs to a computer. Well, the guy who is planning the DIY upgrade has setup a website which is documenting progress and also other useful PaceTwin information. See the URL below for more information\u0026hellip;\nhttp://www.pace-twin.org.uk ","permalink":"https://wimpysworld.com/posts/pacetwin-usb-interface-modification/","tags":["DVB-T","PVR","PaceTwin","Freeview"],"title":"PaceTwin USB Interface Modification"},{"categories":["Home Cinema","Entertainment"],"contents":"I have been exchanging e-mails with the UK distributor for Lumagen and the Lumagen engineering department. Today is a happy day because I have just tested a pre-release firmware which fully fixes the issues I\u0026rsquo;ve reported.\nThanks very much to the engineers at Lumagen amd for their patience and hard work. Truly excellent customer service! See my post in the Lumagen forums.\nUK DVB-T PAL De-interlacing Issues ","permalink":"https://wimpysworld.com/posts/lumagen-video-processor-bug-fixed/","tags":["Lumagen","VisionDVI","FPGA","Scaler"],"title":"Lumagen Video Processor Bug Fixed"},{"categories":["Home Cinema","Entertainment"],"contents":"I have spent the last few weeks tweaking and improving my home cinema setup, most of my time has been spent learning how to fully exploit my Lumagen video processor. I am extremely impressed with the huge improvements in image quality the Lumagen VisionDVI provides as opposed to sending video sources direct to the plasma screen, but something isn\u0026rsquo;t right with the de-interlacing of DVB-T (or Freeview as we call it in the UK). I have isolated the exact issue and posted a problem report in the Lumagen forums.\n","permalink":"https://wimpysworld.com/posts/lumagen-video-processor-bug-hunting/","tags":["Lumagen","VisionDVI","FPGA","Scaler","Freeview"],"title":"Lumagen Video Processor Bug Hunting"},{"categories":["Home Cinema"],"contents":"Tonight was a landmark occasion. After nearly two years of planning I finally completed our home cinema. The last job was mounting the plasma screen. Apart from hiding away some power cables it is complete and I can\u0026rsquo;t wait to get into some serious film viewing. Mounting the plasma screen was not a job I was looking forward as DIY is not my strong suit. But, I managed it and posted my experiences in the topic below at AVForums.\nMounting on dry-lined walls ","permalink":"https://wimpysworld.com/posts/home-cinema-is-complete/","tags":null,"title":"Home Cinema is complete!"},{"categories":["Linux","Open Source","Home Cinema","Entertainment"],"contents":"I have built an initial prototype of a Linux based PVR using some (very) old hardware I had available. I simply plugged in a new Hauppauge Nova-T PCI card and hoped for the best. I got everything working but had to fudge things so that over the air electronic program guide (EPG) can be imported into the MythTV program guide database.\nThis initial prototype uses KnoppMyth Release 5A16 so that I could get up to speed as quickly as possible but I plan on using Debian or Ubuntu in the future.\n","permalink":"https://wimpysworld.com/posts/first-prototype-of-my-linux-pvr/","tags":["PVR","DVB-T","MythTV","Freeview"],"title":"First Prototype of my Linux PVR"},{"categories":["Linux","Open Source","Home Cinema","Entertainment"],"contents":"I have started working on a new project at home, it is one I know I am going to enjoy because it satisfies two of my hobbies. I am going to build a prototype PVR based on MythTV.\n","permalink":"https://wimpysworld.com/posts/when-linux-meets-home-cinema/","tags":["PVR","DVB-T","MythTV","Freeview"],"title":"When Linux meets Home Cinema"},{"categories":["Travel"],"contents":"I arranged a surprise holiday to the Isles of Scilly for my wifes birthday and we got back a couple of days ago. What a fantastic place!\nWe very much enjoyed our short time on the islands and will definately be going back in the future, I think our enjoyment was also heightened by the fantastic weather we had during our stay. One of the highlights of the trip was the helicopter flights to and from the islands, which gives you some great views of the Cornish coast line and Lands End. The Scilly Isles have a rich history and this is slowly revealed as you visit each island and the attractions they offer.\nThe scenery is beautiful everywhere, but the Abbey Garden on Tresco is very impressive. A side from island hoping and wandering around the island coastal pathways we also went out to see some grey seals out on the rocks to the west of the islands. Other highlights are the plentiful supply of real Cornish pasties, cream teas and ice cream. The food on the islands was very good and if you like fish you are in for a treat. The views of the sunsets are lovely and best accompanied with a pint of ale :-)\n","permalink":"https://wimpysworld.com/posts/isles-of-scilly/","tags":["Isles of Scilly","Travel"],"title":"Isles of Scilly"},{"categories":["Linux","Open Source","Gadgets","Computer Hardware"],"contents":"I have replaced the disk in my Libretto CT100 with a 20GB disk I had going spare and re-installed Debian Sarge 3.1, this time I didn\u0026rsquo;t bother with the 2.6 kernel or Xfce because I\u0026rsquo;ve had my fun with those now. But playing around with Linux on my Libretto has re-kindled my interested in running Linux on small portable devices.\nEarlier this year I experimented with Familiar Linux 0.8.2 on my iPAQ 3970 and installed via a serial cable, which was very slow going. So I\u0026rsquo;ve invested in a 512MB Compact Flash card to speed up my next round of tinkering with Familiar but this time I intend to leave Familiar installed and not re-flash the 3970 with PocketPC 2002. The Familiar v0.8.2 Installation guide covers pretty much everything you need to know about the installation process.\n","permalink":"https://wimpysworld.com/posts/handheld-linux/","tags":["Libretto CT100","PocketPC","iPAQ 3970","Familiar Linux","Debian"],"title":"Handheld Linux"},{"categories":["Linux","Open Source","Computer Hardware"],"contents":"I decided to stick with the 2.1GB hard disk in the end, but in order to complete the initial install I fitted it in an old IBM Thinkpad 600X. This allowed me to boot off the Debian 3.1 Net Install CD and get a basic system installed. Once that was done I fitted the hard disk back in the Libretto and installed the essential bits and pieces I needed. I am feeling a lot of love for apt-get today.\nThen I got carried away. I upgraded to the 2.6 kernel, installed X and Xfce 4.2.2. Then I migrated to the testing repositories, the upgrade for which has finished a few minutes ago. I found Quentin Stafford-Fraser\u0026rsquo;s Linux on the Libretto 100CT page very helpful in finding the right Modeline settings to get X going. I don\u0026rsquo;t really need Xfce on the Libretto but I couldn\u0026rsquo;t resist getting it running. Despite the low spec processor and just 64MB of RAM it runs very well, even Firefox is usable. I might have to bring this box along to the next HantsLUG meeting.\n","permalink":"https://wimpysworld.com/posts/debian-3.1-on-libretto-ct100/","tags":["Libretto CT100","ThinkPad 600X","Debian","Xfce"],"title":"Debian 3.1 on Libretto CT100"},{"categories":["Linux","Computer Hardware"],"contents":"The CPU fan on my home server stopped spinning, which has rendered the computer unusable until I find the time to replace it. I have my workstation, so I can keep working for the most part, but the services I was running on the server are critical so I need a server replacement ASAP. I have decided to setup a dedicated server for those services.\nI always knew my Libretto CT100 would come in handy someday. With 64MB RAM and a Pentium 166mhz MMX CPU I think it will make an excellent server. Although I may upgrade the hard disk from 2.1GB to 20GB. I am undecided which distro I\u0026rsquo;ll install, probably Ubuntu 5.10 or Debian 3.1, but because the Libretto CT100 has weird hardware this install is not straight forward. The following web pages seem to be the most useful to me right now:\nInstalling Debian Linux 3.1 Sarge on Toshiba Libretto 50 Installing RedHat Linux on a Toshiba Libretto 100CT Has good background information on the hardware and hibernation partition There are several other installs documented on the Linux on Toshiba Laptop and Notebook Computers page.\n","permalink":"https://wimpysworld.com/posts/server-crash-but-i-have-the-perfect-replacement/","tags":["Libretto CT100","Debian"],"title":"Server crash! But I have the perfect replacement"},{"categories":["Linux","Open Source"],"contents":"Adam Tricket got a few people interested in QEMU at the HantsLUG meeting on Saturday 3rd September 2005. Having recently discovered the wonders of QEMU myself I couldn\u0026rsquo;t help but get involved in the conversation. Me and my big mouth! I somehow managed to lumber myself with the job of writing a Wiki page about QEMU for the HantsLUG website. The page is more or less useful now and you can read it here\u0026hellip;\nLinuxHints/QemuEmulation ","permalink":"https://wimpysworld.com/posts/qemu-how-to-wiki-thingy/","tags":["Virtualisation","QEMU"],"title":"QEMU How-To Wiki Thingy"},{"categories":["Food \u0026 Drink"],"contents":"I finally got around to planting a small herb garden today, something I have wanted to do ever since my wife and I designed the garden layout. The border looks much better for being planted out but, once they are established, I can\u0026rsquo;t wait to start harvesting my new crop üòÑ\nSo far I have planted Chive, Mint, Basil, Red Basil, Thyme, Lavender, Oregano, Sage, Rosemary and Parsley. I just need to add some Coriander.\n","permalink":"https://wimpysworld.com/posts/herb-garden/","tags":["Herbs"],"title":"Herb Garden"},{"categories":["Open Source","Content Creation","Development"],"contents":"Yesterday was a sad day. I finally notified the core Minerva developers that I am leaving the project. Given that I started the project a few years back it was not a decision I made lightly.\nI have a couple of reasons for leaving the project, the main one being that I just do not have the time available to effectively lead or contribute to the project. All open source projects require good leadership and I haven\u0026rsquo;t been able to provide that for most of 2005. It is with the best interests of Minerva in mind that I decided to leave.\nHowever, Minerva is in very good hands and is under active development, with Dave and Chris leading the effort. I wish all the Minerva developers and users every success with the upcoming release of R4, it is a marvelous achievement and I am sure will prove to be very successful. I will be keeping an eye on R4 development, and if time permits, I may contribute some blocks and modules in the future. Until then, good luck and make me proud!\n","permalink":"https://wimpysworld.com/posts/leaving-minerva/","tags":["Minerva","PHP","Content Management"],"title":"Leaving Minerva"},{"categories":["Gadgets"],"contents":"I picked up a pair of new earbuds yesterday. I decided on the Sony MDR-EX71SL earbuds as all the reviews I have read have been very positive, and after listening to a few of my favourite albums with them, I am also very impressed with their performance. Due to their earbud design nearly all background noise is eliminated meaning you can hear your music very clearly at lower volumes, this good for preserving your hearing and also prevents you from annoying people nearby with noise bleed from the headphones. Bass performance is especially good and you get three different sizes silicon ear bud so everyone should be able to get a comfortable fit, the smallest size is best for me. I chose to get a black pair but the are also available in white for iPod owners.\n","permalink":"https://wimpysworld.com/posts/ere-ear/","tags":["Sony MDR-EX71SL","Earbuds"],"title":"'ere ear!"},{"categories":["Gadgets","Entertainment","Retro"],"contents":"I recently discovered ScummVM and have started playing Zak McKracken and the Alien Mindbenders for the first time in years! ScummVM allows you to run certain classic graphical point-and-click adventure games, provided you already have their data files, allowing you to play them on systems for which they were never designed!\nSo, I decided to organise my old adventure games for use with ScummVM so that I can enjoy them all again, but this has led to a couple of eBay bids to buy some games I am missing. I have used the ScummVM tools to compress as the game data files so I can fit the games on my iPAQ 4150. Life is good. I have been thinking of getting a new solid state Ogg Vorbis compatible portable music player but haven\u0026rsquo;t found one which completely suits my needs. So, my iPAQ 4150 is now standing in as my portable music player too. This is thanks too the excellent GSPlayer. I have configured my iPAQ 4150 to be a full time entertainment device.\nI am off to get myself a decent set of head phones today, more on that later\u0026hellip;\n","permalink":"https://wimpysworld.com/posts/pocket-entertainment/","tags":["PocketPC","iPAQ 4150","Emulation","ScummVM","MP3"],"title":"Pocket Entertainment"},{"categories":["Open Source","Development"],"contents":"I\u0026rsquo;ve finished hacking together a new theme for Jaws 0.5.x, which I have named Stanley, and is now the default theme on this site. I\u0026rsquo;ve still got to fix a couple of bugs and make sure that it is compatible with browsers other than Firefox. I wanted a theme which was crisp and clean, but also fully compatible with Jaws, so I decided to blend some of my favourite themes together. Stanley is inspired by the Kubrick theme which is popular among bloggers and although the Kubrick graphics have been borrowed the style sheet and layout are derived from the jaws, orange-grey and simple-green themes which are bundled with Jaws. As a result Stanley is properly Jaws compatible, in that left and right layouts work, all the CSS elements are supported and CSS tweaks are used throughout to improve the visual appeal.\n","permalink":"https://wimpysworld.com/posts/introducing-stanley-a-new-theme-for-jaws/","tags":["Content Management","Jaws","PHP"],"title":"Introducing Stanley, a new theme for Jaws"},{"categories":["Open Source","Content Creation"],"contents":"After fiddling around with the Jaws setup for a while I have finally settled on something which I\u0026rsquo;m happy with. Once I found the default_page setting in the registry I was very happy. I\u0026rsquo;ll enable more gadgets (plugins) as I find a use for them, but my next task will probably be creating my own theme or at least combining ideas from several existing themes.\n","permalink":"https://wimpysworld.com/posts/basic-site-layout-complete/","tags":["Content Management","Jaws","PHP"],"title":"Basic site layout complete"},{"categories":["Open Source","Content Creation"],"contents":"Well, I have decided to get Flexion.Org on-line again and picked Jaws as the tool for the job. This might seem an odd choice considering I have been working on Minerva for the last 3 years, but there you are, life is strange.\n","permalink":"https://wimpysworld.com/posts/grrr-a-site-with-teeth/","tags":["Content Management","Jaws","PHP"],"title":"Grrr, a site with teeth"}]